{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import av\n",
    "import math\n",
    "from video_a import Video\n",
    "path = '../videos/SOX5yA1l24A.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla = Video(path, stream=\"video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla.seek(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 22,  36,  38, ...,  96,  95,  94],\n",
      "       [ 22,  36,  38, ..., 100,  98,  98],\n",
      "       [ 22,  36,  38, ..., 102, 100, 100],\n",
      "       ...,\n",
      "       [132, 132, 132, ..., 140, 140, 140],\n",
      "       [132, 132, 132, ..., 133, 136, 137],\n",
      "       [132, 132, 132, ..., 128, 130, 131]], dtype=uint8), 9.743066666666667)\n"
     ]
    }
   ],
   "source": [
    "print(bla.next())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing rudimentary read video function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms as t\n",
    "\n",
    "\n",
    "# read video\n",
    "def _read_video(vo,per_frame_transform, start=0, end=None ):\n",
    "    if not isinstance(vo, Video):\n",
    "        vo = Video(path)\n",
    "    \n",
    "    if end is None:\n",
    "        end = float(\"inf\")\n",
    "    \n",
    "    if end < start:\n",
    "        raise ValueError(\n",
    "            \"end_pts should be larger than start_pts, got \"\n",
    "            \"start_pts={} and end_pts={}\".format(start_pts, end_pts)\n",
    "        )\n",
    "    \n",
    "    \n",
    "    current_pts = start\n",
    "    frames = []\n",
    "       \n",
    "    # this should get us close to the actual starting point we want\n",
    "    vo.seek(start)\n",
    "    while current_pts <= end:\n",
    "        frame, current_pts = vo.next()\n",
    "        if current_pts >= start and current_pts <= end:\n",
    "            frames.append(per_frame_transform(frame))\n",
    "        \n",
    "    \n",
    "    return torch.stack(frames, 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_video(vo, start=0, end=None, width=-1, height=-1):\n",
    "    # get transfroms per frames\n",
    "    transforms = [t.ToTensor()]\n",
    "    if width > 0 and height>0:\n",
    "            transforms.insert(0, t.Resize((height, width), interpolation=2))\n",
    "            transforms.insert(0, t.ToPILImage())\n",
    "            \n",
    "    transform = t.Compose(transforms)\n",
    "    \n",
    "    return _read_video(vo, transform, start, end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 1, 384, 340])\n"
     ]
    }
   ],
   "source": [
    "test = read_video(bla, 4, 8)\n",
    "print(test.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 1, 224, 376])\n"
     ]
    }
   ],
   "source": [
    "test = read_video(bla, 8, 10, 376, 224)\n",
    "print(test.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TVAV 61\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "torchvision.set_video_backend(\"pyav\")\n",
    "def get_tv(path):\n",
    "    vframes, _, _ = torchvision.io.read_video(path, 8, 10, pts_unit=\"sec\")\n",
    "    print(\"TVAV\", len(vframes))\n",
    "\n",
    "get_tv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
