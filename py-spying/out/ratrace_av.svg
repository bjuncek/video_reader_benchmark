<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg version="1.1" width="1200" height="698" onload="init(evt)" viewBox="0 0 1200 698" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><!--Flame graph stack visualization. See https://github.com/brendangregg/FlameGraph for latest version, and http://www.brendangregg.com/flamegraphs.html for examples.--><!--NOTES: --><defs><linearGradient id="background" y1="0" y2="1" x1="0" x2="0"><stop stop-color="#eeeeee" offset="5%"/><stop stop-color="#eeeeb0" offset="95%"/></linearGradient></defs><style type="text/css">
text { font-family:"Verdana"; font-size:12px; fill:rgb(0,0,0); }
#title { text-anchor:middle; font-size:17px; }
#search { opacity:0.1; cursor:pointer; }
#search:hover, #search.show { opacity:1; }
#subtitle { text-anchor:middle; font-color:rgb(160,160,160); }
#unzoom { cursor:pointer; }
#frames > *:hover { stroke:black; stroke-width:0.5; cursor:pointer; }
.hide { display:none; }
.parent { opacity:0.5; }
</style><script type="text/ecmascript"><![CDATA[var nametype = 'Function:';
var fontsize = 12;
var fontwidth = 0.59;
var xpad = 10;
var inverted = true;
var searchcolor = 'rgb(230,0,230)';
var fluiddrawing = true;
var truncate_text_right = false;]]><![CDATA["use strict";
var details, searchbtn, unzoombtn, matchedtxt, svg, searching, frames;
function init(evt) {
    details = document.getElementById("details").firstChild;
    searchbtn = document.getElementById("search");
    unzoombtn = document.getElementById("unzoom");
    matchedtxt = document.getElementById("matched");
    svg = document.getElementsByTagName("svg")[0];
    frames = document.getElementById("frames");
    searching = 0;

    // Use GET parameters to restore a flamegraph's state.
    var restore_state = function() {
        var params = get_params();
        if (params.x && params.y)
            zoom(find_group(document.querySelector('[x="' + params.x + '"][y="' + params.y + '"]')));
        if (params.s)
            search(params.s);
    };

    if (fluiddrawing) {
        // Make width dynamic so the SVG fits its parent's width.
        svg.removeAttribute("width");
        // Edge requires us to have a viewBox that gets updated with size changes.
        var isEdge = /Edge\/\d./i.test(navigator.userAgent);
        if (!isEdge) {
          svg.removeAttribute("viewBox");
        }
        var update_for_width_change = function() {
            if (isEdge) {
                svg.attributes.viewBox.value = "0 0 " + svg.width.baseVal.value + " " + svg.height.baseVal.value;
            }

            // Keep consistent padding on left and right of frames container.
            frames.attributes.width.value = svg.width.baseVal.value - xpad * 2;

            // Text truncation needs to be adjusted for the current width.
            var el = frames.children;
            for(var i = 0; i < el.length; i++) {
                update_text(el[i]);
            }

            // Keep search elements at a fixed distance from right edge.
            var svgWidth = svg.width.baseVal.value;
            searchbtn.attributes.x.value = svgWidth - xpad - 100;
            matchedtxt.attributes.x.value = svgWidth - xpad - 100;
        };
        window.addEventListener('resize', function() {
            update_for_width_change();
        });
        // This needs to be done asynchronously for Safari to work.
        setTimeout(function() {
            unzoom();
            update_for_width_change();
            restore_state();
        }, 0);
    } else {
        restore_state();
    }
}
// event listeners
window.addEventListener("click", function(e) {
    var target = find_group(e.target);
    if (target) {
        if (target.nodeName == "a") {
            if (e.ctrlKey === false) return;
            e.preventDefault();
        }
        if (target.classList.contains("parent")) unzoom();
        zoom(target);

        // set parameters for zoom state
        var el = target.querySelector("rect");
        if (el && el.attributes && el.attributes.y && el.attributes._orig_x) {
            var params = get_params()
            params.x = el.attributes._orig_x.value;
            params.y = el.attributes.y.value;
            history.replaceState(null, null, parse_params(params));
        }
    }
    else if (e.target.id == "unzoom") {
        unzoom();

        // remove zoom state
        var params = get_params();
        if (params.x) delete params.x;
        if (params.y) delete params.y;
        history.replaceState(null, null, parse_params(params));
    }
    else if (e.target.id == "search") search_prompt();
}, false)
// mouse-over for info
// show
window.addEventListener("mouseover", function(e) {
    var target = find_group(e.target);
    if (target) details.nodeValue = nametype + " " + g_to_text(target);
}, false)
// clear
window.addEventListener("mouseout", function(e) {
    var target = find_group(e.target);
    if (target) details.nodeValue = ' ';
}, false)
// ctrl-F for search
window.addEventListener("keydown",function (e) {
    if (e.keyCode === 114 || (e.ctrlKey && e.keyCode === 70)) {
        e.preventDefault();
        search_prompt();
    }
}, false)
// functions
function get_params() {
    var params = {};
    var paramsarr = window.location.search.substr(1).split('&');
    for (var i = 0; i < paramsarr.length; ++i) {
        var tmp = paramsarr[i].split("=");
        if (!tmp[0] || !tmp[1]) continue;
        params[tmp[0]]  = decodeURIComponent(tmp[1]);
    }
    return params;
}
function parse_params(params) {
    var uri = "?";
    for (var key in params) {
        uri += key + '=' + encodeURIComponent(params[key]) + '&';
    }
    if (uri.slice(-1) == "&")
        uri = uri.substring(0, uri.length - 1);
    if (uri == '?')
        uri = window.location.href.split('?')[0];
    return uri;
}
function find_child(node, selector) {
    var children = node.querySelectorAll(selector);
    if (children.length) return children[0];
    return;
}
function find_group(node) {
    var parent = node.parentElement;
    if (!parent) return;
    if (parent.id == "frames") return node;
    return find_group(parent);
}
function orig_save(e, attr, val) {
    if (e.attributes["_orig_" + attr] != undefined) return;
    if (e.attributes[attr] == undefined) return;
    if (val == undefined) val = e.attributes[attr].value;
    e.setAttribute("_orig_" + attr, val);
}
function orig_load(e, attr) {
    if (e.attributes["_orig_"+attr] == undefined) return;
    e.attributes[attr].value = e.attributes["_orig_" + attr].value;
    e.removeAttribute("_orig_" + attr);
}
function g_to_text(e) {
    var text = find_child(e, "title").firstChild.nodeValue;
    return (text)
}
function g_to_func(e) {
    var func = g_to_text(e);
    // if there's any manipulation we want to do to the function
    // name before it's searched, do it here before returning.
    return (func);
}
function update_text(e) {
    var r = find_child(e, "rect");
    var t = find_child(e, "text");
    var w = parseFloat(r.attributes.width.value) * frames.attributes.width.value / 100 - 3;
    var txt = find_child(e, "title").textContent.replace(/\([^(]*\)$/,"");
    t.attributes.x.value = format_percent((parseFloat(r.attributes.x.value) + (100 * 3 / frames.attributes.width.value)));
    // Smaller than this size won't fit anything
    if (w < 2 * fontsize * fontwidth) {
        t.textContent = "";
        return;
    }
    t.textContent = txt;
    // Fit in full text width
    if (/^ *\$/.test(txt) || t.getComputedTextLength() < w)
        return;
    if (truncate_text_right) {
        // Truncate the right side of the text.
        for (var x = txt.length - 2; x > 0; x--) {
            if (t.getSubStringLength(0, x + 2) <= w) {
                t.textContent = txt.substring(0, x) + "..";
                return;
            }
        }
    } else {
        // Truncate the left side of the text.
        for (var x = 2; x < txt.length; x++) {
            if (t.getSubStringLength(x - 2, txt.length) <= w) {
                t.textContent = ".." + txt.substring(x, txt.length);
                return;
            }
        }
    }
    t.textContent = "";
}
// zoom
function zoom_reset(e) {
    if (e.attributes != undefined) {
        orig_load(e, "x");
        orig_load(e, "width");
    }
    if (e.childNodes == undefined) return;
    for(var i = 0, c = e.childNodes; i < c.length; i++) {
        zoom_reset(c[i]);
    }
}
function zoom_child(e, x, ratio) {
    if (e.attributes != undefined) {
        if (e.attributes.x != undefined) {
            orig_save(e, "x");
            e.attributes.x.value = format_percent((parseFloat(e.attributes.x.value) - x) * ratio);
            if (e.tagName == "text") {
                e.attributes.x.value = format_percent(parseFloat(find_child(e.parentNode, "rect[x]").attributes.x.value) + (100 * 3 / frames.attributes.width.value));
            }
        }
        if (e.attributes.width != undefined) {
            orig_save(e, "width");
            e.attributes.width.value = format_percent(parseFloat(e.attributes.width.value) * ratio);
        }
    }
    if (e.childNodes == undefined) return;
    for(var i = 0, c = e.childNodes; i < c.length; i++) {
        zoom_child(c[i], x, ratio);
    }
}
function zoom_parent(e) {
    if (e.attributes) {
        if (e.attributes.x != undefined) {
            orig_save(e, "x");
            e.attributes.x.value = "0.0%";
        }
        if (e.attributes.width != undefined) {
            orig_save(e, "width");
            e.attributes.width.value = "100.0%";
        }
    }
    if (e.childNodes == undefined) return;
    for(var i = 0, c = e.childNodes; i < c.length; i++) {
        zoom_parent(c[i]);
    }
}
function zoom(node) {
    var attr = find_child(node, "rect").attributes;
    var width = parseFloat(attr.width.value);
    var xmin = parseFloat(attr.x.value);
    var xmax = xmin + width;
    var ymin = parseFloat(attr.y.value);
    var ratio = 100 / width;
    // XXX: Workaround for JavaScript float issues (fix me)
    var fudge = 0.001;
    unzoombtn.classList.remove("hide");
    var el = frames.children;
    for (var i = 0; i < el.length; i++) {
        var e = el[i];
        var a = find_child(e, "rect").attributes;
        var ex = parseFloat(a.x.value);
        var ew = parseFloat(a.width.value);
        // Is it an ancestor
        if (!inverted) {
            var upstack = parseFloat(a.y.value) > ymin;
        } else {
            var upstack = parseFloat(a.y.value) < ymin;
        }
        if (upstack) {
            // Direct ancestor
            if (ex <= xmin && (ex+ew+fudge) >= xmax) {
                e.classList.add("parent");
                zoom_parent(e);
                update_text(e);
            }
            // not in current path
            else
                e.classList.add("hide");
        }
        // Children maybe
        else {
            // no common path
            if (ex < xmin || ex + fudge >= xmax) {
                e.classList.add("hide");
            }
            else {
                zoom_child(e, xmin, ratio);
                update_text(e);
            }
        }
    }
}
function unzoom() {
    unzoombtn.classList.add("hide");
    var el = frames.children;
    for(var i = 0; i < el.length; i++) {
        el[i].classList.remove("parent");
        el[i].classList.remove("hide");
        zoom_reset(el[i]);
        update_text(el[i]);
    }
}
// search
function reset_search() {
    var el = document.querySelectorAll("#frames rect");
    for (var i = 0; i < el.length; i++) {
        orig_load(el[i], "fill")
    }
    var params = get_params();
    delete params.s;
    history.replaceState(null, null, parse_params(params));
}
function search_prompt() {
    if (!searching) {
        var term = prompt("Enter a search term (regexp " +
            "allowed, eg: ^ext4_)", "");
        if (term != null) {
            search(term)
        }
    } else {
        reset_search();
        searching = 0;
        searchbtn.classList.remove("show");
        searchbtn.firstChild.nodeValue = "Search"
        matchedtxt.classList.add("hide");
        matchedtxt.firstChild.nodeValue = ""
    }
}
function search(term) {
    var re = new RegExp(term);
    var el = frames.children;
    var matches = new Object();
    var maxwidth = 0;
    for (var i = 0; i < el.length; i++) {
        var e = el[i];
        var func = g_to_func(e);
        var rect = find_child(e, "rect");
        if (func == null || rect == null)
            continue;
        // Save max width. Only works as we have a root frame
        var w = parseFloat(rect.attributes.width.value);
        if (w > maxwidth)
            maxwidth = w;
        if (func.match(re)) {
            // highlight
            var x = parseFloat(rect.attributes.x.value);
            orig_save(rect, "fill");
            rect.attributes.fill.value = searchcolor;
            // remember matches
            if (matches[x] == undefined) {
                matches[x] = w;
            } else {
                if (w > matches[x]) {
                    // overwrite with parent
                    matches[x] = w;
                }
            }
            searching = 1;
        }
    }
    if (!searching)
        return;
    var params = get_params();
    params.s = term;
    history.replaceState(null, null, parse_params(params));

    searchbtn.classList.add("show");
    searchbtn.firstChild.nodeValue = "Reset Search";
    // calculate percent matched, excluding vertical overlap
    var count = 0;
    var lastx = -1;
    var lastw = 0;
    var keys = Array();
    for (k in matches) {
        if (matches.hasOwnProperty(k))
            keys.push(k);
    }
    // sort the matched frames by their x location
    // ascending, then width descending
    keys.sort(function(a, b){
        return a - b;
    });
    // Step through frames saving only the biggest bottom-up frames
    // thanks to the sort order. This relies on the tree property
    // where children are always smaller than their parents.
    var fudge = 0.0001;    // JavaScript floating point
    for (var k in keys) {
        var x = parseFloat(keys[k]);
        var w = matches[keys[k]];
        if (x >= lastx + lastw - fudge) {
            count += w;
            lastx = x;
            lastw = w;
        }
    }
    // display matched percent
    matchedtxt.classList.remove("hide");
    var pct = 100 * count / maxwidth;
    if (pct != 100) pct = pct.toFixed(1);
    matchedtxt.firstChild.nodeValue = "Matched: " + pct + "%";
}
function format_percent(n) {
    return n.toFixed(4) + "%";
}
]]></script><rect x="0" y="0" width="100%" height="698" fill="url(#background)"/><text id="title" x="50.0000%" y="24.00">py-spy</text><text id="details" x="10" y="40.00"> </text><text id="unzoom" class="hide" x="10" y="24.00">Reset Zoom</text><text id="search" x="1090" y="24.00">Search</text><text id="matched" x="1090" y="687.00"> </text><svg id="frames" x="10" width="1180"><g><title>dlopen (libdl-2.27.so) (185 samples, 1.17%)</title><rect x="0.8680%" y="484" width="1.1721%" height="15" fill="rgb(227,0,7)"/><text x="1.1180%" y="494.50"></text></g><g><title>0x7f624f2ec745 (libdl-2.27.so) (185 samples, 1.17%)</title><rect x="0.8680%" y="500" width="1.1721%" height="15" fill="rgb(217,0,24)"/><text x="1.1180%" y="510.50"></text></g><g><title>_dl_catch_error (libc-2.27.so) (185 samples, 1.17%)</title><rect x="0.8680%" y="516" width="1.1721%" height="15" fill="rgb(221,193,54)"/><text x="1.1180%" y="526.50"></text></g><g><title>_dl_catch_exception (libc-2.27.so) (185 samples, 1.17%)</title><rect x="0.8680%" y="532" width="1.1721%" height="15" fill="rgb(248,212,6)"/><text x="1.1180%" y="542.50"></text></g><g><title>0x7f624f2ebf96 (libdl-2.27.so) (185 samples, 1.17%)</title><rect x="0.8680%" y="548" width="1.1721%" height="15" fill="rgb(208,68,35)"/><text x="1.1180%" y="558.50"></text></g><g><title>0x7f624fb1396a (ld-2.27.so) (185 samples, 1.17%)</title><rect x="0.8680%" y="564" width="1.1721%" height="15" fill="rgb(232,128,0)"/><text x="1.1180%" y="574.50"></text></g><g><title>_dl_catch_exception (libc-2.27.so) (185 samples, 1.17%)</title><rect x="0.8680%" y="580" width="1.1721%" height="15" fill="rgb(207,160,47)"/><text x="1.1180%" y="590.50"></text></g><g><title>&lt;module&gt; (torch/__init__.py:196) (354 samples, 2.24%)</title><rect x="0.8553%" y="372" width="2.2428%" height="15" fill="rgb(228,23,34)"/><text x="1.1053%" y="382.50">&lt;..</text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:991) (354 samples, 2.24%)</title><rect x="0.8553%" y="388" width="2.2428%" height="15" fill="rgb(218,30,26)"/><text x="1.1053%" y="398.50">_..</text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:975) (354 samples, 2.24%)</title><rect x="0.8553%" y="404" width="2.2428%" height="15" fill="rgb(220,122,19)"/><text x="1.1053%" y="414.50">_..</text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:657) (354 samples, 2.24%)</title><rect x="0.8553%" y="420" width="2.2428%" height="15" fill="rgb(250,228,42)"/><text x="1.1053%" y="430.50">_..</text></g><g><title>module_from_spec (&lt;frozen importlib._bootstrap&gt;:556) (354 samples, 2.24%)</title><rect x="0.8553%" y="436" width="2.2428%" height="15" fill="rgb(240,193,28)"/><text x="1.1053%" y="446.50">m..</text></g><g><title>create_module (&lt;frozen importlib._bootstrap_external&gt;:1101) (354 samples, 2.24%)</title><rect x="0.8553%" y="452" width="2.2428%" height="15" fill="rgb(216,20,37)"/><text x="1.1053%" y="462.50">c..</text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (354 samples, 2.24%)</title><rect x="0.8553%" y="468" width="2.2428%" height="15" fill="rgb(206,188,39)"/><text x="1.1053%" y="478.50">_..</text></g><g><title>initModule (libtorch_python.so) (167 samples, 1.06%)</title><rect x="2.0400%" y="484" width="1.0580%" height="15" fill="rgb(217,207,13)"/><text x="2.2900%" y="494.50"></text></g><g><title>_register_extensions (torchvision/extension.py:11) (557 samples, 3.53%)</title><rect x="0.0253%" y="276" width="3.5289%" height="15" fill="rgb(231,73,38)"/><text x="0.2753%" y="286.50">_re..</text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:991) (557 samples, 3.53%)</title><rect x="0.0253%" y="292" width="3.5289%" height="15" fill="rgb(225,20,46)"/><text x="0.2753%" y="302.50">_fi..</text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:975) (557 samples, 3.53%)</title><rect x="0.0253%" y="308" width="3.5289%" height="15" fill="rgb(210,31,41)"/><text x="0.2753%" y="318.50">_fi..</text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:671) (557 samples, 3.53%)</title><rect x="0.0253%" y="324" width="3.5289%" height="15" fill="rgb(221,200,47)"/><text x="0.2753%" y="334.50">_lo..</text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:783) (557 samples, 3.53%)</title><rect x="0.0253%" y="340" width="3.5289%" height="15" fill="rgb(226,26,5)"/><text x="0.2753%" y="350.50">exe..</text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (557 samples, 3.53%)</title><rect x="0.0253%" y="356" width="3.5289%" height="15" fill="rgb(249,33,26)"/><text x="0.2753%" y="366.50">_ca..</text></g><g><title>&lt;module&gt; (torchvision/__init__.py:4) (612 samples, 3.88%)</title><rect x="0.0253%" y="164" width="3.8773%" height="15" fill="rgb(235,183,28)"/><text x="0.2753%" y="174.50">&lt;mod..</text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:991) (612 samples, 3.88%)</title><rect x="0.0253%" y="180" width="3.8773%" height="15" fill="rgb(221,5,38)"/><text x="0.2753%" y="190.50">_fin..</text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:975) (612 samples, 3.88%)</title><rect x="0.0253%" y="196" width="3.8773%" height="15" fill="rgb(247,18,42)"/><text x="0.2753%" y="206.50">_fin..</text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:671) (612 samples, 3.88%)</title><rect x="0.0253%" y="212" width="3.8773%" height="15" fill="rgb(241,131,45)"/><text x="0.2753%" y="222.50">_loa..</text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:783) (612 samples, 3.88%)</title><rect x="0.0253%" y="228" width="3.8773%" height="15" fill="rgb(249,31,29)"/><text x="0.2753%" y="238.50">exec..</text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (612 samples, 3.88%)</title><rect x="0.0253%" y="244" width="3.8773%" height="15" fill="rgb(225,111,53)"/><text x="0.2753%" y="254.50">_cal..</text></g><g><title>&lt;module&gt; (torchvision/extension.py:51) (612 samples, 3.88%)</title><rect x="0.0253%" y="260" width="3.8773%" height="15" fill="rgb(238,160,17)"/><text x="0.2753%" y="270.50">&lt;mod..</text></g><g><title>&lt;module&gt; (PV_ratrace_newAPI.py:1) (739 samples, 4.68%)</title><rect x="0.0000%" y="68" width="4.6820%" height="15" fill="rgb(214,148,48)"/><text x="0.2500%" y="78.50">&lt;modu..</text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:991) (739 samples, 4.68%)</title><rect x="0.0000%" y="84" width="4.6820%" height="15" fill="rgb(232,36,49)"/><text x="0.2500%" y="94.50">_find..</text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:975) (739 samples, 4.68%)</title><rect x="0.0000%" y="100" width="4.6820%" height="15" fill="rgb(209,103,24)"/><text x="0.2500%" y="110.50">_find..</text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:671) (739 samples, 4.68%)</title><rect x="0.0000%" y="116" width="4.6820%" height="15" fill="rgb(229,88,8)"/><text x="0.2500%" y="126.50">_load..</text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:783) (739 samples, 4.68%)</title><rect x="0.0000%" y="132" width="4.6820%" height="15" fill="rgb(213,181,19)"/><text x="0.2500%" y="142.50">exec_..</text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (739 samples, 4.68%)</title><rect x="0.0000%" y="148" width="4.6820%" height="15" fill="rgb(254,191,54)"/><text x="0.2500%" y="158.50">_call..</text></g><g><title>vision::video::Video::Video (video.cpp:184) (190 samples, 1.20%)</title><rect x="4.8277%" y="356" width="1.2038%" height="15" fill="rgb(241,83,37)"/><text x="5.0777%" y="366.50"></text></g><g><title>__init__ (torchvision/io/__init__.py:109) (378 samples, 2.39%)</title><rect x="4.7326%" y="84" width="2.3948%" height="15" fill="rgb(233,36,39)"/><text x="4.9826%" y="94.50">__..</text></g><g><title>pybind11::cpp_function::dispatcher (libtorch_python.so) (374 samples, 2.37%)</title><rect x="4.7580%" y="100" width="2.3695%" height="15" fill="rgb(226,3,54)"/><text x="5.0080%" y="110.50">py..</text></g><g><title>pybind11::cpp_function::initialize&lt;pybind11::cpp_function::cpp_function&lt;pybind11::object, torch::jit::ScriptClass, pybind11::args, pybind11::kwargs, pybind11::name, pybind11::is_method, pybind11::sibling&gt;(pybind11::name const, pybind11::is_method&amp;, pybind11::sibling)::{lambda(torch::jit::ScriptClass*, pybind11::args, pybind11::kwargs)#1}, pybind11::object, torch::jit::ScriptClass*, pybind11::args, pybind11::kwargs, pybind11::name, pybind11::is_method, pybind11::sibling&gt;(pybind11::cpp_function::cpp_function&lt;pybind11::object, torch::jit::ScriptClass, pybind11::args, pybind11::kwargs, pybind11::name, pybind11::is_method, pybind11::sibling&gt;(pybind11::name const, pybind11::is_method&amp;, pybind11::sibling)::{lambda(torch::jit::ScriptClass*, pybind11::args&amp;&amp;, pybind11::kwargs)#1}, pybind11::object (*)(torch::jit::ScriptClass*, pybind11::args, pybind11::kwargs), pybind11::name const, pybind11::is_method&amp;, pybind11::sibling)::{lambda(pybind11::detail::function_call&amp;)#3}::operator() const (libtorch_python.so) (373 samples, 2.36%)</title><rect x="4.7643%" y="116" width="2.3632%" height="15" fill="rgb(245,192,40)"/><text x="5.0143%" y="126.50">py..</text></g><g><title>torch::jit::ScriptClass::__call__ (libtorch_python.so) (373 samples, 2.36%)</title><rect x="4.7643%" y="132" width="2.3632%" height="15" fill="rgb(238,167,29)"/><text x="5.0143%" y="142.50">to..</text></g><g><title>torch::jit::runAndInsertCall (libtorch_python.so) (372 samples, 2.36%)</title><rect x="4.7707%" y="148" width="2.3568%" height="15" fill="rgb(232,182,51)"/><text x="5.0207%" y="158.50">t..</text></g><g><title>std::_Function_handler&lt;void (std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;), torch::class_&lt;vision::video::Video&gt;::defineMethod&lt;torch::class_&lt;vision::video::Video&gt;::def&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;(torch::detail::types&lt;void, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)::{lambda(c10::tagged_capsule&lt;vision::video::Video&gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)#1}&gt;(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, torch::class_&lt;vision::video::Video&gt;::def&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;(torch::detail::types&lt;void, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)::{lambda(c10::tagged_capsule&lt;vision::video::Video&gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)#1}, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)::{lambda(std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;)#1}&gt;::_M_invoke (std_function.h:316) (372 samples, 2.36%)</title><rect x="4.7707%" y="164" width="2.3568%" height="15" fill="rgb(231,60,39)"/><text x="5.0207%" y="174.50">s..</text></g><g><title>torch::class_&lt;vision::video::Video&gt;::defineMethod&lt;torch::class_&lt;vision::video::Video&gt;::def&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;(torch::detail::types&lt;void, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)::{lambda(c10::tagged_capsule&lt;vision::video::Video&gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)#1}&gt;(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, torch::class_&lt;vision::video::Video&gt;::def&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;(torch::detail::types&lt;void, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)::{lambda(c10::tagged_capsule&lt;vision::video::Video&gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)#1}, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)::{lambda(std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;)#1}::operator() (custom_class.h:276) (372 samples, 2.36%)</title><rect x="4.7707%" y="180" width="2.3568%" height="15" fill="rgb(208,69,12)"/><text x="5.0207%" y="190.50">t..</text></g><g><title>torch::detail::BoxedProxy&lt;void, torch::class_&lt;vision::video::Video&gt;::def&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;(torch::detail::types&lt;void, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)::{lambda(c10::tagged_capsule&lt;vision::video::Video&gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)#1}&gt;::operator() (custom_class_detail.h:115) (372 samples, 2.36%)</title><rect x="4.7707%" y="196" width="2.3568%" height="15" fill="rgb(235,93,37)"/><text x="5.0207%" y="206.50">t..</text></g><g><title>torch::detail::call_torchbind_method_from_stack&lt;torch::class_&lt;vision::video::Video&gt;::def&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;(torch::detail::types&lt;void, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)::{lambda(c10::tagged_capsule&lt;vision::video::Video&gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)#1}, false&gt; (custom_class_detail.h:94) (372 samples, 2.36%)</title><rect x="4.7707%" y="212" width="2.3568%" height="15" fill="rgb(213,116,39)"/><text x="5.0207%" y="222.50">t..</text></g><g><title>torch::detail::call_torchbind_method_from_stack&lt;torch::class_&lt;vision::video::Video&gt;::def&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;(torch::detail::types&lt;void, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)::{lambda(c10::tagged_capsule&lt;vision::video::Video&gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)#1}, false, (unsigned long)0, (unsigned long)1, (unsigned long)2&gt; (custom_class_detail.h:81) (372 samples, 2.36%)</title><rect x="4.7707%" y="228" width="2.3568%" height="15" fill="rgb(222,207,29)"/><text x="5.0207%" y="238.50">t..</text></g><g><title>c10::tagged_capsule&lt;vision::video::Video&gt;::~tagged_capsule (ivalue_inl.h:44) (372 samples, 2.36%)</title><rect x="4.7707%" y="244" width="2.3568%" height="15" fill="rgb(206,96,30)"/><text x="5.0207%" y="254.50">c..</text></g><g><title>c10::IValue::~IValue (ivalue.h:193) (372 samples, 2.36%)</title><rect x="4.7707%" y="260" width="2.3568%" height="15" fill="rgb(218,138,4)"/><text x="5.0207%" y="270.50">c..</text></g><g><title>torch::class_&lt;vision::video::Video&gt;::def&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;(torch::detail::types&lt;void, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)::{lambda(c10::tagged_capsule&lt;vision::video::Video&gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)#1}::operator() const (custom_class.h:104) (372 samples, 2.36%)</title><rect x="4.7707%" y="276" width="2.3568%" height="15" fill="rgb(250,191,14)"/><text x="5.0207%" y="286.50">t..</text></g><g><title>c10::make_intrusive&lt;vision::video::Video, c10::detail::intrusive_target_default_null_type&lt;vision::video::Video&gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;&amp;&gt; (intrusive_ptr.h:464) (372 samples, 2.36%)</title><rect x="4.7707%" y="292" width="2.3568%" height="15" fill="rgb(239,60,40)"/><text x="5.0207%" y="302.50">c..</text></g><g><title>c10::intrusive_ptr&lt;vision::video::Video, c10::detail::intrusive_target_default_null_type&lt;vision::video::Video&gt; &gt;::make&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;&amp;&gt; (basic_string.h:647) (372 samples, 2.36%)</title><rect x="4.7707%" y="308" width="2.3568%" height="15" fill="rgb(206,27,48)"/><text x="5.0207%" y="318.50">c..</text></g><g><title>std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;::_M_dispose (basic_string.h:220) (372 samples, 2.36%)</title><rect x="4.7707%" y="324" width="2.3568%" height="15" fill="rgb(225,35,8)"/><text x="5.0207%" y="334.50">s..</text></g><g><title>std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;::_M_is_local (basic_string.h:211) (372 samples, 2.36%)</title><rect x="4.7707%" y="340" width="2.3568%" height="15" fill="rgb(250,213,24)"/><text x="5.0207%" y="350.50">s..</text></g><g><title>vision::video::Video::Video (video.cpp:211) (170 samples, 1.08%)</title><rect x="6.0504%" y="356" width="1.0770%" height="15" fill="rgb(247,123,22)"/><text x="6.3004%" y="366.50"></text></g><g><title>std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;::~basic_string (basic_string.h:647) (170 samples, 1.08%)</title><rect x="6.0504%" y="372" width="1.0770%" height="15" fill="rgb(231,138,38)"/><text x="6.3004%" y="382.50"></text></g><g><title>std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;::_M_dispose (basic_string.h:220) (170 samples, 1.08%)</title><rect x="6.0504%" y="388" width="1.0770%" height="15" fill="rgb(231,145,46)"/><text x="6.3004%" y="398.50"></text></g><g><title>std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;::_M_is_local (basic_string.h:211) (170 samples, 1.08%)</title><rect x="6.0504%" y="404" width="1.0770%" height="15" fill="rgb(251,118,11)"/><text x="6.3004%" y="414.50"></text></g><g><title>vision::video::Video::setCurrentStream (video.cpp:241) (169 samples, 1.07%)</title><rect x="6.0568%" y="420" width="1.0707%" height="15" fill="rgb(217,147,25)"/><text x="6.3068%" y="430.50"></text></g><g><title>&lt;module&gt; (PV_ratrace_newAPI.py:7) (387 samples, 2.45%)</title><rect x="4.7326%" y="68" width="2.4518%" height="15" fill="rgb(247,81,37)"/><text x="4.9826%" y="78.50">&lt;m..</text></g><g><title>mpeg4_decode_mb (mpeg4videodec.c:1739) (242 samples, 1.53%)</title><rect x="11.9361%" y="468" width="1.5332%" height="15" fill="rgb(209,12,38)"/><text x="12.1861%" y="478.50"></text></g><g><title>mpeg4_decode_mb (mpeg4videodec.c:1748) (442 samples, 2.80%)</title><rect x="13.5707%" y="468" width="2.8003%" height="15" fill="rgb(227,1,9)"/><text x="13.8207%" y="478.50">mp..</text></g><g><title>decode_slice (h263dec.c:269) (1,184 samples, 7.50%)</title><rect x="9.1675%" y="452" width="7.5013%" height="15" fill="rgb(248,47,43)"/><text x="9.4175%" y="462.50">decode_sli..</text></g><g><title>put_pixels16_xy2_8_c (hpeldsp.c:334) (160 samples, 1.01%)</title><rect x="20.2547%" y="564" width="1.0137%" height="15" fill="rgb(221,10,30)"/><text x="20.5047%" y="574.50"></text></g><g><title>put_pixels8_xy2_8_c (hpeldsp.c:334) (160 samples, 1.01%)</title><rect x="20.2547%" y="580" width="1.0137%" height="15" fill="rgb(210,229,1)"/><text x="20.5047%" y="590.50"></text></g><g><title>mpeg_motion_internal (mpegvideo_motion.c:360) (522 samples, 3.31%)</title><rect x="18.3287%" y="548" width="3.3071%" height="15" fill="rgb(222,148,37)"/><text x="18.5787%" y="558.50">mpe..</text></g><g><title>mpeg_motion (mpegvideo_motion.c:384) (859 samples, 5.44%)</title><rect x="17.8472%" y="532" width="5.4422%" height="15" fill="rgb(234,67,33)"/><text x="18.0972%" y="542.50">mpeg_mo..</text></g><g><title>ff_mpv_motion (mpegvideo_motion.c:983) (893 samples, 5.66%)</title><rect x="17.6445%" y="500" width="5.6576%" height="15" fill="rgb(247,98,35)"/><text x="17.8945%" y="510.50">ff_mpv_..</text></g><g><title>mpv_motion_internal (mpegvideo_motion.c:909) (890 samples, 5.64%)</title><rect x="17.6635%" y="516" width="5.6386%" height="15" fill="rgb(247,138,52)"/><text x="17.9135%" y="526.50">mpv_mot..</text></g><g><title>mpv_reconstruct_mb_internal (mpegvideo.c:2071) (955 samples, 6.05%)</title><rect x="17.5558%" y="484" width="6.0504%" height="15" fill="rgb(213,79,30)"/><text x="17.8058%" y="494.50">mpv_reco..</text></g><g><title>mpeg_motion_internal (mpegvideo_motion.c:360) (272 samples, 1.72%)</title><rect x="23.9863%" y="548" width="1.7233%" height="15" fill="rgb(246,177,23)"/><text x="24.2363%" y="558.50"></text></g><g><title>mpeg_motion (mpegvideo_motion.c:384) (465 samples, 2.95%)</title><rect x="23.7456%" y="532" width="2.9460%" height="15" fill="rgb(230,62,27)"/><text x="23.9956%" y="542.50">mp..</text></g><g><title>ff_mpv_motion (mpegvideo_motion.c:983) (480 samples, 3.04%)</title><rect x="23.6759%" y="500" width="3.0411%" height="15" fill="rgb(216,154,8)"/><text x="23.9259%" y="510.50">ff_..</text></g><g><title>mpv_motion_internal (mpegvideo_motion.c:909) (478 samples, 3.03%)</title><rect x="23.6885%" y="516" width="3.0284%" height="15" fill="rgb(244,35,45)"/><text x="23.9385%" y="526.50">mpv..</text></g><g><title>mpv_reconstruct_mb_internal (mpegvideo.c:2074) (514 samples, 3.26%)</title><rect x="23.6125%" y="484" width="3.2565%" height="15" fill="rgb(251,115,12)"/><text x="23.8625%" y="494.50">mpv..</text></g><g><title>ff_simple_idct_add_int16_8bit (simple_idct_template.c:357) (179 samples, 1.13%)</title><rect x="27.6039%" y="500" width="1.1341%" height="15" fill="rgb(240,54,50)"/><text x="27.8539%" y="510.50"></text></g><g><title>mpv_reconstruct_mb_internal (mpegvideo.c:2110) (277 samples, 1.75%)</title><rect x="27.0020%" y="484" width="1.7549%" height="15" fill="rgb(233,84,52)"/><text x="27.2520%" y="494.50"></text></g><g><title>ff_simple_idct_add_int16_8bit (simple_idct_template.c:357) (205 samples, 1.30%)</title><rect x="29.2892%" y="500" width="1.2988%" height="15" fill="rgb(207,117,47)"/><text x="29.5392%" y="510.50"></text></g><g><title>mpv_reconstruct_mb_internal (mpegvideo.c:2111) (291 samples, 1.84%)</title><rect x="28.7570%" y="484" width="1.8436%" height="15" fill="rgb(249,43,39)"/><text x="29.0070%" y="494.50">m..</text></g><g><title>ff_simple_idct_add_int16_8bit (simple_idct_template.c:357) (206 samples, 1.31%)</title><rect x="31.1898%" y="516" width="1.3051%" height="15" fill="rgb(209,38,44)"/><text x="31.4398%" y="526.50"></text></g><g><title>add_dct (mpegvideo.c:1894) (296 samples, 1.88%)</title><rect x="30.6386%" y="500" width="1.8753%" height="15" fill="rgb(236,212,23)"/><text x="30.8886%" y="510.50">a..</text></g><g><title>ff_simple_idct_add_int16_8bit (simple_idct_template.c:357) (193 samples, 1.22%)</title><rect x="32.9701%" y="500" width="1.2228%" height="15" fill="rgb(242,79,21)"/><text x="33.2201%" y="510.50"></text></g><g><title>mpv_reconstruct_mb_internal (mpegvideo.c:2112) (568 samples, 3.60%)</title><rect x="30.6006%" y="484" width="3.5986%" height="15" fill="rgb(211,96,35)"/><text x="30.8506%" y="494.50">mpv_..</text></g><g><title>add_dct (mpegvideo.c:1894) (183 samples, 1.16%)</title><rect x="34.3006%" y="500" width="1.1594%" height="15" fill="rgb(253,215,40)"/><text x="34.5506%" y="510.50"></text></g><g><title>mpv_reconstruct_mb_internal (mpegvideo.c:2117) (355 samples, 2.25%)</title><rect x="34.2562%" y="484" width="2.2491%" height="15" fill="rgb(211,81,21)"/><text x="34.5062%" y="494.50">m..</text></g><g><title>mpv_reconstruct_mb_internal (mpegvideo.c:2248) (180 samples, 1.14%)</title><rect x="39.7935%" y="484" width="1.1404%" height="15" fill="rgb(208,190,38)"/><text x="40.0435%" y="494.50"></text></g><g><title>put_pixels16_8_c (pel_template.c:78) (168 samples, 1.06%)</title><rect x="39.8695%" y="500" width="1.0644%" height="15" fill="rgb(235,213,38)"/><text x="40.1195%" y="510.50"></text></g><g><title>put_pixels8_8_c (pel_template.c:78) (166 samples, 1.05%)</title><rect x="39.8822%" y="516" width="1.0517%" height="15" fill="rgb(237,122,38)"/><text x="40.1322%" y="526.50"></text></g><g><title>ff_mpv_reconstruct_mb (mpegvideo.c:2264) (3,788 samples, 24.00%)</title><rect x="17.1503%" y="468" width="23.9990%" height="15" fill="rgb(244,218,35)"/><text x="17.4003%" y="478.50">ff_mpv_reconstruct_mb (mpegvideo.c:226..</text></g><g><title>decode_slice (h263dec.c:309) (3,847 samples, 24.37%)</title><rect x="16.9665%" y="452" width="24.3728%" height="15" fill="rgb(240,68,47)"/><text x="17.2165%" y="462.50">decode_slice (h263dec.c:309)</text></g><g><title>ff_h263_decode_frame (h263dec.c:644) (5,131 samples, 32.51%)</title><rect x="8.8444%" y="436" width="32.5076%" height="15" fill="rgb(210,16,53)"/><text x="9.0944%" y="446.50">ff_h263_decode_frame (h263dec.c:644)</text></g><g><title>decode_simple_internal (decode.c:433) (5,253 samples, 33.28%)</title><rect x="8.3186%" y="420" width="33.2805%" height="15" fill="rgb(235,124,12)"/><text x="8.5686%" y="430.50">decode_simple_internal (decode.c:433)</text></g><g><title>decode_receive_frame_internal (decode.c:647) (5,259 samples, 33.32%)</title><rect x="8.2995%" y="388" width="33.3186%" height="15" fill="rgb(224,169,11)"/><text x="8.5495%" y="398.50">decode_receive_frame_internal (decode.c:647)</text></g><g><title>decode_simple_receive_frame (decode.c:629) (5,259 samples, 33.32%)</title><rect x="8.2995%" y="404" width="33.3186%" height="15" fill="rgb(250,166,2)"/><text x="8.5495%" y="414.50">decode_simple_receive_frame (decode.c:629)</text></g><g><title>ffmpeg::Stream::decodePacket (stream.cpp:145) (5,285 samples, 33.48%)</title><rect x="8.1538%" y="340" width="33.4833%" height="15" fill="rgb(242,216,29)"/><text x="8.4038%" y="350.50">ffmpeg::Stream::decodePacket (stream.cpp:145)</text></g><g><title>ffmpeg::Stream::analyzePacket (stream.cpp:99) (5,268 samples, 33.38%)</title><rect x="8.2615%" y="356" width="33.3756%" height="15" fill="rgb(230,116,27)"/><text x="8.5115%" y="366.50">ffmpeg::Stream::analyzePacket (stream.cpp:99)</text></g><g><title>avcodec_send_packet (decode.c:706) (5,263 samples, 33.34%)</title><rect x="8.2932%" y="372" width="33.3439%" height="15" fill="rgb(228,99,48)"/><text x="8.5432%" y="382.50">avcodec_send_packet (decode.c:706)</text></g><g><title>yuv2rgb_c_24_rgb (yuv2rgb.c:347) (241 samples, 1.53%)</title><rect x="42.0362%" y="420" width="1.5269%" height="15" fill="rgb(253,11,6)"/><text x="42.2862%" y="430.50"></text></g><g><title>yuv2rgb_c_24_rgb (yuv2rgb.c:348) (280 samples, 1.77%)</title><rect x="43.5631%" y="420" width="1.7739%" height="15" fill="rgb(247,143,39)"/><text x="43.8131%" y="430.50">y..</text></g><g><title>yuv2rgb_c_24_rgb (yuv2rgb.c:349) (294 samples, 1.86%)</title><rect x="45.3371%" y="420" width="1.8626%" height="15" fill="rgb(236,97,10)"/><text x="45.5871%" y="430.50">y..</text></g><g><title>yuv2rgb_c_24_rgb (yuv2rgb.c:351) (177 samples, 1.12%)</title><rect x="47.1997%" y="420" width="1.1214%" height="15" fill="rgb(233,208,19)"/><text x="47.4497%" y="430.50"></text></g><g><title>yuv2rgb_c_24_rgb (yuv2rgb.c:352) (336 samples, 2.13%)</title><rect x="48.3211%" y="420" width="2.1287%" height="15" fill="rgb(216,164,2)"/><text x="48.5711%" y="430.50">y..</text></g><g><title>yuv2rgb_c_24_rgb (yuv2rgb.c:353) (188 samples, 1.19%)</title><rect x="50.4498%" y="420" width="1.1911%" height="15" fill="rgb(220,129,5)"/><text x="50.6998%" y="430.50"></text></g><g><title>yuv2rgb_c_24_rgb (yuv2rgb.c:355) (212 samples, 1.34%)</title><rect x="51.6409%" y="420" width="1.3431%" height="15" fill="rgb(242,17,10)"/><text x="51.8909%" y="430.50"></text></g><g><title>yuv2rgb_c_24_rgb (yuv2rgb.c:356) (426 samples, 2.70%)</title><rect x="52.9840%" y="420" width="2.6989%" height="15" fill="rgb(242,107,0)"/><text x="53.2340%" y="430.50">yu..</text></g><g><title>yuv2rgb_c_24_rgb (yuv2rgb.c:359) (229 samples, 1.45%)</title><rect x="56.6270%" y="420" width="1.4508%" height="15" fill="rgb(251,28,31)"/><text x="56.8770%" y="430.50"></text></g><g><title>yuv2rgb_c_24_rgb (yuv2rgb.c:360) (321 samples, 2.03%)</title><rect x="58.0778%" y="420" width="2.0337%" height="15" fill="rgb(233,223,10)"/><text x="58.3278%" y="430.50">y..</text></g><g><title>yuv2rgb_c_24_rgb (yuv2rgb.c:361) (218 samples, 1.38%)</title><rect x="60.1115%" y="420" width="1.3811%" height="15" fill="rgb(215,21,27)"/><text x="60.3615%" y="430.50"></text></g><g><title>ffmpeg::VideoStream::copyFrameBytes (video_stream.cpp:115) (3,154 samples, 19.98%)</title><rect x="41.6561%" y="356" width="19.9823%" height="15" fill="rgb(232,23,21)"/><text x="41.9061%" y="366.50">ffmpeg::VideoStream::copyFrameB..</text></g><g><title>ffmpeg::VideoSampler::sample (video_sampler.cpp:182) (3,133 samples, 19.85%)</title><rect x="41.7892%" y="372" width="19.8492%" height="15" fill="rgb(244,5,23)"/><text x="42.0392%" y="382.50">ffmpeg::VideoSampler::sample (v..</text></g><g><title>transformImage (video_sampler.cpp:45) (3,133 samples, 19.85%)</title><rect x="41.7892%" y="388" width="19.8492%" height="15" fill="rgb(226,81,46)"/><text x="42.0392%" y="398.50">transformImage (video_sampler.c..</text></g><g><title>sws_scale (swscale.c:989) (3,124 samples, 19.79%)</title><rect x="41.8462%" y="404" width="19.7922%" height="15" fill="rgb(247,70,30)"/><text x="42.0962%" y="414.50">sws_scale (swscale.c:989)</text></g><g><title>ffmpeg::Decoder::processPacket (decoder.cpp:622) (8,457 samples, 53.58%)</title><rect x="8.1475%" y="324" width="53.5796%" height="15" fill="rgb(212,68,19)"/><text x="8.3975%" y="334.50">ffmpeg::Decoder::processPacket (decoder.cpp:622)</text></g><g><title>ffmpeg::Stream::decodePacket (stream.cpp:148) (3,171 samples, 20.09%)</title><rect x="41.6371%" y="340" width="20.0900%" height="15" fill="rgb(240,187,13)"/><text x="41.8871%" y="350.50">ffmpeg::Stream::decodePacket (st..</text></g><g><title>ffmpeg::Decoder::getFrame (decoder.cpp:536) (8,468 samples, 53.65%)</title><rect x="8.1412%" y="308" width="53.6493%" height="15" fill="rgb(223,113,26)"/><text x="8.3912%" y="318.50">ffmpeg::Decoder::getFrame (decoder.cpp:536)</text></g><g><title>ffmpeg::SyncDecoder::decode (sync_decoder.cpp:72) (8,713 samples, 55.20%)</title><rect x="7.5456%" y="292" width="55.2015%" height="15" fill="rgb(206,192,2)"/><text x="7.7956%" y="302.50">ffmpeg::SyncDecoder::decode (sync_decoder.cpp:72)</text></g><g><title>vision::video::Video::Next (video.cpp:276) (8,761 samples, 55.51%)</title><rect x="7.5329%" y="276" width="55.5056%" height="15" fill="rgb(241,108,4)"/><text x="7.7829%" y="286.50">vision::video::Video::Next (video.cpp:276)</text></g><g><title>futex_wake (futex.h:66) (264 samples, 1.67%)</title><rect x="64.4767%" y="628" width="1.6726%" height="15" fill="rgb(247,173,49)"/><text x="64.7267%" y="638.50"></text></g><g><title>do_spin (wait.h:56) (165 samples, 1.05%)</title><rect x="66.1556%" y="660" width="1.0454%" height="15" fill="rgb(224,114,35)"/><text x="66.4056%" y="670.50"></text></g><g><title>do_wait (wait.h:66) (208 samples, 1.32%)</title><rect x="66.1556%" y="644" width="1.3178%" height="15" fill="rgb(245,159,27)"/><text x="66.4056%" y="654.50"></text></g><g><title>GOMP_parallel (parallel.c:171) (588 samples, 3.73%)</title><rect x="63.8938%" y="596" width="3.7253%" height="15" fill="rgb(245,172,44)"/><text x="64.1438%" y="606.50">GOMP..</text></g><g><title>gomp_team_start (team.c:861) (496 samples, 3.14%)</title><rect x="64.4767%" y="612" width="3.1424%" height="15" fill="rgb(236,23,11)"/><text x="64.7267%" y="622.50">gom..</text></g><g><title>gomp_barrier_wait_end (bar.c:49) (231 samples, 1.46%)</title><rect x="66.1556%" y="628" width="1.4635%" height="15" fill="rgb(205,117,38)"/><text x="66.4056%" y="638.50"></text></g><g><title>do_spin (wait.h:56) (3,210 samples, 20.34%)</title><rect x="68.5948%" y="644" width="20.3371%" height="15" fill="rgb(237,72,25)"/><text x="68.8448%" y="654.50">do_spin (wait.h:56)</text></g><g><title>do_wait (wait.h:66) (4,034 samples, 25.56%)</title><rect x="68.5948%" y="628" width="25.5575%" height="15" fill="rgb(244,70,9)"/><text x="68.8448%" y="638.50">do_wait (wait.h:66)</text></g><g><title>do_spin (wait.h:57) (824 samples, 5.22%)</title><rect x="88.9318%" y="644" width="5.2205%" height="15" fill="rgb(217,125,39)"/><text x="89.1818%" y="654.50">do_spi..</text></g><g><title>gomp_team_end (team.c:935) (4,489 samples, 28.44%)</title><rect x="68.5631%" y="596" width="28.4402%" height="15" fill="rgb(235,36,10)"/><text x="68.8131%" y="606.50">gomp_team_end (team.c:935)</text></g><g><title>gomp_team_barrier_wait_end (bar.c:113) (4,485 samples, 28.41%)</title><rect x="68.5884%" y="612" width="28.4149%" height="15" fill="rgb(251,123,47)"/><text x="68.8384%" y="622.50">gomp_team_barrier_wait_end (bar.c:113)</text></g><g><title>do_wait (wait.h:67) (450 samples, 2.85%)</title><rect x="94.1523%" y="628" width="2.8510%" height="15" fill="rgb(221,13,13)"/><text x="94.4023%" y="638.50">do..</text></g><g><title>futex_wait (futex.h:44) (450 samples, 2.85%)</title><rect x="94.1523%" y="644" width="2.8510%" height="15" fill="rgb(238,131,9)"/><text x="94.4023%" y="654.50">fu..</text></g><g><title>at::native::fill_out (libtorch_cpu.so) (5,272 samples, 33.40%)</title><rect x="63.6341%" y="516" width="33.4009%" height="15" fill="rgb(211,50,8)"/><text x="63.8841%" y="526.50">at::native::fill_out (libtorch_cpu.so)</text></g><g><title>at::native::(anonymous namespace)::fill_kernel (libtorch_cpu.so) (5,242 samples, 33.21%)</title><rect x="63.8241%" y="532" width="33.2108%" height="15" fill="rgb(245,182,24)"/><text x="64.0741%" y="542.50">at::native::(anonymous namespace)::fill_kernel (libtor..</text></g><g><title>at::native::(anonymous namespace)::fill_kernel(at::TensorIterator&amp;, c10::Scalar)::{lambda()#1}::operator() const (libtorch_cpu.so) (5,241 samples, 33.20%)</title><rect x="63.8305%" y="548" width="33.2045%" height="15" fill="rgb(242,14,37)"/><text x="64.0805%" y="558.50">at::native::(anonymous namespace)::fill_kernel(at::Ten..</text></g><g><title>at::TensorIteratorBase::for_each (libtorch_cpu.so) (5,238 samples, 33.19%)</title><rect x="63.8495%" y="564" width="33.1855%" height="15" fill="rgb(246,228,12)"/><text x="64.0995%" y="574.50">at::TensorIteratorBase::for_each (libtorch_cpu.so)</text></g><g><title>at::TensorIteratorBase::for_each (libtorch_cpu.so) (5,238 samples, 33.19%)</title><rect x="63.8495%" y="580" width="33.1855%" height="15" fill="rgb(213,55,15)"/><text x="64.0995%" y="590.50">at::TensorIteratorBase::for_each (libtorch_cpu.so)</text></g><g><title>at::(anonymous namespace)::fill__Scalar (libtorch_cpu.so) (5,276 samples, 33.43%)</title><rect x="63.6214%" y="500" width="33.4263%" height="15" fill="rgb(209,9,3)"/><text x="63.8714%" y="510.50">at::(anonymous namespace)::fill__Scalar (libtorch_cpu...</text></g><g><title>at::native::zeros (libtorch_cpu.so) (5,355 samples, 33.93%)</title><rect x="63.1272%" y="436" width="33.9268%" height="15" fill="rgb(230,59,30)"/><text x="63.3772%" y="446.50">at::native::zeros (libtorch_cpu.so)</text></g><g><title>c10::Dispatcher::call&lt;at::Tensor&amp;, at::Tensor&amp;&gt; (libtorch_cpu.so) (5,281 samples, 33.46%)</title><rect x="63.5960%" y="452" width="33.4579%" height="15" fill="rgb(209,121,21)"/><text x="63.8460%" y="462.50">c10::Dispatcher::call&lt;at::Tensor&amp;, at::Tensor&amp;&gt; (libto..</text></g><g><title>at::native::zero_ (libtorch_cpu.so) (5,281 samples, 33.46%)</title><rect x="63.5960%" y="468" width="33.4579%" height="15" fill="rgb(220,109,13)"/><text x="63.8460%" y="478.50">at::native::zero_ (libtorch_cpu.so)</text></g><g><title>c10::Dispatcher::call&lt;at::Tensor&amp;, at::Tensor&amp;, c10::Scalar&gt; (libtorch_cpu.so) (5,278 samples, 33.44%)</title><rect x="63.6151%" y="484" width="33.4389%" height="15" fill="rgb(232,18,1)"/><text x="63.8651%" y="494.50">c10::Dispatcher::call&lt;at::Tensor&amp;, at::Tensor&amp;, c10::S..</text></g><g><title>at::zeros (libtorch_cpu.so) (5,370 samples, 34.02%)</title><rect x="63.0575%" y="372" width="34.0218%" height="15" fill="rgb(215,41,42)"/><text x="63.3075%" y="382.50">at::zeros (libtorch_cpu.so)</text></g><g><title>c10::Dispatcher::call&lt;at::Tensor, c10::ArrayRef&lt;long&gt;, c10::optional&lt;c10::ScalarType&gt;, c10::optional&lt;c10::Layout&gt;, c10::optional&lt;c10::Device&gt;, c10::optional&lt;bool&gt; &gt; (libtorch_cpu.so) (5,367 samples, 34.00%)</title><rect x="63.0765%" y="388" width="34.0028%" height="15" fill="rgb(224,123,36)"/><text x="63.3265%" y="398.50">c10::Dispatcher::call&lt;at::Tensor, c10::ArrayRef&lt;long&gt;, ..</text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::ArrayRef&lt;long&gt;, c10::optional&lt;c10::ScalarType&gt;, c10::optional&lt;c10::Layout&gt;, c10::optional&lt;c10::Device&gt;, c10::optional&lt;bool&gt;), &amp;at::(anonymous namespace)::zeros(c10::ArrayRef&lt;long&gt;, c10::optional&lt;c10::ScalarType&gt;, c10::optional&lt;c10::Layout&gt;, c10::optional&lt;c10::Device&gt;, c10::optional&lt;bool&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::ArrayRef&lt;long&gt;, c10::optional&lt;c10::ScalarType&gt;, c10::optional&lt;c10::Layout&gt;, c10::optional&lt;c10::Device&gt;, c10::optional&lt;bool&gt; &gt; &gt;, at::Tensor(c10::ArrayRef&lt;long&gt;, c10::optional&lt;c10::ScalarType&gt;, c10::optional&lt;c10::Layout&gt;, c10::optional&lt;c10::Device&gt;, c10::optional&lt;bool&gt;)&gt;::call (libtorch_cpu.so) (5,364 samples, 33.98%)</title><rect x="63.0955%" y="404" width="33.9838%" height="15" fill="rgb(240,125,3)"/><text x="63.3455%" y="414.50">c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::deta..</text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::ArrayRef&lt;long&gt;, c10::optional&lt;c10::ScalarType&gt;, c10::optional&lt;c10::Layout&gt;, c10::optional&lt;c10::Device&gt;, c10::optional&lt;bool&gt;), &amp;c10::impl::detail::with_scattered_tensor_options_impl_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::ArrayRef&lt;long&gt;, c10::TensorOptions const&amp;), &amp;at::(anonymous namespace)::zeros(c10::ArrayRef&lt;long&gt;, c10::TensorOptions const&amp;)&gt;, c10::guts::typelist::typelist&lt;c10::ArrayRef&lt;long&gt; &gt;, c10::guts::typelist::typelist&lt;&gt; &gt;::wrapper(c10::ArrayRef&lt;long&gt;, c10::optional&lt;c10::ScalarType&gt;, c10::optional&lt;c10::Layout&gt;, c10::optional&lt;c10::Device&gt;, c10::optional&lt;bool&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::ArrayRef&lt;long&gt;, c10::optional&lt;c10::ScalarType&gt;, c10::optional&lt;c10::Layout&gt;, c10::optional&lt;c10::Device&gt;, c10::optional&lt;bool&gt; &gt; &gt;, at::Tensor(c10::ArrayRef&lt;long&gt;, c10::optional&lt;c10::ScalarType&gt;, c10::optional&lt;c10::Layout&gt;, c10::optional&lt;c10::Device&gt;, c10::optional&lt;bool&gt;)&gt;::call (libtorch_cpu.so) (5,359 samples, 33.95%)</title><rect x="63.1272%" y="420" width="33.9521%" height="15" fill="rgb(205,98,50)"/><text x="63.3772%" y="430.50">c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::deta..</text></g><g><title>at::Tensor::operator= &amp; (TensorBody.h:207) (5,380 samples, 34.09%)</title><rect x="63.0512%" y="292" width="34.0851%" height="15" fill="rgb(205,185,37)"/><text x="63.3012%" y="302.50">at::Tensor::operator= &amp; (TensorBody.h:207)</text></g><g><title>c10::intrusive_ptr&lt;c10::TensorImpl, c10::UndefinedTensorImpl&gt;::operator= &amp; (intrusive_ptr.h:318) (5,380 samples, 34.09%)</title><rect x="63.0512%" y="308" width="34.0851%" height="15" fill="rgb(238,207,15)"/><text x="63.3012%" y="318.50">c10::intrusive_ptr&lt;c10::TensorImpl, c10::UndefinedTenso..</text></g><g><title>c10::intrusive_ptr&lt;c10::TensorImpl, c10::UndefinedTensorImpl&gt;::operator=&lt;c10::TensorImpl, c10::UndefinedTensorImpl&gt; &amp; (intrusive_ptr.h:328) (5,380 samples, 34.09%)</title><rect x="63.0512%" y="324" width="34.0851%" height="15" fill="rgb(213,199,42)"/><text x="63.3012%" y="334.50">c10::intrusive_ptr&lt;c10::TensorImpl, c10::UndefinedTenso..</text></g><g><title>c10::intrusive_ptr&lt;c10::TensorImpl, c10::UndefinedTensorImpl&gt;::swap (intrusive_ptr.h:367) (5,380 samples, 34.09%)</title><rect x="63.0512%" y="340" width="34.0851%" height="15" fill="rgb(235,201,11)"/><text x="63.3012%" y="350.50">c10::intrusive_ptr&lt;c10::TensorImpl, c10::UndefinedTenso..</text></g><g><title>torch::zeros (variable_factories.h:358) (5,380 samples, 34.09%)</title><rect x="63.0512%" y="356" width="34.0851%" height="15" fill="rgb(207,46,11)"/><text x="63.3012%" y="366.50">torch::zeros (variable_factories.h:358)</text></g><g><title>vision::video::Video::Next (video.cpp:293) (5,384 samples, 34.11%)</title><rect x="63.0512%" y="276" width="34.1105%" height="15" fill="rgb(241,35,35)"/><text x="63.3012%" y="286.50">vision::video::Video::Next (video.cpp:293)</text></g><g><title>vision::video::Video::Next (video.cpp:295) (332 samples, 2.10%)</title><rect x="97.1617%" y="276" width="2.1034%" height="15" fill="rgb(243,32,47)"/><text x="97.4117%" y="286.50">v..</text></g><g><title>torch::detail::BoxedProxy&lt;std::tuple&lt;at::Tensor, double&gt;, torch::detail::WrapMethod&lt;std::tuple&lt;at::Tensor, double&gt; (vision::video::Video::*)()&gt; &gt;::operator() (custom_class_detail.h:104) (14,490 samples, 91.80%)</title><rect x="7.4949%" y="212" width="91.8018%" height="15" fill="rgb(247,202,23)"/><text x="7.7449%" y="222.50">torch::detail::BoxedProxy&lt;std::tuple&lt;at::Tensor, double&gt;, torch::detail::WrapMethod&lt;std::tuple&lt;at::Tensor, double&gt; (vision::video::Video::*)()&gt; &gt;::operat..</text></g><g><title>torch::detail::call_torchbind_method_from_stack&lt;torch::detail::WrapMethod&lt;std::tuple&lt;at::Tensor, double&gt; (vision::video::Video::*)()&gt;, false&gt; (custom_class_detail.h:95) (14,490 samples, 91.80%)</title><rect x="7.4949%" y="228" width="91.8018%" height="15" fill="rgb(219,102,11)"/><text x="7.7449%" y="238.50">torch::detail::call_torchbind_method_from_stack&lt;torch::detail::WrapMethod&lt;std::tuple&lt;at::Tensor, double&gt; (vision::video::Video::*)()&gt;, false&gt; (custom_cla..</text></g><g><title>torch::detail::call_torchbind_method_from_stack&lt;torch::detail::WrapMethod&lt;std::tuple&lt;at::Tensor, double&gt; (vision::video::Video::*)()&gt;, false, (unsigned long)0&gt; (custom_class_detail.h:86) (14,490 samples, 91.80%)</title><rect x="7.4949%" y="244" width="91.8018%" height="15" fill="rgb(243,110,44)"/><text x="7.7449%" y="254.50">torch::detail::call_torchbind_method_from_stack&lt;torch::detail::WrapMethod&lt;std::tuple&lt;at::Tensor, double&gt; (vision::video::Video::*)()&gt;, false, (unsigned l..</text></g><g><title>c10::intrusive_ptr&lt;vision::video::Video, c10::detail::intrusive_target_default_null_type&lt;vision::video::Video&gt; &gt;::~intrusive_ptr (intrusive_ptr.h:314) (14,486 samples, 91.78%)</title><rect x="7.5203%" y="260" width="91.7765%" height="15" fill="rgb(222,74,54)"/><text x="7.7703%" y="270.50">c10::intrusive_ptr&lt;vision::video::Video, c10::detail::intrusive_target_default_null_type&lt;vision::video::Video&gt; &gt;::~intrusive_ptr (intrusive_ptr.h:314)</text></g><g><title>std::_Function_handler&lt;void (std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;), torch::class_&lt;vision::video::Video&gt;::defineMethod&lt;torch::detail::WrapMethod&lt;std::tuple&lt;at::Tensor, double&gt; (vision::video::Video::*)()&gt; &gt;(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, torch::detail::WrapMethod&lt;std::tuple&lt;at::Tensor, double&gt; (vision::video::Video::*)()&gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)::{lambda(std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;)#1}&gt;::_M_invoke (std_function.h:316) (14,493 samples, 91.82%)</title><rect x="7.4949%" y="180" width="91.8208%" height="15" fill="rgb(216,99,12)"/><text x="7.7449%" y="190.50">std::_Function_handler&lt;void (std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;), torch::class_&lt;vision::video::Video&gt;::defineMethod&lt;torch::detail::W..</text></g><g><title>torch::class_&lt;vision::video::Video&gt;::defineMethod&lt;torch::detail::WrapMethod&lt;std::tuple&lt;at::Tensor, double&gt; (vision::video::Video::*)()&gt; &gt;(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, torch::detail::WrapMethod&lt;std::tuple&lt;at::Tensor, double&gt; (vision::video::Video::*)()&gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)::{lambda(std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;)#1}::operator() (custom_class.h:276) (14,493 samples, 91.82%)</title><rect x="7.4949%" y="196" width="91.8208%" height="15" fill="rgb(226,22,26)"/><text x="7.7449%" y="206.50">torch::class_&lt;vision::video::Video&gt;::defineMethod&lt;torch::detail::WrapMethod&lt;std::tuple&lt;at::Tensor, double&gt; (vision::video::Video::*)()&gt; &gt;(std::__cxx11::b..</text></g><g><title>pybind11::cpp_function::initialize&lt;torch::jit::initJitScriptBindings(_object*)::{lambda(pybind11::args, pybind11::kwargs)#50}, pybind11::object, pybind11::args, pybind11::kwargs, pybind11::name, pybind11::is_method, pybind11::sibling&gt;(torch::jit::initJitScriptBindings(_object*)::{lambda(pybind11::args&amp;&amp;, pybind11::kwargs)#50}, pybind11::object (*)(pybind11::args, pybind11::kwargs), pybind11::name const, pybind11::is_method&amp;, pybind11::sibling)::{lambda(pybind11::detail::function_call&amp;)#3}::_FUN (libtorch_python.so) (14,542 samples, 92.13%)</title><rect x="7.4506%" y="116" width="92.1313%" height="15" fill="rgb(217,163,10)"/><text x="7.7006%" y="126.50">pybind11::cpp_function::initialize&lt;torch::jit::initJitScriptBindings(_object*)::{lambda(pybind11::args, pybind11::kwargs)#50}, pybind11::object, pybind11:..</text></g><g><title>torch::jit::initJitScriptBindings(_object*)::{lambda(pybind11::args, pybind11::kwargs)#50}::operator() const (libtorch_python.so) (14,542 samples, 92.13%)</title><rect x="7.4506%" y="132" width="92.1313%" height="15" fill="rgb(213,25,53)"/><text x="7.7006%" y="142.50">torch::jit::initJitScriptBindings(_object*)::{lambda(pybind11::args, pybind11::kwargs)#50}::operator() const (libtorch_python.so)</text></g><g><title>torch::jit::invokeScriptMethodFromPython (libtorch_python.so) (14,541 samples, 92.12%)</title><rect x="7.4569%" y="148" width="92.1249%" height="15" fill="rgb(252,105,26)"/><text x="7.7069%" y="158.50">torch::jit::invokeScriptMethodFromPython (libtorch_python.so)</text></g><g><title>torch::jit::runAndInsertCall (libtorch_python.so) (14,540 samples, 92.12%)</title><rect x="7.4633%" y="164" width="92.1186%" height="15" fill="rgb(220,39,43)"/><text x="7.7133%" y="174.50">torch::jit::runAndInsertCall (libtorch_python.so)</text></g><g><title>pybind11::cpp_function::dispatcher (libtorch_python.so) (14,585 samples, 92.40%)</title><rect x="7.4126%" y="100" width="92.4037%" height="15" fill="rgb(229,68,48)"/><text x="7.6626%" y="110.50">pybind11::cpp_function::dispatcher (libtorch_python.so)</text></g><g><title>__next__ (torchvision/io/__init__.py:123) (14,617 samples, 92.61%)</title><rect x="7.2795%" y="84" width="92.6064%" height="15" fill="rgb(252,8,32)"/><text x="7.5295%" y="94.50">__next__ (torchvision/io/__init__.py:123)</text></g><g><title>&lt;module&gt; (PV_ratrace_newAPI.py:8) (14,645 samples, 92.78%)</title><rect x="7.1845%" y="68" width="92.7838%" height="15" fill="rgb(223,20,43)"/><text x="7.4345%" y="78.50">&lt;module&gt; (PV_ratrace_newAPI.py:8)</text></g><g><title>all (15,784 samples, 100%)</title><rect x="0.0000%" y="52" width="100.0000%" height="15" fill="rgb(229,81,49)"/><text x="0.2500%" y="62.50"></text></g></svg></svg>