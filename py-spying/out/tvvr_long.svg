<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg version="1.1" width="1200" height="902" onload="init(evt)" viewBox="0 0 1200 902" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><!--Flame graph stack visualization. See https://github.com/brendangregg/FlameGraph for latest version, and http://www.brendangregg.com/flamegraphs.html for examples.--><!--NOTES: --><defs><linearGradient id="background" y1="0" y2="1" x1="0" x2="0"><stop stop-color="#eeeeee" offset="5%"/><stop stop-color="#eeeeb0" offset="95%"/></linearGradient></defs><style type="text/css">
text { font-family:"Verdana"; font-size:12px; fill:rgb(0,0,0); }
#title { text-anchor:middle; font-size:17px; }
#search { opacity:0.1; cursor:pointer; }
#search:hover, #search.show { opacity:1; }
#subtitle { text-anchor:middle; font-color:rgb(160,160,160); }
#unzoom { cursor:pointer; }
#frames > *:hover { stroke:black; stroke-width:0.5; cursor:pointer; }
.hide { display:none; }
.parent { opacity:0.5; }
</style><script type="text/ecmascript"><![CDATA[var nametype = 'Function:';
var fontsize = 12;
var fontwidth = 0.59;
var xpad = 10;
var inverted = true;
var searchcolor = 'rgb(230,0,230)';
var fluiddrawing = true;
var truncate_text_right = false;]]><![CDATA["use strict";
var details, searchbtn, unzoombtn, matchedtxt, svg, searching, frames;
function init(evt) {
    details = document.getElementById("details").firstChild;
    searchbtn = document.getElementById("search");
    unzoombtn = document.getElementById("unzoom");
    matchedtxt = document.getElementById("matched");
    svg = document.getElementsByTagName("svg")[0];
    frames = document.getElementById("frames");
    searching = 0;

    // Use GET parameters to restore a flamegraph's state.
    var restore_state = function() {
        var params = get_params();
        if (params.x && params.y)
            zoom(find_group(document.querySelector('[x="' + params.x + '"][y="' + params.y + '"]')));
        if (params.s)
            search(params.s);
    };

    if (fluiddrawing) {
        // Make width dynamic so the SVG fits its parent's width.
        svg.removeAttribute("width");
        // Edge requires us to have a viewBox that gets updated with size changes.
        var isEdge = /Edge\/\d./i.test(navigator.userAgent);
        if (!isEdge) {
          svg.removeAttribute("viewBox");
        }
        var update_for_width_change = function() {
            if (isEdge) {
                svg.attributes.viewBox.value = "0 0 " + svg.width.baseVal.value + " " + svg.height.baseVal.value;
            }

            // Keep consistent padding on left and right of frames container.
            frames.attributes.width.value = svg.width.baseVal.value - xpad * 2;

            // Text truncation needs to be adjusted for the current width.
            var el = frames.children;
            for(var i = 0; i < el.length; i++) {
                update_text(el[i]);
            }

            // Keep search elements at a fixed distance from right edge.
            var svgWidth = svg.width.baseVal.value;
            searchbtn.attributes.x.value = svgWidth - xpad - 100;
            matchedtxt.attributes.x.value = svgWidth - xpad - 100;
        };
        window.addEventListener('resize', function() {
            update_for_width_change();
        });
        // This needs to be done asynchronously for Safari to work.
        setTimeout(function() {
            unzoom();
            update_for_width_change();
            restore_state();
        }, 0);
    } else {
        restore_state();
    }
}
// event listeners
window.addEventListener("click", function(e) {
    var target = find_group(e.target);
    if (target) {
        if (target.nodeName == "a") {
            if (e.ctrlKey === false) return;
            e.preventDefault();
        }
        if (target.classList.contains("parent")) unzoom();
        zoom(target);

        // set parameters for zoom state
        var el = target.querySelector("rect");
        if (el && el.attributes && el.attributes.y && el.attributes._orig_x) {
            var params = get_params()
            params.x = el.attributes._orig_x.value;
            params.y = el.attributes.y.value;
            history.replaceState(null, null, parse_params(params));
        }
    }
    else if (e.target.id == "unzoom") {
        unzoom();

        // remove zoom state
        var params = get_params();
        if (params.x) delete params.x;
        if (params.y) delete params.y;
        history.replaceState(null, null, parse_params(params));
    }
    else if (e.target.id == "search") search_prompt();
}, false)
// mouse-over for info
// show
window.addEventListener("mouseover", function(e) {
    var target = find_group(e.target);
    if (target) details.nodeValue = nametype + " " + g_to_text(target);
}, false)
// clear
window.addEventListener("mouseout", function(e) {
    var target = find_group(e.target);
    if (target) details.nodeValue = ' ';
}, false)
// ctrl-F for search
window.addEventListener("keydown",function (e) {
    if (e.keyCode === 114 || (e.ctrlKey && e.keyCode === 70)) {
        e.preventDefault();
        search_prompt();
    }
}, false)
// functions
function get_params() {
    var params = {};
    var paramsarr = window.location.search.substr(1).split('&');
    for (var i = 0; i < paramsarr.length; ++i) {
        var tmp = paramsarr[i].split("=");
        if (!tmp[0] || !tmp[1]) continue;
        params[tmp[0]]  = decodeURIComponent(tmp[1]);
    }
    return params;
}
function parse_params(params) {
    var uri = "?";
    for (var key in params) {
        uri += key + '=' + encodeURIComponent(params[key]) + '&';
    }
    if (uri.slice(-1) == "&")
        uri = uri.substring(0, uri.length - 1);
    if (uri == '?')
        uri = window.location.href.split('?')[0];
    return uri;
}
function find_child(node, selector) {
    var children = node.querySelectorAll(selector);
    if (children.length) return children[0];
    return;
}
function find_group(node) {
    var parent = node.parentElement;
    if (!parent) return;
    if (parent.id == "frames") return node;
    return find_group(parent);
}
function orig_save(e, attr, val) {
    if (e.attributes["_orig_" + attr] != undefined) return;
    if (e.attributes[attr] == undefined) return;
    if (val == undefined) val = e.attributes[attr].value;
    e.setAttribute("_orig_" + attr, val);
}
function orig_load(e, attr) {
    if (e.attributes["_orig_"+attr] == undefined) return;
    e.attributes[attr].value = e.attributes["_orig_" + attr].value;
    e.removeAttribute("_orig_" + attr);
}
function g_to_text(e) {
    var text = find_child(e, "title").firstChild.nodeValue;
    return (text)
}
function g_to_func(e) {
    var func = g_to_text(e);
    // if there's any manipulation we want to do to the function
    // name before it's searched, do it here before returning.
    return (func);
}
function update_text(e) {
    var r = find_child(e, "rect");
    var t = find_child(e, "text");
    var w = parseFloat(r.attributes.width.value) * frames.attributes.width.value / 100 - 3;
    var txt = find_child(e, "title").textContent.replace(/\([^(]*\)$/,"");
    t.attributes.x.value = format_percent((parseFloat(r.attributes.x.value) + (100 * 3 / frames.attributes.width.value)));
    // Smaller than this size won't fit anything
    if (w < 2 * fontsize * fontwidth) {
        t.textContent = "";
        return;
    }
    t.textContent = txt;
    // Fit in full text width
    if (/^ *\$/.test(txt) || t.getComputedTextLength() < w)
        return;
    if (truncate_text_right) {
        // Truncate the right side of the text.
        for (var x = txt.length - 2; x > 0; x--) {
            if (t.getSubStringLength(0, x + 2) <= w) {
                t.textContent = txt.substring(0, x) + "..";
                return;
            }
        }
    } else {
        // Truncate the left side of the text.
        for (var x = 2; x < txt.length; x++) {
            if (t.getSubStringLength(x - 2, txt.length) <= w) {
                t.textContent = ".." + txt.substring(x, txt.length);
                return;
            }
        }
    }
    t.textContent = "";
}
// zoom
function zoom_reset(e) {
    if (e.attributes != undefined) {
        orig_load(e, "x");
        orig_load(e, "width");
    }
    if (e.childNodes == undefined) return;
    for(var i = 0, c = e.childNodes; i < c.length; i++) {
        zoom_reset(c[i]);
    }
}
function zoom_child(e, x, ratio) {
    if (e.attributes != undefined) {
        if (e.attributes.x != undefined) {
            orig_save(e, "x");
            e.attributes.x.value = format_percent((parseFloat(e.attributes.x.value) - x) * ratio);
            if (e.tagName == "text") {
                e.attributes.x.value = format_percent(parseFloat(find_child(e.parentNode, "rect[x]").attributes.x.value) + (100 * 3 / frames.attributes.width.value));
            }
        }
        if (e.attributes.width != undefined) {
            orig_save(e, "width");
            e.attributes.width.value = format_percent(parseFloat(e.attributes.width.value) * ratio);
        }
    }
    if (e.childNodes == undefined) return;
    for(var i = 0, c = e.childNodes; i < c.length; i++) {
        zoom_child(c[i], x, ratio);
    }
}
function zoom_parent(e) {
    if (e.attributes) {
        if (e.attributes.x != undefined) {
            orig_save(e, "x");
            e.attributes.x.value = "0.0%";
        }
        if (e.attributes.width != undefined) {
            orig_save(e, "width");
            e.attributes.width.value = "100.0%";
        }
    }
    if (e.childNodes == undefined) return;
    for(var i = 0, c = e.childNodes; i < c.length; i++) {
        zoom_parent(c[i]);
    }
}
function zoom(node) {
    var attr = find_child(node, "rect").attributes;
    var width = parseFloat(attr.width.value);
    var xmin = parseFloat(attr.x.value);
    var xmax = xmin + width;
    var ymin = parseFloat(attr.y.value);
    var ratio = 100 / width;
    // XXX: Workaround for JavaScript float issues (fix me)
    var fudge = 0.001;
    unzoombtn.classList.remove("hide");
    var el = frames.children;
    for (var i = 0; i < el.length; i++) {
        var e = el[i];
        var a = find_child(e, "rect").attributes;
        var ex = parseFloat(a.x.value);
        var ew = parseFloat(a.width.value);
        // Is it an ancestor
        if (!inverted) {
            var upstack = parseFloat(a.y.value) > ymin;
        } else {
            var upstack = parseFloat(a.y.value) < ymin;
        }
        if (upstack) {
            // Direct ancestor
            if (ex <= xmin && (ex+ew+fudge) >= xmax) {
                e.classList.add("parent");
                zoom_parent(e);
                update_text(e);
            }
            // not in current path
            else
                e.classList.add("hide");
        }
        // Children maybe
        else {
            // no common path
            if (ex < xmin || ex + fudge >= xmax) {
                e.classList.add("hide");
            }
            else {
                zoom_child(e, xmin, ratio);
                update_text(e);
            }
        }
    }
}
function unzoom() {
    unzoombtn.classList.add("hide");
    var el = frames.children;
    for(var i = 0; i < el.length; i++) {
        el[i].classList.remove("parent");
        el[i].classList.remove("hide");
        zoom_reset(el[i]);
        update_text(el[i]);
    }
}
// search
function reset_search() {
    var el = document.querySelectorAll("#frames rect");
    for (var i = 0; i < el.length; i++) {
        orig_load(el[i], "fill")
    }
    var params = get_params();
    delete params.s;
    history.replaceState(null, null, parse_params(params));
}
function search_prompt() {
    if (!searching) {
        var term = prompt("Enter a search term (regexp " +
            "allowed, eg: ^ext4_)", "");
        if (term != null) {
            search(term)
        }
    } else {
        reset_search();
        searching = 0;
        searchbtn.classList.remove("show");
        searchbtn.firstChild.nodeValue = "Search"
        matchedtxt.classList.add("hide");
        matchedtxt.firstChild.nodeValue = ""
    }
}
function search(term) {
    var re = new RegExp(term);
    var el = frames.children;
    var matches = new Object();
    var maxwidth = 0;
    for (var i = 0; i < el.length; i++) {
        var e = el[i];
        var func = g_to_func(e);
        var rect = find_child(e, "rect");
        if (func == null || rect == null)
            continue;
        // Save max width. Only works as we have a root frame
        var w = parseFloat(rect.attributes.width.value);
        if (w > maxwidth)
            maxwidth = w;
        if (func.match(re)) {
            // highlight
            var x = parseFloat(rect.attributes.x.value);
            orig_save(rect, "fill");
            rect.attributes.fill.value = searchcolor;
            // remember matches
            if (matches[x] == undefined) {
                matches[x] = w;
            } else {
                if (w > matches[x]) {
                    // overwrite with parent
                    matches[x] = w;
                }
            }
            searching = 1;
        }
    }
    if (!searching)
        return;
    var params = get_params();
    params.s = term;
    history.replaceState(null, null, parse_params(params));

    searchbtn.classList.add("show");
    searchbtn.firstChild.nodeValue = "Reset Search";
    // calculate percent matched, excluding vertical overlap
    var count = 0;
    var lastx = -1;
    var lastw = 0;
    var keys = Array();
    for (k in matches) {
        if (matches.hasOwnProperty(k))
            keys.push(k);
    }
    // sort the matched frames by their x location
    // ascending, then width descending
    keys.sort(function(a, b){
        return a - b;
    });
    // Step through frames saving only the biggest bottom-up frames
    // thanks to the sort order. This relies on the tree property
    // where children are always smaller than their parents.
    var fudge = 0.0001;    // JavaScript floating point
    for (var k in keys) {
        var x = parseFloat(keys[k]);
        var w = matches[keys[k]];
        if (x >= lastx + lastw - fudge) {
            count += w;
            lastx = x;
            lastw = w;
        }
    }
    // display matched percent
    matchedtxt.classList.remove("hide");
    var pct = 100 * count / maxwidth;
    if (pct != 100) pct = pct.toFixed(1);
    matchedtxt.firstChild.nodeValue = "Matched: " + pct + "%";
}
function format_percent(n) {
    return n.toFixed(4) + "%";
}
]]></script><rect x="0" y="0" width="100%" height="902" fill="url(#background)"/><text id="title" x="50.0000%" y="24.00">py-spy</text><text id="details" x="10" y="885.00"> </text><text id="unzoom" class="hide" x="10" y="24.00">Reset Zoom</text><text id="search" x="1090" y="24.00">Search</text><text id="matched" x="1090" y="885.00"> </text><svg id="frames" x="10" width="1180"><g><title>c10::TensorImpl::release_resources (libc10.so) (204 samples, 1.45%)</title><rect x="0.5184%" y="100" width="1.4486%" height="15" fill="rgb(227,0,7)"/><text x="0.7684%" y="110.50"></text></g><g><title>cfree (libc-2.27.so) (204 samples, 1.45%)</title><rect x="0.5184%" y="116" width="1.4486%" height="15" fill="rgb(217,0,24)"/><text x="0.7684%" y="126.50"></text></g><g><title>munmap (libc-2.27.so) (204 samples, 1.45%)</title><rect x="0.5184%" y="132" width="1.4486%" height="15" fill="rgb(221,193,54)"/><text x="0.7684%" y="142.50"></text></g><g><title>THPVariable_dealloc (libtorch_python.so) (205 samples, 1.46%)</title><rect x="0.5184%" y="68" width="1.4557%" height="15" fill="rgb(248,212,6)"/><text x="0.7684%" y="78.50"></text></g><g><title>THPVariable_clear (libtorch_python.so) (205 samples, 1.46%)</title><rect x="0.5184%" y="84" width="1.4557%" height="15" fill="rgb(208,68,35)"/><text x="0.7684%" y="94.50"></text></g><g><title>ffmpeg::Decoder::init (decoder.cpp:333) (176 samples, 1.25%)</title><rect x="2.1373%" y="388" width="1.2497%" height="15" fill="rgb(232,128,0)"/><text x="2.3873%" y="398.50"></text></g><g><title>avformat_open_input (libavformat.so.58.29.100) (176 samples, 1.25%)</title><rect x="2.1373%" y="404" width="1.2497%" height="15" fill="rgb(207,160,47)"/><text x="2.3873%" y="414.50"></text></g><g><title>ffmpeg::Decoder::init (decoder.cpp:354) (191 samples, 1.36%)</title><rect x="3.3871%" y="388" width="1.3562%" height="15" fill="rgb(228,23,34)"/><text x="3.6371%" y="398.50"></text></g><g><title>avformat_find_stream_info (libavformat.so.58.29.100) (191 samples, 1.36%)</title><rect x="3.3871%" y="404" width="1.3562%" height="15" fill="rgb(218,30,26)"/><text x="3.6371%" y="414.50"></text></g><g><title>video_reader::probeVideo (VideoReader.cpp:559) (393 samples, 2.79%)</title><rect x="2.1231%" y="372" width="2.7906%" height="15" fill="rgb(220,122,19)"/><text x="2.3731%" y="382.50">vi..</text></g><g><title>video_reader::probeVideoFromFile (VideoReader.cpp:667) (410 samples, 2.91%)</title><rect x="2.1231%" y="324" width="2.9113%" height="15" fill="rgb(250,228,42)"/><text x="2.3731%" y="334.50">vi..</text></g><g><title>std::string::~string (basic_string.h:3630) (410 samples, 2.91%)</title><rect x="2.1231%" y="340" width="2.9113%" height="15" fill="rgb(240,193,28)"/><text x="2.3731%" y="350.50">st..</text></g><g><title>std::string::_M_rep (basic_string.h:3312) (410 samples, 2.91%)</title><rect x="2.1231%" y="356" width="2.9113%" height="15" fill="rgb(216,20,37)"/><text x="2.3731%" y="366.50">st..</text></g><g><title>torch::jit::(anonymous namespace)::createOperatorFromC10_withTracingHandledHere(c10::OperatorHandle const&amp;)::{lambda(std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)#1}::operator() const (libtorch_cpu.so) (413 samples, 2.93%)</title><rect x="2.1089%" y="164" width="2.9326%" height="15" fill="rgb(206,188,39)"/><text x="2.3589%" y="174.50">to..</text></g><g><title>c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string&gt; &gt;, true&gt;::call (make_boxed_from_unboxed_functor.h:292) (413 samples, 2.93%)</title><rect x="2.1089%" y="180" width="2.9326%" height="15" fill="rgb(217,207,13)"/><text x="2.3589%" y="190.50">c1..</text></g><g><title>c10::guts::if_constexpr&lt;true, c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string&gt; &gt;, true&gt;::call(c10::OperatorKernel*, c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)::{lambda(auto:1)#1}, c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string&gt; &gt;, true&gt;::call(c10::OperatorKernel*, c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)::{lambda()#2}&gt; (C++17.h:282) (413 samples, 2.93%)</title><rect x="2.1089%" y="196" width="2.9326%" height="15" fill="rgb(231,73,38)"/><text x="2.3589%" y="206.50">c1..</text></g><g><title>c10::guts::detail::_if_constexpr&lt;true&gt;::call&lt;c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string&gt; &gt;, true&gt;::call(c10::OperatorKernel*, c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)::{lambda(auto:1)#1}, c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string&gt; &gt;, true&gt;::call(c10::OperatorKernel*, c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)::{lambda()#2}, (void*)0&gt; (C++17.h:193) (413 samples, 2.93%)</title><rect x="2.1089%" y="212" width="2.9326%" height="15" fill="rgb(225,20,46)"/><text x="2.3589%" y="222.50">c1..</text></g><g><title>c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string&gt; &gt;, true&gt;::call(c10::OperatorKernel*, c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)::{lambda(auto:1)#1}::operator()&lt;c10::guts::detail::_identity&gt; const (make_boxed_from_unboxed_functor.h:293) (413 samples, 2.93%)</title><rect x="2.1089%" y="228" width="2.9326%" height="15" fill="rgb(210,31,41)"/><text x="2.3589%" y="238.50">c1..</text></g><g><title>c10::impl::call_functor_with_args_from_stack&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string&gt; &gt;, true&gt; (make_boxed_from_unboxed_functor.h:255) (413 samples, 2.93%)</title><rect x="2.1089%" y="244" width="2.9326%" height="15" fill="rgb(221,200,47)"/><text x="2.3589%" y="254.50">c1..</text></g><g><title>c10::impl::call_functor_with_args_from_stack_&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string&gt; &gt;, true, (unsigned long)0&gt; (make_boxed_from_unboxed_functor.h:249) (413 samples, 2.93%)</title><rect x="2.1089%" y="260" width="2.9326%" height="15" fill="rgb(226,26,5)"/><text x="2.3589%" y="270.50">c1..</text></g><g><title>c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string&gt; &gt;::operator() (WrapFunctionIntoRuntimeFunctor.h:18) (413 samples, 2.93%)</title><rect x="2.1089%" y="276" width="2.9326%" height="15" fill="rgb(249,33,26)"/><text x="2.3589%" y="286.50">c1..</text></g><g><title>std::string::~string (basic_string.h:3630) (412 samples, 2.93%)</title><rect x="2.1160%" y="292" width="2.9255%" height="15" fill="rgb(235,183,28)"/><text x="2.3660%" y="302.50">st..</text></g><g><title>std::string::_M_rep (basic_string.h:3312) (412 samples, 2.93%)</title><rect x="2.1160%" y="308" width="2.9255%" height="15" fill="rgb(221,5,38)"/><text x="2.3660%" y="318.50">st..</text></g><g><title>_probe_video_from_file (torchvision/io/_video_opt.py:295) (431 samples, 3.06%)</title><rect x="1.9953%" y="100" width="3.0604%" height="15" fill="rgb(247,18,42)"/><text x="2.2453%" y="110.50">_pr..</text></g><g><title>pybind11::cpp_function::dispatcher (libtorch_python.so) (417 samples, 2.96%)</title><rect x="2.0947%" y="116" width="2.9610%" height="15" fill="rgb(241,131,45)"/><text x="2.3447%" y="126.50">pyb..</text></g><g><title>void pybind11::cpp_function::initialize&lt;torch::jit::initJITBindings(_object*)::{lambda(std::string const&amp;)#93}::operator()(std::string const&amp;) const::{lambda(pybind11::args, pybind11::kwargs)#1}, pybind11::object, pybind11::args, pybind11::kwargs, pybind11::name, pybind11::doc&gt;(torch::jit::initJITBindings(_object*)::{lambda(std::string const&amp;)#93}::operator()(std::string const&amp;) const::{lambda(pybind11::args&amp;&amp;, pybind11::kwargs)#1}, pybind11::object (*)(pybind11::args, pybind11::kwargs), pybind11::name const, pybind11::doc&amp;)::{lambda(pybind11::detail::function_call&amp;)#3}::_FUN (libtorch_python.so) (416 samples, 2.95%)</title><rect x="2.1018%" y="132" width="2.9539%" height="15" fill="rgb(249,31,29)"/><text x="2.3518%" y="142.50">voi..</text></g><g><title>torch::jit::invokeOperatorFromPython (libtorch_python.so) (415 samples, 2.95%)</title><rect x="2.1089%" y="148" width="2.9468%" height="15" fill="rgb(225,111,53)"/><text x="2.3589%" y="158.50">to..</text></g><g><title>_read_video (torchvision/io/_video_opt.py:483) (448 samples, 3.18%)</title><rect x="1.9882%" y="84" width="3.1811%" height="15" fill="rgb(238,160,17)"/><text x="2.2382%" y="94.50">_re..</text></g><g><title>video_reader::readVideo (VideoReader.cpp:262) (185 samples, 1.31%)</title><rect x="22.2254%" y="404" width="1.3136%" height="15" fill="rgb(214,148,48)"/><text x="22.4754%" y="414.50"></text></g><g><title>ffmpeg::Decoder::getFrame (decoder.cpp:487) (157 samples, 1.11%)</title><rect x="24.0290%" y="436" width="1.1148%" height="15" fill="rgb(232,36,49)"/><text x="24.2790%" y="446.50"></text></g><g><title>av_read_frame (libavformat.so.58.29.100) (157 samples, 1.11%)</title><rect x="24.0290%" y="452" width="1.1148%" height="15" fill="rgb(209,103,24)"/><text x="24.2790%" y="462.50"></text></g><g><title>0x7f7d9854e00a (libavcodec.so.58.54.100) (508 samples, 3.61%)</title><rect x="27.3024%" y="548" width="3.6072%" height="15" fill="rgb(229,88,8)"/><text x="27.5524%" y="558.50">0x7f..</text></g><g><title>0x7f7d9854e039 (libavcodec.so.58.54.100) (201 samples, 1.43%)</title><rect x="31.0729%" y="548" width="1.4273%" height="15" fill="rgb(213,181,19)"/><text x="31.3229%" y="558.50"></text></g><g><title>0x7f7d9854ee5a (libavcodec.so.58.54.100) (764 samples, 5.42%)</title><rect x="27.1249%" y="532" width="5.4250%" height="15" fill="rgb(254,191,54)"/><text x="27.3749%" y="542.50">0x7f7d9..</text></g><g><title>0x7f7d9855473a (libavcodec.so.58.54.100) (227 samples, 1.61%)</title><rect x="36.0719%" y="580" width="1.6119%" height="15" fill="rgb(241,83,37)"/><text x="36.3219%" y="590.50"></text></g><g><title>0x7f7d9855691d (libavcodec.so.58.54.100) (771 samples, 5.47%)</title><rect x="43.5419%" y="580" width="5.4747%" height="15" fill="rgb(233,36,39)"/><text x="43.7919%" y="590.50">0x7f7d9..</text></g><g><title>0x7f7d9855a63c (libavcodec.so.58.54.100) (151 samples, 1.07%)</title><rect x="54.0581%" y="580" width="1.0722%" height="15" fill="rgb(226,3,54)"/><text x="54.3081%" y="590.50"></text></g><g><title>0x7f7d9855a6b7 (libavcodec.so.58.54.100) (157 samples, 1.11%)</title><rect x="56.1599%" y="580" width="1.1148%" height="15" fill="rgb(245,192,40)"/><text x="56.4099%" y="590.50"></text></g><g><title>0x7f7d9855a6fd (libavcodec.so.58.54.100) (158 samples, 1.12%)</title><rect x="57.2818%" y="580" width="1.1219%" height="15" fill="rgb(238,167,29)"/><text x="57.5318%" y="590.50"></text></g><g><title>0x7f7d985a1490 (libavcodec.so.58.54.100) (3,743 samples, 26.58%)</title><rect x="34.2044%" y="564" width="26.5781%" height="15" fill="rgb(232,182,51)"/><text x="34.4544%" y="574.50">0x7f7d985a1490 (libavcodec.so.58.54.100)</text></g><g><title>0x7f7d98584299 (libavcodec.so.58.54.100) (185 samples, 1.31%)</title><rect x="63.4808%" y="580" width="1.3136%" height="15" fill="rgb(231,60,39)"/><text x="63.7308%" y="590.50"></text></g><g><title>0x7f7d985a17ac (libavcodec.so.58.54.100) (627 samples, 4.45%)</title><rect x="60.8890%" y="564" width="4.4522%" height="15" fill="rgb(208,69,12)"/><text x="61.1390%" y="574.50">0x7f7..</text></g><g><title>0x7f7d9859dfc5 (libavcodec.so.58.54.100) (217 samples, 1.54%)</title><rect x="65.6394%" y="580" width="1.5409%" height="15" fill="rgb(235,93,37)"/><text x="65.8894%" y="590.50"></text></g><g><title>0x7f7d9859e1d1 (libavcodec.so.58.54.100) (231 samples, 1.64%)</title><rect x="67.5211%" y="580" width="1.6403%" height="15" fill="rgb(213,116,39)"/><text x="67.7711%" y="590.50"></text></g><g><title>0x7f7d985a185d (libavcodec.so.58.54.100) (539 samples, 3.83%)</title><rect x="65.3838%" y="564" width="3.8273%" height="15" fill="rgb(222,207,29)"/><text x="65.6338%" y="574.50">0x7f..</text></g><g><title>0x7f7d9847e6f7 (libavcodec.so.58.54.100) (6,155 samples, 43.71%)</title><rect x="25.5627%" y="516" width="43.7052%" height="15" fill="rgb(206,96,30)"/><text x="25.8127%" y="526.50">0x7f7d9847e6f7 (libavcodec.so.58.54.100)</text></g><g><title>0x7f7d985a9317 (libavcodec.so.58.54.100) (4,980 samples, 35.36%)</title><rect x="33.9061%" y="532" width="35.3618%" height="15" fill="rgb(218,138,4)"/><text x="34.1561%" y="542.50">0x7f7d985a9317 (libavcodec.so.58.54.100)</text></g><g><title>0x7f7d985a30c1 (libavcodec.so.58.54.100) (4,978 samples, 35.35%)</title><rect x="33.9203%" y="548" width="35.3476%" height="15" fill="rgb(250,191,14)"/><text x="34.1703%" y="558.50">0x7f7d985a30c1 (libavcodec.so.58.54.100)</text></g><g><title>ffmpeg::Stream::decodePacket (stream.cpp:144) (6,211 samples, 44.10%)</title><rect x="25.2858%" y="468" width="44.1028%" height="15" fill="rgb(239,60,40)"/><text x="25.5358%" y="478.50">ffmpeg::Stream::decodePacket (stream.cpp:144)</text></g><g><title>ffmpeg::Stream::analyzePacket (stream.cpp:98) (6,187 samples, 43.93%)</title><rect x="25.4562%" y="484" width="43.9324%" height="15" fill="rgb(206,27,48)"/><text x="25.7062%" y="494.50">ffmpeg::Stream::analyzePacket (stream.cpp:98)</text></g><g><title>avcodec_send_packet (libavcodec.so.58.54.100) (6,187 samples, 43.93%)</title><rect x="25.4562%" y="500" width="43.9324%" height="15" fill="rgb(225,35,8)"/><text x="25.7062%" y="510.50">avcodec_send_packet (libavcodec.so.58.54.100)</text></g><g><title>ffmpeg::VideoSampler::sample (video_sampler.cpp:182) (2,601 samples, 18.47%)</title><rect x="70.0987%" y="500" width="18.4691%" height="15" fill="rgb(250,213,24)"/><text x="70.3487%" y="510.50">ffmpeg::VideoSampler::sample ..</text></g><g><title>transformImage (video_sampler.cpp:45) (2,600 samples, 18.46%)</title><rect x="70.1058%" y="516" width="18.4620%" height="15" fill="rgb(247,123,22)"/><text x="70.3558%" y="526.50">transformImage (video_sampler..</text></g><g><title>sws_scale (libswscale.so.5.5.100) (2,600 samples, 18.46%)</title><rect x="70.1058%" y="532" width="18.4620%" height="15" fill="rgb(231,138,38)"/><text x="70.3558%" y="542.50">sws_scale (libswscale.so.5.5...</text></g><g><title>ffmpeg::VideoStream::copyFrameBytes (video_stream.cpp:115) (2,655 samples, 18.85%)</title><rect x="69.7295%" y="484" width="18.8525%" height="15" fill="rgb(231,145,46)"/><text x="69.9795%" y="494.50">ffmpeg::VideoStream::copyFram..</text></g><g><title>ffmpeg::Decoder::processPacket (decoder.cpp:600) (8,932 samples, 63.42%)</title><rect x="25.2787%" y="452" width="63.4240%" height="15" fill="rgb(251,118,11)"/><text x="25.5287%" y="462.50">ffmpeg::Decoder::processPacket (decoder.cpp:600)</text></g><g><title>ffmpeg::Stream::decodePacket (stream.cpp:147) (2,720 samples, 19.31%)</title><rect x="69.3886%" y="468" width="19.3141%" height="15" fill="rgb(217,147,25)"/><text x="69.6386%" y="478.50">ffmpeg::Stream::decodePacket (..</text></g><g><title>ffmpeg::Decoder::getFrame (decoder.cpp:517) (8,945 samples, 63.52%)</title><rect x="25.2574%" y="436" width="63.5163%" height="15" fill="rgb(247,81,37)"/><text x="25.5074%" y="446.50">ffmpeg::Decoder::getFrame (decoder.cpp:517)</text></g><g><title>ffmpeg::SyncDecoder::decode (sync_decoder.cpp:72) (9,294 samples, 65.99%)</title><rect x="23.5390%" y="420" width="65.9945%" height="15" fill="rgb(209,12,38)"/><text x="23.7890%" y="430.50">ffmpeg::SyncDecoder::decode (sync_decoder.cpp:72)</text></g><g><title>video_reader::readVideo (VideoReader.cpp:272) (9,295 samples, 66.00%)</title><rect x="23.5390%" y="404" width="66.0016%" height="15" fill="rgb(227,1,9)"/><text x="23.7890%" y="414.50">video_reader::readVideo (VideoReader.cpp:272)</text></g><g><title>GOMP_parallel (parallel.c:173) (261 samples, 1.85%)</title><rect x="89.7465%" y="788" width="1.8533%" height="15" fill="rgb(248,47,43)"/><text x="89.9965%" y="798.50">G..</text></g><g><title>at::parallel_for&lt;at::TensorIterator::for_each(c10::function_ref&lt;void (char**, long const*, long, long)&gt;, long)::{lambda(long, long)#1}&gt; [clone ._omp_fn.0] (libtorch_cpu.so) (261 samples, 1.85%)</title><rect x="89.7465%" y="804" width="1.8533%" height="15" fill="rgb(221,10,30)"/><text x="89.9965%" y="814.50">a..</text></g><g><title>at::TensorIterator::serial_for_each (libtorch_cpu.so) (261 samples, 1.85%)</title><rect x="89.7465%" y="820" width="1.8533%" height="15" fill="rgb(210,229,1)"/><text x="89.9965%" y="830.50">a..</text></g><g><title>c10::function_ref&lt;void (char**, long const*, long, long)&gt;::callback_fn&lt;at::TensorIterator::for_each(c10::function_ref&lt;void (char**, long const*, long)&gt;, long)::{lambda(char**, long const*, long, long)#1}&gt; (libtorch_cpu.so) (261 samples, 1.85%)</title><rect x="89.7465%" y="836" width="1.8533%" height="15" fill="rgb(222,148,37)"/><text x="89.9965%" y="846.50">c..</text></g><g><title>c10::function_ref&lt;void (char**, long const*, long)&gt;::callback_fn&lt;void at::native::(anonymous namespace)::cpu_kernel_vec&lt;true, at::native::(anonymous namespace)::fill_kernel(at::TensorIterator&amp;, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#1}::operator()() const::{lambda()#1}, at::native::(anonymous namespace)::fill_kernel(at::TensorIterator&amp;, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#1}::operator()() const::{lambda()#2}&gt;(at::TensorIterator&amp;, at::native::(anonymous namespace)::fill_kernel(at::TensorIterator&amp;, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#1}::operator()() const::{lambda()#1}&amp;&amp;, at::native::(anonymous namespace)::fill_kernel(at::TensorIterator&amp;, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#1}::operator()() const::{lambda()#2}&amp;&amp;)::{lambda(char**, long const*, long)#2}&gt; (libtorch_cpu.so) (261 samples, 1.85%)</title><rect x="89.7465%" y="852" width="1.8533%" height="15" fill="rgb(234,67,33)"/><text x="89.9965%" y="862.50">c..</text></g><g><title>video_reader::readVideo (VideoReader.cpp:311) (390 samples, 2.77%)</title><rect x="89.6400%" y="404" width="2.7693%" height="15" fill="rgb(247,98,35)"/><text x="89.8900%" y="414.50">vi..</text></g><g><title>at::Tensor::operator= &amp; (TensorBody.h:172) (390 samples, 2.77%)</title><rect x="89.6400%" y="420" width="2.7693%" height="15" fill="rgb(247,138,52)"/><text x="89.8900%" y="430.50">at..</text></g><g><title>c10::intrusive_ptr&lt;c10::TensorImpl, c10::UndefinedTensorImpl&gt;::operator= &amp; (intrusive_ptr.h:253) (390 samples, 2.77%)</title><rect x="89.6400%" y="436" width="2.7693%" height="15" fill="rgb(213,79,30)"/><text x="89.8900%" y="446.50">c1..</text></g><g><title>c10::intrusive_ptr&lt;c10::TensorImpl, c10::UndefinedTensorImpl&gt;::operator=&lt;c10::TensorImpl, c10::UndefinedTensorImpl&gt; &amp; (intrusive_ptr.h:262) (390 samples, 2.77%)</title><rect x="89.6400%" y="452" width="2.7693%" height="15" fill="rgb(246,177,23)"/><text x="89.8900%" y="462.50">c1..</text></g><g><title>c10::intrusive_ptr&lt;c10::TensorImpl, c10::UndefinedTensorImpl&gt;::intrusive_ptr (intrusive_ptr.h:222) (390 samples, 2.77%)</title><rect x="89.6400%" y="468" width="2.7693%" height="15" fill="rgb(230,62,27)"/><text x="89.8900%" y="478.50">c1..</text></g><g><title>torch::zeros (variable_factories.h:618) (390 samples, 2.77%)</title><rect x="89.6400%" y="484" width="2.7693%" height="15" fill="rgb(216,154,8)"/><text x="89.8900%" y="494.50">to..</text></g><g><title>torch::zeros(c10::ArrayRef&lt;long&gt;, c10::TensorOptions const&amp;)::{lambda()#1}::operator() const (variable_factories.h:616) (390 samples, 2.77%)</title><rect x="89.6400%" y="500" width="2.7693%" height="15" fill="rgb(244,35,45)"/><text x="89.8900%" y="510.50">to..</text></g><g><title>at::AutoNonVariableTypeMode::~AutoNonVariableTypeMode (LegacyTypeDispatch.h:46) (390 samples, 2.77%)</title><rect x="89.6400%" y="516" width="2.7693%" height="15" fill="rgb(251,115,12)"/><text x="89.8900%" y="526.50">at..</text></g><g><title>at::zeros (libtorch_cpu.so) (390 samples, 2.77%)</title><rect x="89.6400%" y="532" width="2.7693%" height="15" fill="rgb(240,54,50)"/><text x="89.8900%" y="542.50">at..</text></g><g><title>c10::TypedOperatorHandle&lt;at::Tensor(c10::ArrayRef&lt;long&gt;, c10::optional&lt;c10::ScalarType&gt;, c10::optional&lt;c10::Layout&gt;, c10::optional&lt;c10::Device&gt;, c10::optional&lt;bool&gt;)&gt;::call (libtorch_cpu.so) (390 samples, 2.77%)</title><rect x="89.6400%" y="548" width="2.7693%" height="15" fill="rgb(233,84,52)"/><text x="89.8900%" y="558.50">c1..</text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;at::Tensor (*)(c10::ArrayRef&lt;long&gt;, c10::optional&lt;c10::ScalarType&gt;, c10::optional&lt;c10::Layout&gt;, c10::optional&lt;c10::Device&gt;, c10::optional&lt;bool&gt;), at::Tensor, c10::guts::typelist::typelist&lt;c10::ArrayRef&lt;long&gt;, c10::optional&lt;c10::ScalarType&gt;, c10::optional&lt;c10::Layout&gt;, c10::optional&lt;c10::Device&gt;, c10::optional&lt;bool&gt; &gt; &gt;, at::Tensor(c10::ArrayRef&lt;long&gt;, c10::optional&lt;c10::ScalarType&gt;, c10::optional&lt;c10::Layout&gt;, c10::optional&lt;c10::Device&gt;, c10::optional&lt;bool&gt;)&gt;::call (libtorch_cpu.so) (390 samples, 2.77%)</title><rect x="89.6400%" y="564" width="2.7693%" height="15" fill="rgb(207,117,47)"/><text x="89.8900%" y="574.50">c1..</text></g><g><title>c10::impl::detail::with_scattered_tensor_options_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::ArrayRef&lt;long&gt;, c10::TensorOptions const&amp;), &amp;at::(anonymous namespace)::zeros(c10::ArrayRef&lt;long&gt;, c10::TensorOptions const&amp;)&gt;, c10::guts::typelist::typelist&lt;c10::ArrayRef&lt;long&gt; &gt;, c10::guts::typelist::typelist&lt;&gt; &gt;::wrapper (libtorch_cpu.so) (390 samples, 2.77%)</title><rect x="89.6400%" y="580" width="2.7693%" height="15" fill="rgb(249,43,39)"/><text x="89.8900%" y="590.50">c1..</text></g><g><title>c10::TypedOperatorHandle&lt;at::Tensor(c10::ArrayRef&lt;long&gt;, c10::optional&lt;c10::ScalarType&gt;, c10::optional&lt;c10::Layout&gt;, c10::optional&lt;c10::Device&gt;, c10::optional&lt;bool&gt;)&gt;::callWithDispatchKey (libtorch_cpu.so) (390 samples, 2.77%)</title><rect x="89.6400%" y="596" width="2.7693%" height="15" fill="rgb(209,38,44)"/><text x="89.8900%" y="606.50">c1..</text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;at::Tensor (*)(c10::ArrayRef&lt;long&gt;, c10::optional&lt;c10::ScalarType&gt;, c10::optional&lt;c10::Layout&gt;, c10::optional&lt;c10::Device&gt;, c10::optional&lt;bool&gt;), at::Tensor, c10::guts::typelist::typelist&lt;c10::ArrayRef&lt;long&gt;, c10::optional&lt;c10::ScalarType&gt;, c10::optional&lt;c10::Layout&gt;, c10::optional&lt;c10::Device&gt;, c10::optional&lt;bool&gt; &gt; &gt;, at::Tensor(c10::ArrayRef&lt;long&gt;, c10::optional&lt;c10::ScalarType&gt;, c10::optional&lt;c10::Layout&gt;, c10::optional&lt;c10::Device&gt;, c10::optional&lt;bool&gt;)&gt;::call (libtorch_cpu.so) (390 samples, 2.77%)</title><rect x="89.6400%" y="612" width="2.7693%" height="15" fill="rgb(236,212,23)"/><text x="89.8900%" y="622.50">c1..</text></g><g><title>c10::impl::detail::with_scattered_tensor_options_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::ArrayRef&lt;long&gt;, c10::TensorOptions const&amp;), &amp;at::TypeDefault::zeros(c10::ArrayRef&lt;long&gt;, c10::TensorOptions const&amp;)&gt;, c10::guts::typelist::typelist&lt;c10::ArrayRef&lt;long&gt; &gt;, c10::guts::typelist::typelist&lt;&gt; &gt;::wrapper (libtorch_cpu.so) (390 samples, 2.77%)</title><rect x="89.6400%" y="628" width="2.7693%" height="15" fill="rgb(242,79,21)"/><text x="89.8900%" y="638.50">c1..</text></g><g><title>at::TypeDefault::zeros (libtorch_cpu.so) (390 samples, 2.77%)</title><rect x="89.6400%" y="644" width="2.7693%" height="15" fill="rgb(211,96,35)"/><text x="89.8900%" y="654.50">at..</text></g><g><title>at::native::zeros (libtorch_cpu.so) (390 samples, 2.77%)</title><rect x="89.6400%" y="660" width="2.7693%" height="15" fill="rgb(253,215,40)"/><text x="89.8900%" y="670.50">at..</text></g><g><title>at::native::zero_ (libtorch_cpu.so) (388 samples, 2.76%)</title><rect x="89.6542%" y="676" width="2.7551%" height="15" fill="rgb(211,81,21)"/><text x="89.9042%" y="686.50">at..</text></g><g><title>at::TypeDefault::fill__Scalar (libtorch_cpu.so) (388 samples, 2.76%)</title><rect x="89.6542%" y="692" width="2.7551%" height="15" fill="rgb(208,190,38)"/><text x="89.9042%" y="702.50">at..</text></g><g><title>at::native::fill_out (libtorch_cpu.so) (387 samples, 2.75%)</title><rect x="89.6613%" y="708" width="2.7480%" height="15" fill="rgb(235,213,38)"/><text x="89.9113%" y="718.50">at..</text></g><g><title>at::native::(anonymous namespace)::fill_kernel (libtorch_cpu.so) (387 samples, 2.75%)</title><rect x="89.6613%" y="724" width="2.7480%" height="15" fill="rgb(237,122,38)"/><text x="89.9113%" y="734.50">at..</text></g><g><title>at::native::(anonymous namespace)::fill_kernel(at::TensorIterator&amp;, c10::Scalar)::{lambda()#1}::operator() const (libtorch_cpu.so) (387 samples, 2.75%)</title><rect x="89.6613%" y="740" width="2.7480%" height="15" fill="rgb(244,218,35)"/><text x="89.9113%" y="750.50">at..</text></g><g><title>at::TensorIterator::for_each (libtorch_cpu.so) (387 samples, 2.75%)</title><rect x="89.6613%" y="756" width="2.7480%" height="15" fill="rgb(240,68,47)"/><text x="89.9113%" y="766.50">at..</text></g><g><title>at::TensorIterator::for_each (libtorch_cpu.so) (387 samples, 2.75%)</title><rect x="89.6613%" y="772" width="2.7480%" height="15" fill="rgb(210,16,53)"/><text x="89.9113%" y="782.50">at..</text></g><g><title>video_reader::fillTensor&lt;unsigned char&gt; (VideoReader.cpp:112) (920 samples, 6.53%)</title><rect x="92.7217%" y="420" width="6.5327%" height="15" fill="rgb(235,124,12)"/><text x="92.9717%" y="430.50">video_rea..</text></g><g><title>video_reader::readVideo (VideoReader.cpp:326) (962 samples, 6.83%)</title><rect x="92.4306%" y="404" width="6.8309%" height="15" fill="rgb(224,169,11)"/><text x="92.6806%" y="414.50">video_rea..</text></g><g><title>_read_video_from_file (torchvision/io/_video_opt.py:242) (13,321 samples, 94.59%)</title><rect x="5.2120%" y="100" width="94.5892%" height="15" fill="rgb(250,166,2)"/><text x="5.4620%" y="110.50">_read_video_from_file (torchvision/io/_video_opt.py:242)</text></g><g><title>pybind11::cpp_function::dispatcher (libtorch_python.so) (10,941 samples, 77.69%)</title><rect x="22.1118%" y="116" width="77.6894%" height="15" fill="rgb(242,216,29)"/><text x="22.3618%" y="126.50">pybind11::cpp_function::dispatcher (libtorch_python.so)</text></g><g><title>void pybind11::cpp_function::initialize&lt;torch::jit::initJITBindings(_object*)::{lambda(std::string const&amp;)#93}::operator()(std::string const&amp;) const::{lambda(pybind11::args, pybind11::kwargs)#1}, pybind11::object, pybind11::args, pybind11::kwargs, pybind11::name, pybind11::doc&gt;(torch::jit::initJITBindings(_object*)::{lambda(std::string const&amp;)#93}::operator()(std::string const&amp;) const::{lambda(pybind11::args&amp;&amp;, pybind11::kwargs)#1}, pybind11::object (*)(pybind11::args, pybind11::kwargs), pybind11::name const, pybind11::doc&amp;)::{lambda(pybind11::detail::function_call&amp;)#3}::_FUN (libtorch_python.so) (10,941 samples, 77.69%)</title><rect x="22.1118%" y="132" width="77.6894%" height="15" fill="rgb(230,116,27)"/><text x="22.3618%" y="142.50">void pybind11::cpp_function::initialize&lt;torch::jit::initJITBindings(_object*)::{lambda(std::string const&amp;)#93}::operator()(std::s..</text></g><g><title>torch::jit::invokeOperatorFromPython (libtorch_python.so) (10,941 samples, 77.69%)</title><rect x="22.1118%" y="148" width="77.6894%" height="15" fill="rgb(228,99,48)"/><text x="22.3618%" y="158.50">torch::jit::invokeOperatorFromPython (libtorch_python.so)</text></g><g><title>torch::jit::(anonymous namespace)::createOperatorFromC10_withTracingHandledHere(c10::OperatorHandle const&amp;)::{lambda(std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)#1}::operator() const (libtorch_cpu.so) (10,941 samples, 77.69%)</title><rect x="22.1118%" y="164" width="77.6894%" height="15" fill="rgb(253,11,6)"/><text x="22.3618%" y="174.50">torch::jit::(anonymous namespace)::createOperatorFromC10_withTracingHandledHere(c10::OperatorHandle const&amp;)::{lambda(std::vector&lt;..</text></g><g><title>c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long&gt; &gt;, true&gt;::call (make_boxed_from_unboxed_functor.h:292) (10,941 samples, 77.69%)</title><rect x="22.1118%" y="180" width="77.6894%" height="15" fill="rgb(247,143,39)"/><text x="22.3618%" y="190.50">c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::stri..</text></g><g><title>c10::guts::if_constexpr&lt;true, c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long&gt; &gt;, true&gt;::call(c10::OperatorKernel*, c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)::{lambda(auto:1)#1}, c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long&gt; &gt;, true&gt;::call(c10::OperatorKernel*, c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)::{lambda()#2}&gt; (C++17.h:282) (10,941 samples, 77.69%)</title><rect x="22.1118%" y="196" width="77.6894%" height="15" fill="rgb(236,97,10)"/><text x="22.3618%" y="206.50">c10::guts::if_constexpr&lt;true, c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::..</text></g><g><title>c10::guts::detail::_if_constexpr&lt;true&gt;::call&lt;c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long&gt; &gt;, true&gt;::call(c10::OperatorKernel*, c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)::{lambda(auto:1)#1}, c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long&gt; &gt;, true&gt;::call(c10::OperatorKernel*, c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)::{lambda()#2}, (void*)0&gt; (C++17.h:193) (10,941 samples, 77.69%)</title><rect x="22.1118%" y="212" width="77.6894%" height="15" fill="rgb(233,208,19)"/><text x="22.3618%" y="222.50">c10::guts::detail::_if_constexpr&lt;true&gt;::call&lt;c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntim..</text></g><g><title>c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long&gt; &gt;, true&gt;::call(c10::OperatorKernel*, c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)::{lambda(auto:1)#1}::operator()&lt;c10::guts::detail::_identity&gt; const (make_boxed_from_unboxed_functor.h:294) (10,941 samples, 77.69%)</title><rect x="22.1118%" y="228" width="77.6894%" height="15" fill="rgb(216,164,2)"/><text x="22.3618%" y="238.50">c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::stri..</text></g><g><title>drop (stack.h:57) (10,941 samples, 77.69%)</title><rect x="22.1118%" y="244" width="77.6894%" height="15" fill="rgb(220,129,5)"/><text x="22.3618%" y="254.50">drop (stack.h:57)</text></g><g><title>std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;::end (stl_vector.h:582) (10,941 samples, 77.69%)</title><rect x="22.1118%" y="260" width="77.6894%" height="15" fill="rgb(242,17,10)"/><text x="22.3618%" y="270.50">std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;::end (stl_vector.h:582)</text></g><g><title>__gnu_cxx::__normal_iterator&lt;c10::IValue*, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt; &gt;::__normal_iterator (stl_iterator.h:783) (10,941 samples, 77.69%)</title><rect x="22.1118%" y="276" width="77.6894%" height="15" fill="rgb(242,107,0)"/><text x="22.3618%" y="286.50">__gnu_cxx::__normal_iterator&lt;c10::IValue*, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt; &gt;::__normal_iterator (stl_itera..</text></g><g><title>c10::impl::call_functor_with_args_from_stack_&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long&gt; &gt;, true, (unsigned long)0, (unsigned long)1, (unsigned long)2, (unsigned long)3, (unsigned long)4, (unsigned long)5, (unsigned long)6, (unsigned long)7, (unsigned long)8, (unsigned long)9, (unsigned long)10, (unsigned long)11, (unsigned long)12, (unsigned long)13, (unsigned long)14, (unsigned long)15, (unsigned long)16, (unsigned long)17, (unsigned long)18&gt; (make_boxed_from_unboxed_functor.h:249) (10,941 samples, 77.69%)</title><rect x="22.1118%" y="292" width="77.6894%" height="15" fill="rgb(251,28,31)"/><text x="22.3618%" y="302.50">c10::impl::call_functor_with_args_from_stack_&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::s..</text></g><g><title>c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long&gt; &gt;::operator() (WrapFunctionIntoRuntimeFunctor.h:18) (10,941 samples, 77.69%)</title><rect x="22.1118%" y="308" width="77.6894%" height="15" fill="rgb(233,223,10)"/><text x="22.3618%" y="318.50">c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string, double, long, long, long, long, long, l..</text></g><g><title>std::string::~string (basic_string.h:3630) (10,940 samples, 77.68%)</title><rect x="22.1189%" y="324" width="77.6823%" height="15" fill="rgb(215,21,27)"/><text x="22.3689%" y="334.50">std::string::~string (basic_string.h:3630)</text></g><g><title>std::string::_M_rep (basic_string.h:3312) (10,940 samples, 77.68%)</title><rect x="22.1189%" y="340" width="77.6823%" height="15" fill="rgb(232,23,21)"/><text x="22.3689%" y="350.50">std::string::_M_rep (basic_string.h:3312)</text></g><g><title>video_reader::readVideoFromFile (VideoReader.cpp:514) (10,939 samples, 77.68%)</title><rect x="22.1260%" y="356" width="77.6752%" height="15" fill="rgb(244,5,23)"/><text x="22.3760%" y="366.50">video_reader::readVideoFromFile (VideoReader.cpp:514)</text></g><g><title>std::string::~string (basic_string.h:3630) (10,939 samples, 77.68%)</title><rect x="22.1260%" y="372" width="77.6752%" height="15" fill="rgb(226,81,46)"/><text x="22.3760%" y="382.50">std::string::~string (basic_string.h:3630)</text></g><g><title>std::string::_M_rep (basic_string.h:3312) (10,939 samples, 77.68%)</title><rect x="22.1260%" y="388" width="77.6752%" height="15" fill="rgb(247,70,30)"/><text x="22.3760%" y="398.50">std::string::_M_rep (basic_string.h:3312)</text></g><g><title>&lt;module&gt; (profile_tvvr_long.py:14) (13,999 samples, 99.40%)</title><rect x="0.5042%" y="52" width="99.4035%" height="15" fill="rgb(212,68,19)"/><text x="0.7542%" y="62.50">&lt;module&gt; (profile_tvvr_long.py:14)</text></g><g><title>read_video (torchvision/io/video.py:215) (13,791 samples, 97.93%)</title><rect x="1.9811%" y="68" width="97.9266%" height="15" fill="rgb(240,187,13)"/><text x="2.2311%" y="78.50">read_video (torchvision/io/video.py:215)</text></g><g><title>_read_video (torchvision/io/_video_opt.py:522) (13,339 samples, 94.72%)</title><rect x="5.1907%" y="84" width="94.7170%" height="15" fill="rgb(223,113,26)"/><text x="5.4407%" y="94.50">_read_video (torchvision/io/_video_opt.py:522)</text></g><g><title>all (14,083 samples, 100%)</title><rect x="0.0000%" y="36" width="100.0000%" height="15" fill="rgb(206,192,2)"/><text x="0.2500%" y="46.50"></text></g></svg></svg>