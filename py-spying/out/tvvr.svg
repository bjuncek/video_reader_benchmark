<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg version="1.1" width="1200" height="838" onload="init(evt)" viewBox="0 0 1200 838" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><!--Flame graph stack visualization. See https://github.com/brendangregg/FlameGraph for latest version, and http://www.brendangregg.com/flamegraphs.html for examples.--><!--NOTES: --><defs><linearGradient id="background" y1="0" y2="1" x1="0" x2="0"><stop stop-color="#eeeeee" offset="5%"/><stop stop-color="#eeeeb0" offset="95%"/></linearGradient></defs><style type="text/css">
text { font-family:"Verdana"; font-size:12px; fill:rgb(0,0,0); }
#title { text-anchor:middle; font-size:17px; }
#search { opacity:0.1; cursor:pointer; }
#search:hover, #search.show { opacity:1; }
#subtitle { text-anchor:middle; font-color:rgb(160,160,160); }
#unzoom { cursor:pointer; }
#frames > *:hover { stroke:black; stroke-width:0.5; cursor:pointer; }
.hide { display:none; }
.parent { opacity:0.5; }
</style><script type="text/ecmascript"><![CDATA[var nametype = 'Function:';
var fontsize = 12;
var fontwidth = 0.59;
var xpad = 10;
var inverted = true;
var searchcolor = 'rgb(230,0,230)';
var fluiddrawing = true;
var truncate_text_right = false;]]><![CDATA["use strict";
var details, searchbtn, unzoombtn, matchedtxt, svg, searching, frames;
function init(evt) {
    details = document.getElementById("details").firstChild;
    searchbtn = document.getElementById("search");
    unzoombtn = document.getElementById("unzoom");
    matchedtxt = document.getElementById("matched");
    svg = document.getElementsByTagName("svg")[0];
    frames = document.getElementById("frames");
    searching = 0;

    // Use GET parameters to restore a flamegraph's state.
    var restore_state = function() {
        var params = get_params();
        if (params.x && params.y)
            zoom(find_group(document.querySelector('[x="' + params.x + '"][y="' + params.y + '"]')));
        if (params.s)
            search(params.s);
    };

    if (fluiddrawing) {
        // Make width dynamic so the SVG fits its parent's width.
        svg.removeAttribute("width");
        // Edge requires us to have a viewBox that gets updated with size changes.
        var isEdge = /Edge\/\d./i.test(navigator.userAgent);
        if (!isEdge) {
          svg.removeAttribute("viewBox");
        }
        var update_for_width_change = function() {
            if (isEdge) {
                svg.attributes.viewBox.value = "0 0 " + svg.width.baseVal.value + " " + svg.height.baseVal.value;
            }

            // Keep consistent padding on left and right of frames container.
            frames.attributes.width.value = svg.width.baseVal.value - xpad * 2;

            // Text truncation needs to be adjusted for the current width.
            var el = frames.children;
            for(var i = 0; i < el.length; i++) {
                update_text(el[i]);
            }

            // Keep search elements at a fixed distance from right edge.
            var svgWidth = svg.width.baseVal.value;
            searchbtn.attributes.x.value = svgWidth - xpad - 100;
            matchedtxt.attributes.x.value = svgWidth - xpad - 100;
        };
        window.addEventListener('resize', function() {
            update_for_width_change();
        });
        // This needs to be done asynchronously for Safari to work.
        setTimeout(function() {
            unzoom();
            update_for_width_change();
            restore_state();
        }, 0);
    } else {
        restore_state();
    }
}
// event listeners
window.addEventListener("click", function(e) {
    var target = find_group(e.target);
    if (target) {
        if (target.nodeName == "a") {
            if (e.ctrlKey === false) return;
            e.preventDefault();
        }
        if (target.classList.contains("parent")) unzoom();
        zoom(target);

        // set parameters for zoom state
        var el = target.querySelector("rect");
        if (el && el.attributes && el.attributes.y && el.attributes._orig_x) {
            var params = get_params()
            params.x = el.attributes._orig_x.value;
            params.y = el.attributes.y.value;
            history.replaceState(null, null, parse_params(params));
        }
    }
    else if (e.target.id == "unzoom") {
        unzoom();

        // remove zoom state
        var params = get_params();
        if (params.x) delete params.x;
        if (params.y) delete params.y;
        history.replaceState(null, null, parse_params(params));
    }
    else if (e.target.id == "search") search_prompt();
}, false)
// mouse-over for info
// show
window.addEventListener("mouseover", function(e) {
    var target = find_group(e.target);
    if (target) details.nodeValue = nametype + " " + g_to_text(target);
}, false)
// clear
window.addEventListener("mouseout", function(e) {
    var target = find_group(e.target);
    if (target) details.nodeValue = ' ';
}, false)
// ctrl-F for search
window.addEventListener("keydown",function (e) {
    if (e.keyCode === 114 || (e.ctrlKey && e.keyCode === 70)) {
        e.preventDefault();
        search_prompt();
    }
}, false)
// functions
function get_params() {
    var params = {};
    var paramsarr = window.location.search.substr(1).split('&');
    for (var i = 0; i < paramsarr.length; ++i) {
        var tmp = paramsarr[i].split("=");
        if (!tmp[0] || !tmp[1]) continue;
        params[tmp[0]]  = decodeURIComponent(tmp[1]);
    }
    return params;
}
function parse_params(params) {
    var uri = "?";
    for (var key in params) {
        uri += key + '=' + encodeURIComponent(params[key]) + '&';
    }
    if (uri.slice(-1) == "&")
        uri = uri.substring(0, uri.length - 1);
    if (uri == '?')
        uri = window.location.href.split('?')[0];
    return uri;
}
function find_child(node, selector) {
    var children = node.querySelectorAll(selector);
    if (children.length) return children[0];
    return;
}
function find_group(node) {
    var parent = node.parentElement;
    if (!parent) return;
    if (parent.id == "frames") return node;
    return find_group(parent);
}
function orig_save(e, attr, val) {
    if (e.attributes["_orig_" + attr] != undefined) return;
    if (e.attributes[attr] == undefined) return;
    if (val == undefined) val = e.attributes[attr].value;
    e.setAttribute("_orig_" + attr, val);
}
function orig_load(e, attr) {
    if (e.attributes["_orig_"+attr] == undefined) return;
    e.attributes[attr].value = e.attributes["_orig_" + attr].value;
    e.removeAttribute("_orig_" + attr);
}
function g_to_text(e) {
    var text = find_child(e, "title").firstChild.nodeValue;
    return (text)
}
function g_to_func(e) {
    var func = g_to_text(e);
    // if there's any manipulation we want to do to the function
    // name before it's searched, do it here before returning.
    return (func);
}
function update_text(e) {
    var r = find_child(e, "rect");
    var t = find_child(e, "text");
    var w = parseFloat(r.attributes.width.value) * frames.attributes.width.value / 100 - 3;
    var txt = find_child(e, "title").textContent.replace(/\([^(]*\)$/,"");
    t.attributes.x.value = format_percent((parseFloat(r.attributes.x.value) + (100 * 3 / frames.attributes.width.value)));
    // Smaller than this size won't fit anything
    if (w < 2 * fontsize * fontwidth) {
        t.textContent = "";
        return;
    }
    t.textContent = txt;
    // Fit in full text width
    if (/^ *\$/.test(txt) || t.getComputedTextLength() < w)
        return;
    if (truncate_text_right) {
        // Truncate the right side of the text.
        for (var x = txt.length - 2; x > 0; x--) {
            if (t.getSubStringLength(0, x + 2) <= w) {
                t.textContent = txt.substring(0, x) + "..";
                return;
            }
        }
    } else {
        // Truncate the left side of the text.
        for (var x = 2; x < txt.length; x++) {
            if (t.getSubStringLength(x - 2, txt.length) <= w) {
                t.textContent = ".." + txt.substring(x, txt.length);
                return;
            }
        }
    }
    t.textContent = "";
}
// zoom
function zoom_reset(e) {
    if (e.attributes != undefined) {
        orig_load(e, "x");
        orig_load(e, "width");
    }
    if (e.childNodes == undefined) return;
    for(var i = 0, c = e.childNodes; i < c.length; i++) {
        zoom_reset(c[i]);
    }
}
function zoom_child(e, x, ratio) {
    if (e.attributes != undefined) {
        if (e.attributes.x != undefined) {
            orig_save(e, "x");
            e.attributes.x.value = format_percent((parseFloat(e.attributes.x.value) - x) * ratio);
            if (e.tagName == "text") {
                e.attributes.x.value = format_percent(parseFloat(find_child(e.parentNode, "rect[x]").attributes.x.value) + (100 * 3 / frames.attributes.width.value));
            }
        }
        if (e.attributes.width != undefined) {
            orig_save(e, "width");
            e.attributes.width.value = format_percent(parseFloat(e.attributes.width.value) * ratio);
        }
    }
    if (e.childNodes == undefined) return;
    for(var i = 0, c = e.childNodes; i < c.length; i++) {
        zoom_child(c[i], x, ratio);
    }
}
function zoom_parent(e) {
    if (e.attributes) {
        if (e.attributes.x != undefined) {
            orig_save(e, "x");
            e.attributes.x.value = "0.0%";
        }
        if (e.attributes.width != undefined) {
            orig_save(e, "width");
            e.attributes.width.value = "100.0%";
        }
    }
    if (e.childNodes == undefined) return;
    for(var i = 0, c = e.childNodes; i < c.length; i++) {
        zoom_parent(c[i]);
    }
}
function zoom(node) {
    var attr = find_child(node, "rect").attributes;
    var width = parseFloat(attr.width.value);
    var xmin = parseFloat(attr.x.value);
    var xmax = xmin + width;
    var ymin = parseFloat(attr.y.value);
    var ratio = 100 / width;
    // XXX: Workaround for JavaScript float issues (fix me)
    var fudge = 0.001;
    unzoombtn.classList.remove("hide");
    var el = frames.children;
    for (var i = 0; i < el.length; i++) {
        var e = el[i];
        var a = find_child(e, "rect").attributes;
        var ex = parseFloat(a.x.value);
        var ew = parseFloat(a.width.value);
        // Is it an ancestor
        if (!inverted) {
            var upstack = parseFloat(a.y.value) > ymin;
        } else {
            var upstack = parseFloat(a.y.value) < ymin;
        }
        if (upstack) {
            // Direct ancestor
            if (ex <= xmin && (ex+ew+fudge) >= xmax) {
                e.classList.add("parent");
                zoom_parent(e);
                update_text(e);
            }
            // not in current path
            else
                e.classList.add("hide");
        }
        // Children maybe
        else {
            // no common path
            if (ex < xmin || ex + fudge >= xmax) {
                e.classList.add("hide");
            }
            else {
                zoom_child(e, xmin, ratio);
                update_text(e);
            }
        }
    }
}
function unzoom() {
    unzoombtn.classList.add("hide");
    var el = frames.children;
    for(var i = 0; i < el.length; i++) {
        el[i].classList.remove("parent");
        el[i].classList.remove("hide");
        zoom_reset(el[i]);
        update_text(el[i]);
    }
}
// search
function reset_search() {
    var el = document.querySelectorAll("#frames rect");
    for (var i = 0; i < el.length; i++) {
        orig_load(el[i], "fill")
    }
    var params = get_params();
    delete params.s;
    history.replaceState(null, null, parse_params(params));
}
function search_prompt() {
    if (!searching) {
        var term = prompt("Enter a search term (regexp " +
            "allowed, eg: ^ext4_)", "");
        if (term != null) {
            search(term)
        }
    } else {
        reset_search();
        searching = 0;
        searchbtn.classList.remove("show");
        searchbtn.firstChild.nodeValue = "Search"
        matchedtxt.classList.add("hide");
        matchedtxt.firstChild.nodeValue = ""
    }
}
function search(term) {
    var re = new RegExp(term);
    var el = frames.children;
    var matches = new Object();
    var maxwidth = 0;
    for (var i = 0; i < el.length; i++) {
        var e = el[i];
        var func = g_to_func(e);
        var rect = find_child(e, "rect");
        if (func == null || rect == null)
            continue;
        // Save max width. Only works as we have a root frame
        var w = parseFloat(rect.attributes.width.value);
        if (w > maxwidth)
            maxwidth = w;
        if (func.match(re)) {
            // highlight
            var x = parseFloat(rect.attributes.x.value);
            orig_save(rect, "fill");
            rect.attributes.fill.value = searchcolor;
            // remember matches
            if (matches[x] == undefined) {
                matches[x] = w;
            } else {
                if (w > matches[x]) {
                    // overwrite with parent
                    matches[x] = w;
                }
            }
            searching = 1;
        }
    }
    if (!searching)
        return;
    var params = get_params();
    params.s = term;
    history.replaceState(null, null, parse_params(params));

    searchbtn.classList.add("show");
    searchbtn.firstChild.nodeValue = "Reset Search";
    // calculate percent matched, excluding vertical overlap
    var count = 0;
    var lastx = -1;
    var lastw = 0;
    var keys = Array();
    for (k in matches) {
        if (matches.hasOwnProperty(k))
            keys.push(k);
    }
    // sort the matched frames by their x location
    // ascending, then width descending
    keys.sort(function(a, b){
        return a - b;
    });
    // Step through frames saving only the biggest bottom-up frames
    // thanks to the sort order. This relies on the tree property
    // where children are always smaller than their parents.
    var fudge = 0.0001;    // JavaScript floating point
    for (var k in keys) {
        var x = parseFloat(keys[k]);
        var w = matches[keys[k]];
        if (x >= lastx + lastw - fudge) {
            count += w;
            lastx = x;
            lastw = w;
        }
    }
    // display matched percent
    matchedtxt.classList.remove("hide");
    var pct = 100 * count / maxwidth;
    if (pct != 100) pct = pct.toFixed(1);
    matchedtxt.firstChild.nodeValue = "Matched: " + pct + "%";
}
function format_percent(n) {
    return n.toFixed(4) + "%";
}
]]></script><rect x="0" y="0" width="100%" height="838" fill="url(#background)"/><text id="title" x="50.0000%" y="24.00">py-spy</text><text id="details" x="10" y="821.00"> </text><text id="unzoom" class="hide" x="10" y="24.00">Reset Zoom</text><text id="search" x="1090" y="24.00">Search</text><text id="matched" x="1090" y="821.00"> </text><svg id="frames" x="10" width="1180"><g><title>0x7f63926cbaf9 (ld-2.27.so) (8 samples, 3.07%)</title><rect x="0.3831%" y="388" width="3.0651%" height="15" fill="rgb(227,0,7)"/><text x="0.6331%" y="398.50">0x7..</text></g><g><title>0x7f63926ca1ef (ld-2.27.so) (5 samples, 1.92%)</title><rect x="1.5326%" y="404" width="1.9157%" height="15" fill="rgb(217,0,24)"/><text x="1.7826%" y="414.50">0..</text></g><g><title>0x7f63926d40bd (ld-2.27.so) (9 samples, 3.45%)</title><rect x="0.3831%" y="372" width="3.4483%" height="15" fill="rgb(221,193,54)"/><text x="0.6331%" y="382.50">0x7..</text></g><g><title>torch::(anonymous namespace)::debugString (libtorch_cpu.so) (4 samples, 1.53%)</title><rect x="7.6628%" y="468" width="1.5326%" height="15" fill="rgb(248,212,6)"/><text x="7.9128%" y="478.50"></text></g><g><title>c10::detail::_str_wrapper&lt;char const*, char const* const&amp;, char const*, unsigned int const&amp;&gt;::call (libtorch_cpu.so) (4 samples, 1.53%)</title><rect x="7.6628%" y="484" width="1.5326%" height="15" fill="rgb(208,68,35)"/><text x="7.9128%" y="494.50"></text></g><g><title>_GLOBAL__sub_I_CUDAType.cpp (libtorch_cuda.so) (17 samples, 6.51%)</title><rect x="4.2146%" y="404" width="6.5134%" height="15" fill="rgb(232,128,0)"/><text x="4.4646%" y="414.50">_GLOBAL__..</text></g><g><title>at::TORCH_LIBRARY_IMPL_init_aten_CUDA (libtorch_cuda.so) (17 samples, 6.51%)</title><rect x="4.2146%" y="420" width="6.5134%" height="15" fill="rgb(207,160,47)"/><text x="4.4646%" y="430.50">at::TORCH..</text></g><g><title>torch::Library::impl&lt;torch::CppFunction&gt; &amp; (libtorch_cpu.so) (13 samples, 4.98%)</title><rect x="5.7471%" y="436" width="4.9808%" height="15" fill="rgb(228,23,34)"/><text x="5.9971%" y="446.50">torch:..</text></g><g><title>torch::Library::_impl &amp; (libtorch_cpu.so) (13 samples, 4.98%)</title><rect x="5.7471%" y="452" width="4.9808%" height="15" fill="rgb(218,30,26)"/><text x="5.9971%" y="462.50">torch:..</text></g><g><title>torch::jit::parseName (libtorch_cpu.so) (4 samples, 1.53%)</title><rect x="9.1954%" y="468" width="1.5326%" height="15" fill="rgb(220,122,19)"/><text x="9.4454%" y="478.50"></text></g><g><title>torch::jit::parseSchemaOrName (libtorch_cpu.so) (4 samples, 1.53%)</title><rect x="9.1954%" y="484" width="1.5326%" height="15" fill="rgb(250,228,42)"/><text x="9.4454%" y="494.50"></text></g><g><title>c10::detail::inferFunctionSchemaFromFunctor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;at::Tensor (*)(at::Tensor, c10::optional&lt;at::Tensor&gt;, c10::optional&lt;at::Tensor&gt;, at::Tensor, at::Tensor, double, double, long), at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor, c10::optional&lt;at::Tensor&gt;, c10::optional&lt;at::Tensor&gt;, at::Tensor, at::Tensor, double, double, long&gt; &gt; &gt; (libtorch_cpu.so) (3 samples, 1.15%)</title><rect x="14.1762%" y="420" width="1.1494%" height="15" fill="rgb(240,193,28)"/><text x="14.4262%" y="430.50"></text></g><g><title>_GLOBAL__sub_I_qbatch_norm.cpp (libtorch_cpu.so) (7 samples, 2.68%)</title><rect x="14.1762%" y="404" width="2.6820%" height="15" fill="rgb(216,20,37)"/><text x="14.4262%" y="414.50">_G..</text></g><g><title>torch::Library::_impl &amp; (libtorch_cpu.so) (4 samples, 1.53%)</title><rect x="15.3257%" y="420" width="1.5326%" height="15" fill="rgb(206,188,39)"/><text x="15.5757%" y="430.50"></text></g><g><title>_GLOBAL__sub_I_qconv.cpp (libtorch_cpu.so) (5 samples, 1.92%)</title><rect x="17.6245%" y="404" width="1.9157%" height="15" fill="rgb(217,207,13)"/><text x="17.8745%" y="414.50">_..</text></g><g><title>torch::detail::TorchLibraryInit::TorchLibraryInit (libtorch_cpu.so) (5 samples, 1.92%)</title><rect x="17.6245%" y="420" width="1.9157%" height="15" fill="rgb(231,73,38)"/><text x="17.8745%" y="430.50">t..</text></g><g><title>at::native::(anonymous namespace)::TORCH_LIBRARY_IMPL_init_quantized_QuantizedCPU (libtorch_cpu.so) (5 samples, 1.92%)</title><rect x="17.6245%" y="436" width="1.9157%" height="15" fill="rgb(225,20,46)"/><text x="17.8745%" y="446.50">a..</text></g><g><title>dlopen (libdl-2.27.so) (53 samples, 20.31%)</title><rect x="0.3831%" y="260" width="20.3065%" height="15" fill="rgb(210,31,41)"/><text x="0.6331%" y="270.50">dlopen (libdl-2.27.so)</text></g><g><title>0x7f6391eac735 (libdl-2.27.so) (53 samples, 20.31%)</title><rect x="0.3831%" y="276" width="20.3065%" height="15" fill="rgb(221,200,47)"/><text x="0.6331%" y="286.50">0x7f6391eac735 (libdl-2.27.so)</text></g><g><title>_dl_catch_error (libc-2.27.so) (53 samples, 20.31%)</title><rect x="0.3831%" y="292" width="20.3065%" height="15" fill="rgb(226,26,5)"/><text x="0.6331%" y="302.50">_dl_catch_error (libc-2.27.so)</text></g><g><title>_dl_catch_exception (libc-2.27.so) (53 samples, 20.31%)</title><rect x="0.3831%" y="308" width="20.3065%" height="15" fill="rgb(249,33,26)"/><text x="0.6331%" y="318.50">_dl_catch_exception (libc-2.27.s..</text></g><g><title>0x7f6391eabf96 (libdl-2.27.so) (53 samples, 20.31%)</title><rect x="0.3831%" y="324" width="20.3065%" height="15" fill="rgb(235,183,28)"/><text x="0.6331%" y="334.50">0x7f6391eabf96 (libdl-2.27.so)</text></g><g><title>0x7f63926d37ca (ld-2.27.so) (53 samples, 20.31%)</title><rect x="0.3831%" y="340" width="20.3065%" height="15" fill="rgb(221,5,38)"/><text x="0.6331%" y="350.50">0x7f63926d37ca (ld-2.27.so)</text></g><g><title>_dl_catch_exception (libc-2.27.so) (53 samples, 20.31%)</title><rect x="0.3831%" y="356" width="20.3065%" height="15" fill="rgb(247,18,42)"/><text x="0.6331%" y="366.50">_dl_catch_exception (libc-2.27.s..</text></g><g><title>0x7f63926d41ff (ld-2.27.so) (44 samples, 16.86%)</title><rect x="3.8314%" y="372" width="16.8582%" height="15" fill="rgb(241,131,45)"/><text x="4.0814%" y="382.50">0x7f63926d41ff (ld-2.27.so)</text></g><g><title>0x7f63926cf733 (ld-2.27.so) (44 samples, 16.86%)</title><rect x="3.8314%" y="388" width="16.8582%" height="15" fill="rgb(249,31,29)"/><text x="4.0814%" y="398.50">0x7f63926cf733 (ld-2.27.so)</text></g><g><title>&lt;module&gt; (numpy/__init__.py:142) (3 samples, 1.15%)</title><rect x="20.6897%" y="452" width="1.1494%" height="15" fill="rgb(225,111,53)"/><text x="20.9397%" y="462.50"></text></g><g><title>_handle_fromlist (&lt;frozen importlib._bootstrap&gt;:1035) (3 samples, 1.15%)</title><rect x="20.6897%" y="468" width="1.1494%" height="15" fill="rgb(238,160,17)"/><text x="20.9397%" y="478.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (3 samples, 1.15%)</title><rect x="20.6897%" y="484" width="1.1494%" height="15" fill="rgb(214,148,48)"/><text x="20.9397%" y="494.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:983) (3 samples, 1.15%)</title><rect x="20.6897%" y="500" width="1.1494%" height="15" fill="rgb(232,36,49)"/><text x="20.9397%" y="510.50"></text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:967) (3 samples, 1.15%)</title><rect x="20.6897%" y="516" width="1.1494%" height="15" fill="rgb(209,103,24)"/><text x="20.9397%" y="526.50"></text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:677) (3 samples, 1.15%)</title><rect x="20.6897%" y="532" width="1.1494%" height="15" fill="rgb(229,88,8)"/><text x="20.9397%" y="542.50"></text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:728) (3 samples, 1.15%)</title><rect x="20.6897%" y="548" width="1.1494%" height="15" fill="rgb(213,181,19)"/><text x="20.9397%" y="558.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (3 samples, 1.15%)</title><rect x="20.6897%" y="564" width="1.1494%" height="15" fill="rgb(254,191,54)"/><text x="20.9397%" y="574.50"></text></g><g><title>&lt;module&gt; (numpy/core/__init__.py:78) (3 samples, 1.15%)</title><rect x="20.6897%" y="580" width="1.1494%" height="15" fill="rgb(241,83,37)"/><text x="20.9397%" y="590.50"></text></g><g><title>_handle_fromlist (&lt;frozen importlib._bootstrap&gt;:1035) (3 samples, 1.15%)</title><rect x="20.6897%" y="596" width="1.1494%" height="15" fill="rgb(233,36,39)"/><text x="20.9397%" y="606.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (3 samples, 1.15%)</title><rect x="20.6897%" y="612" width="1.1494%" height="15" fill="rgb(226,3,54)"/><text x="20.9397%" y="622.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:983) (3 samples, 1.15%)</title><rect x="20.6897%" y="628" width="1.1494%" height="15" fill="rgb(245,192,40)"/><text x="20.9397%" y="638.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:983) (9 samples, 3.45%)</title><rect x="20.6897%" y="276" width="3.4483%" height="15" fill="rgb(238,167,29)"/><text x="20.9397%" y="286.50">_fi..</text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:953) (9 samples, 3.45%)</title><rect x="20.6897%" y="292" width="3.4483%" height="15" fill="rgb(232,182,51)"/><text x="20.9397%" y="302.50">_fi..</text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (9 samples, 3.45%)</title><rect x="20.6897%" y="308" width="3.4483%" height="15" fill="rgb(231,60,39)"/><text x="20.9397%" y="318.50">_ca..</text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:983) (9 samples, 3.45%)</title><rect x="20.6897%" y="324" width="3.4483%" height="15" fill="rgb(208,69,12)"/><text x="20.9397%" y="334.50">_fi..</text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:953) (9 samples, 3.45%)</title><rect x="20.6897%" y="340" width="3.4483%" height="15" fill="rgb(235,93,37)"/><text x="20.9397%" y="350.50">_fi..</text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (9 samples, 3.45%)</title><rect x="20.6897%" y="356" width="3.4483%" height="15" fill="rgb(213,116,39)"/><text x="20.9397%" y="366.50">_ca..</text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:983) (9 samples, 3.45%)</title><rect x="20.6897%" y="372" width="3.4483%" height="15" fill="rgb(222,207,29)"/><text x="20.9397%" y="382.50">_fi..</text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:967) (9 samples, 3.45%)</title><rect x="20.6897%" y="388" width="3.4483%" height="15" fill="rgb(206,96,30)"/><text x="20.9397%" y="398.50">_fi..</text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:677) (9 samples, 3.45%)</title><rect x="20.6897%" y="404" width="3.4483%" height="15" fill="rgb(218,138,4)"/><text x="20.9397%" y="414.50">_lo..</text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:728) (9 samples, 3.45%)</title><rect x="20.6897%" y="420" width="3.4483%" height="15" fill="rgb(250,191,14)"/><text x="20.9397%" y="430.50">exe..</text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (9 samples, 3.45%)</title><rect x="20.6897%" y="436" width="3.4483%" height="15" fill="rgb(239,60,40)"/><text x="20.9397%" y="446.50">_ca..</text></g><g><title>&lt;module&gt; (numpy/__init__.py:152) (3 samples, 1.15%)</title><rect x="22.9885%" y="452" width="1.1494%" height="15" fill="rgb(206,27,48)"/><text x="23.2385%" y="462.50"></text></g><g><title>_handle_fromlist (&lt;frozen importlib._bootstrap&gt;:1035) (3 samples, 1.15%)</title><rect x="22.9885%" y="468" width="1.1494%" height="15" fill="rgb(225,35,8)"/><text x="23.2385%" y="478.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (3 samples, 1.15%)</title><rect x="22.9885%" y="484" width="1.1494%" height="15" fill="rgb(250,213,24)"/><text x="23.2385%" y="494.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:983) (3 samples, 1.15%)</title><rect x="22.9885%" y="500" width="1.1494%" height="15" fill="rgb(247,123,22)"/><text x="23.2385%" y="510.50"></text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:967) (3 samples, 1.15%)</title><rect x="22.9885%" y="516" width="1.1494%" height="15" fill="rgb(231,138,38)"/><text x="23.2385%" y="526.50"></text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:677) (3 samples, 1.15%)</title><rect x="22.9885%" y="532" width="1.1494%" height="15" fill="rgb(231,145,46)"/><text x="23.2385%" y="542.50"></text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:728) (3 samples, 1.15%)</title><rect x="22.9885%" y="548" width="1.1494%" height="15" fill="rgb(251,118,11)"/><text x="23.2385%" y="558.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (3 samples, 1.15%)</title><rect x="22.9885%" y="564" width="1.1494%" height="15" fill="rgb(217,147,25)"/><text x="23.2385%" y="574.50"></text></g><g><title>&lt;module&gt; (numpy/random/__init__.py:181) (3 samples, 1.15%)</title><rect x="22.9885%" y="580" width="1.1494%" height="15" fill="rgb(247,81,37)"/><text x="23.2385%" y="590.50"></text></g><g><title>_handle_fromlist (&lt;frozen importlib._bootstrap&gt;:1035) (3 samples, 1.15%)</title><rect x="22.9885%" y="596" width="1.1494%" height="15" fill="rgb(209,12,38)"/><text x="23.2385%" y="606.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (3 samples, 1.15%)</title><rect x="22.9885%" y="612" width="1.1494%" height="15" fill="rgb(227,1,9)"/><text x="23.2385%" y="622.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:983) (3 samples, 1.15%)</title><rect x="22.9885%" y="628" width="1.1494%" height="15" fill="rgb(248,47,43)"/><text x="23.2385%" y="638.50"></text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:967) (3 samples, 1.15%)</title><rect x="22.9885%" y="644" width="1.1494%" height="15" fill="rgb(221,10,30)"/><text x="23.2385%" y="654.50"></text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:677) (3 samples, 1.15%)</title><rect x="22.9885%" y="660" width="1.1494%" height="15" fill="rgb(210,229,1)"/><text x="23.2385%" y="670.50"></text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:728) (3 samples, 1.15%)</title><rect x="22.9885%" y="676" width="1.1494%" height="15" fill="rgb(222,148,37)"/><text x="23.2385%" y="686.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (3 samples, 1.15%)</title><rect x="22.9885%" y="692" width="1.1494%" height="15" fill="rgb(234,67,33)"/><text x="23.2385%" y="702.50"></text></g><g><title>&lt;module&gt; (numpy/random/_pickle.py:1) (3 samples, 1.15%)</title><rect x="22.9885%" y="708" width="1.1494%" height="15" fill="rgb(247,98,35)"/><text x="23.2385%" y="718.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:983) (3 samples, 1.15%)</title><rect x="22.9885%" y="724" width="1.1494%" height="15" fill="rgb(247,138,52)"/><text x="23.2385%" y="734.50"></text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:967) (3 samples, 1.15%)</title><rect x="22.9885%" y="740" width="1.1494%" height="15" fill="rgb(213,79,30)"/><text x="23.2385%" y="750.50"></text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:677) (3 samples, 1.15%)</title><rect x="22.9885%" y="756" width="1.1494%" height="15" fill="rgb(246,177,23)"/><text x="23.2385%" y="766.50"></text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:1050) (3 samples, 1.15%)</title><rect x="22.9885%" y="772" width="1.1494%" height="15" fill="rgb(230,62,27)"/><text x="23.2385%" y="782.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (3 samples, 1.15%)</title><rect x="22.9885%" y="788" width="1.1494%" height="15" fill="rgb(216,154,8)"/><text x="23.2385%" y="798.50"></text></g><g><title>&lt;module&gt; (torch/__init__.py:189) (65 samples, 24.90%)</title><rect x="0.3831%" y="148" width="24.9042%" height="15" fill="rgb(244,35,45)"/><text x="0.6331%" y="158.50">&lt;module&gt; (torch/__init__.py:189)</text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:983) (65 samples, 24.90%)</title><rect x="0.3831%" y="164" width="24.9042%" height="15" fill="rgb(251,115,12)"/><text x="0.6331%" y="174.50">_find_and_load (&lt;frozen importlib._boots..</text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:967) (65 samples, 24.90%)</title><rect x="0.3831%" y="180" width="24.9042%" height="15" fill="rgb(240,54,50)"/><text x="0.6331%" y="190.50">_find_and_load_unlocked (&lt;frozen importl..</text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:670) (65 samples, 24.90%)</title><rect x="0.3831%" y="196" width="24.9042%" height="15" fill="rgb(233,84,52)"/><text x="0.6331%" y="206.50">_load_unlocked (&lt;frozen importlib._boots..</text></g><g><title>module_from_spec (&lt;frozen importlib._bootstrap&gt;:583) (65 samples, 24.90%)</title><rect x="0.3831%" y="212" width="24.9042%" height="15" fill="rgb(207,117,47)"/><text x="0.6331%" y="222.50">module_from_spec (&lt;frozen importlib._boo..</text></g><g><title>create_module (&lt;frozen importlib._bootstrap_external&gt;:1043) (65 samples, 24.90%)</title><rect x="0.3831%" y="228" width="24.9042%" height="15" fill="rgb(249,43,39)"/><text x="0.6331%" y="238.50">create_module (&lt;frozen importlib._bootst..</text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (65 samples, 24.90%)</title><rect x="0.3831%" y="244" width="24.9042%" height="15" fill="rgb(209,38,44)"/><text x="0.6331%" y="254.50">_call_with_frames_removed (&lt;frozen impor..</text></g><g><title>initModule (libtorch_python.so) (12 samples, 4.60%)</title><rect x="20.6897%" y="260" width="4.5977%" height="15" fill="rgb(236,212,23)"/><text x="20.9397%" y="270.50">initM..</text></g><g><title>at::init_num_threads (libtorch_cpu.so) (3 samples, 1.15%)</title><rect x="24.1379%" y="276" width="1.1494%" height="15" fill="rgb(242,79,21)"/><text x="24.3879%" y="286.50"></text></g><g><title>mkl_serv_domain_get_max_threads (libmkl_gnu_thread.so) (3 samples, 1.15%)</title><rect x="24.1379%" y="292" width="1.1494%" height="15" fill="rgb(211,96,35)"/><text x="24.3879%" y="302.50"></text></g><g><title>&lt;module&gt; (torch/__init__.py:435) (4 samples, 1.53%)</title><rect x="25.2874%" y="148" width="1.5326%" height="15" fill="rgb(253,215,40)"/><text x="25.5374%" y="158.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:983) (4 samples, 1.53%)</title><rect x="25.2874%" y="164" width="1.5326%" height="15" fill="rgb(211,81,21)"/><text x="25.5374%" y="174.50"></text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:967) (4 samples, 1.53%)</title><rect x="25.2874%" y="180" width="1.5326%" height="15" fill="rgb(208,190,38)"/><text x="25.5374%" y="190.50"></text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:677) (4 samples, 1.53%)</title><rect x="25.2874%" y="196" width="1.5326%" height="15" fill="rgb(235,213,38)"/><text x="25.5374%" y="206.50"></text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:728) (4 samples, 1.53%)</title><rect x="25.2874%" y="212" width="1.5326%" height="15" fill="rgb(237,122,38)"/><text x="25.5374%" y="222.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (4 samples, 1.53%)</title><rect x="25.2874%" y="228" width="1.5326%" height="15" fill="rgb(244,218,35)"/><text x="25.5374%" y="238.50"></text></g><g><title>&lt;module&gt; (torch/functional.py:4) (4 samples, 1.53%)</title><rect x="25.2874%" y="244" width="1.5326%" height="15" fill="rgb(240,68,47)"/><text x="25.5374%" y="254.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:983) (4 samples, 1.53%)</title><rect x="25.2874%" y="260" width="1.5326%" height="15" fill="rgb(210,16,53)"/><text x="25.5374%" y="270.50"></text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:953) (4 samples, 1.53%)</title><rect x="25.2874%" y="276" width="1.5326%" height="15" fill="rgb(235,124,12)"/><text x="25.5374%" y="286.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (4 samples, 1.53%)</title><rect x="25.2874%" y="292" width="1.5326%" height="15" fill="rgb(224,169,11)"/><text x="25.5374%" y="302.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:983) (4 samples, 1.53%)</title><rect x="25.2874%" y="308" width="1.5326%" height="15" fill="rgb(250,166,2)"/><text x="25.5374%" y="318.50"></text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:967) (4 samples, 1.53%)</title><rect x="25.2874%" y="324" width="1.5326%" height="15" fill="rgb(242,216,29)"/><text x="25.5374%" y="334.50"></text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:677) (4 samples, 1.53%)</title><rect x="25.2874%" y="340" width="1.5326%" height="15" fill="rgb(230,116,27)"/><text x="25.5374%" y="350.50"></text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:728) (4 samples, 1.53%)</title><rect x="25.2874%" y="356" width="1.5326%" height="15" fill="rgb(228,99,48)"/><text x="25.5374%" y="366.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (4 samples, 1.53%)</title><rect x="25.2874%" y="372" width="1.5326%" height="15" fill="rgb(253,11,6)"/><text x="25.5374%" y="382.50"></text></g><g><title>&lt;module&gt; (profile_tvvr.py:1) (76 samples, 29.12%)</title><rect x="0.0000%" y="52" width="29.1188%" height="15" fill="rgb(247,143,39)"/><text x="0.2500%" y="62.50">&lt;module&gt; (profile_tvvr.py:1)</text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:983) (76 samples, 29.12%)</title><rect x="0.0000%" y="68" width="29.1188%" height="15" fill="rgb(236,97,10)"/><text x="0.2500%" y="78.50">_find_and_load (&lt;frozen importlib._bootstrap&gt;:9..</text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:967) (76 samples, 29.12%)</title><rect x="0.0000%" y="84" width="29.1188%" height="15" fill="rgb(233,208,19)"/><text x="0.2500%" y="94.50">_find_and_load_unlocked (&lt;frozen importlib._boo..</text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:677) (76 samples, 29.12%)</title><rect x="0.0000%" y="100" width="29.1188%" height="15" fill="rgb(216,164,2)"/><text x="0.2500%" y="110.50">_load_unlocked (&lt;frozen importlib._bootstrap&gt;:6..</text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:728) (76 samples, 29.12%)</title><rect x="0.0000%" y="116" width="29.1188%" height="15" fill="rgb(220,129,5)"/><text x="0.2500%" y="126.50">exec_module (&lt;frozen importlib._bootstrap_exter..</text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (76 samples, 29.12%)</title><rect x="0.0000%" y="132" width="29.1188%" height="15" fill="rgb(242,17,10)"/><text x="0.2500%" y="142.50">_call_with_frames_removed (&lt;frozen importlib._b..</text></g><g><title>THPVariable_dealloc (libtorch_python.so) (3 samples, 1.15%)</title><rect x="29.1188%" y="68" width="1.1494%" height="15" fill="rgb(242,107,0)"/><text x="29.3688%" y="78.50"></text></g><g><title>THPVariable_clear (libtorch_python.so) (3 samples, 1.15%)</title><rect x="29.1188%" y="84" width="1.1494%" height="15" fill="rgb(251,28,31)"/><text x="29.3688%" y="94.50"></text></g><g><title>c10::TensorImpl::release_resources (libc10.so) (3 samples, 1.15%)</title><rect x="29.1188%" y="100" width="1.1494%" height="15" fill="rgb(233,223,10)"/><text x="29.3688%" y="110.50"></text></g><g><title>cfree (libc-2.27.so) (3 samples, 1.15%)</title><rect x="29.1188%" y="116" width="1.1494%" height="15" fill="rgb(215,21,27)"/><text x="29.3688%" y="126.50"></text></g><g><title>munmap (libc-2.27.so) (3 samples, 1.15%)</title><rect x="29.1188%" y="132" width="1.1494%" height="15" fill="rgb(232,23,21)"/><text x="29.3688%" y="142.50"></text></g><g><title>ffmpeg::Decoder::init (decoder.cpp:333) (7 samples, 2.68%)</title><rect x="30.2682%" y="388" width="2.6820%" height="15" fill="rgb(244,5,23)"/><text x="30.5182%" y="398.50">ff..</text></g><g><title>avformat_open_input (libavformat.so.58.29.100) (7 samples, 2.68%)</title><rect x="30.2682%" y="404" width="2.6820%" height="15" fill="rgb(226,81,46)"/><text x="30.5182%" y="414.50">av..</text></g><g><title>av_probe_input_buffer2 (libavformat.so.58.29.100) (4 samples, 1.53%)</title><rect x="31.4176%" y="420" width="1.5326%" height="15" fill="rgb(247,70,30)"/><text x="31.6676%" y="430.50"></text></g><g><title>av_probe_input_format2 (libavformat.so.58.29.100) (3 samples, 1.15%)</title><rect x="31.8008%" y="436" width="1.1494%" height="15" fill="rgb(212,68,19)"/><text x="32.0508%" y="446.50"></text></g><g><title>av_probe_input_format3 (libavformat.so.58.29.100) (3 samples, 1.15%)</title><rect x="31.8008%" y="452" width="1.1494%" height="15" fill="rgb(240,187,13)"/><text x="32.0508%" y="462.50"></text></g><g><title>_read_video (torchvision/io/_video_opt.py:483) (8 samples, 3.07%)</title><rect x="30.2682%" y="84" width="3.0651%" height="15" fill="rgb(223,113,26)"/><text x="30.5182%" y="94.50">_re..</text></g><g><title>_probe_video_from_file (torchvision/io/_video_opt.py:295) (8 samples, 3.07%)</title><rect x="30.2682%" y="100" width="3.0651%" height="15" fill="rgb(206,192,2)"/><text x="30.5182%" y="110.50">_pr..</text></g><g><title>pybind11::cpp_function::dispatcher (libtorch_python.so) (8 samples, 3.07%)</title><rect x="30.2682%" y="116" width="3.0651%" height="15" fill="rgb(241,108,4)"/><text x="30.5182%" y="126.50">pyb..</text></g><g><title>void pybind11::cpp_function::initialize&lt;torch::jit::initJITBindings(_object*)::{lambda(std::string const&amp;)#93}::operator()(std::string const&amp;) const::{lambda(pybind11::args, pybind11::kwargs)#1}, pybind11::object, pybind11::args, pybind11::kwargs, pybind11::name, pybind11::doc&gt;(torch::jit::initJITBindings(_object*)::{lambda(std::string const&amp;)#93}::operator()(std::string const&amp;) const::{lambda(pybind11::args&amp;&amp;, pybind11::kwargs)#1}, pybind11::object (*)(pybind11::args, pybind11::kwargs), pybind11::name const, pybind11::doc&amp;)::{lambda(pybind11::detail::function_call&amp;)#3}::_FUN (libtorch_python.so) (8 samples, 3.07%)</title><rect x="30.2682%" y="132" width="3.0651%" height="15" fill="rgb(247,173,49)"/><text x="30.5182%" y="142.50">voi..</text></g><g><title>torch::jit::invokeOperatorFromPython (libtorch_python.so) (8 samples, 3.07%)</title><rect x="30.2682%" y="148" width="3.0651%" height="15" fill="rgb(224,114,35)"/><text x="30.5182%" y="158.50">tor..</text></g><g><title>torch::jit::(anonymous namespace)::createOperatorFromC10_withTracingHandledHere(c10::OperatorHandle const&amp;)::{lambda(std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)#1}::operator() const (libtorch_cpu.so) (8 samples, 3.07%)</title><rect x="30.2682%" y="164" width="3.0651%" height="15" fill="rgb(245,159,27)"/><text x="30.5182%" y="174.50">tor..</text></g><g><title>c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string&gt; &gt;, true&gt;::call (make_boxed_from_unboxed_functor.h:292) (8 samples, 3.07%)</title><rect x="30.2682%" y="180" width="3.0651%" height="15" fill="rgb(245,172,44)"/><text x="30.5182%" y="190.50">c10..</text></g><g><title>c10::guts::if_constexpr&lt;true, c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string&gt; &gt;, true&gt;::call(c10::OperatorKernel*, c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)::{lambda(auto:1)#1}, c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string&gt; &gt;, true&gt;::call(c10::OperatorKernel*, c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)::{lambda()#2}&gt; (C++17.h:282) (8 samples, 3.07%)</title><rect x="30.2682%" y="196" width="3.0651%" height="15" fill="rgb(236,23,11)"/><text x="30.5182%" y="206.50">c10..</text></g><g><title>c10::guts::detail::_if_constexpr&lt;true&gt;::call&lt;c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string&gt; &gt;, true&gt;::call(c10::OperatorKernel*, c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)::{lambda(auto:1)#1}, c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string&gt; &gt;, true&gt;::call(c10::OperatorKernel*, c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)::{lambda()#2}, (void*)0&gt; (C++17.h:193) (8 samples, 3.07%)</title><rect x="30.2682%" y="212" width="3.0651%" height="15" fill="rgb(205,117,38)"/><text x="30.5182%" y="222.50">c10..</text></g><g><title>c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string&gt; &gt;, true&gt;::call(c10::OperatorKernel*, c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)::{lambda(auto:1)#1}::operator()&lt;c10::guts::detail::_identity&gt; const (make_boxed_from_unboxed_functor.h:293) (8 samples, 3.07%)</title><rect x="30.2682%" y="228" width="3.0651%" height="15" fill="rgb(237,72,25)"/><text x="30.5182%" y="238.50">c10..</text></g><g><title>c10::impl::call_functor_with_args_from_stack&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string&gt; &gt;, true&gt; (make_boxed_from_unboxed_functor.h:255) (8 samples, 3.07%)</title><rect x="30.2682%" y="244" width="3.0651%" height="15" fill="rgb(244,70,9)"/><text x="30.5182%" y="254.50">c10..</text></g><g><title>c10::impl::call_functor_with_args_from_stack_&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string&gt; &gt;, true, (unsigned long)0&gt; (make_boxed_from_unboxed_functor.h:249) (8 samples, 3.07%)</title><rect x="30.2682%" y="260" width="3.0651%" height="15" fill="rgb(217,125,39)"/><text x="30.5182%" y="270.50">c10..</text></g><g><title>c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string&gt; &gt;::operator() (WrapFunctionIntoRuntimeFunctor.h:18) (8 samples, 3.07%)</title><rect x="30.2682%" y="276" width="3.0651%" height="15" fill="rgb(235,36,10)"/><text x="30.5182%" y="286.50">c10..</text></g><g><title>std::string::~string (basic_string.h:3630) (8 samples, 3.07%)</title><rect x="30.2682%" y="292" width="3.0651%" height="15" fill="rgb(251,123,47)"/><text x="30.5182%" y="302.50">std..</text></g><g><title>std::string::_M_rep (basic_string.h:3312) (8 samples, 3.07%)</title><rect x="30.2682%" y="308" width="3.0651%" height="15" fill="rgb(221,13,13)"/><text x="30.5182%" y="318.50">std..</text></g><g><title>video_reader::probeVideoFromFile (VideoReader.cpp:667) (8 samples, 3.07%)</title><rect x="30.2682%" y="324" width="3.0651%" height="15" fill="rgb(238,131,9)"/><text x="30.5182%" y="334.50">vid..</text></g><g><title>std::string::~string (basic_string.h:3630) (8 samples, 3.07%)</title><rect x="30.2682%" y="340" width="3.0651%" height="15" fill="rgb(211,50,8)"/><text x="30.5182%" y="350.50">std..</text></g><g><title>std::string::_M_rep (basic_string.h:3312) (8 samples, 3.07%)</title><rect x="30.2682%" y="356" width="3.0651%" height="15" fill="rgb(245,182,24)"/><text x="30.5182%" y="366.50">std..</text></g><g><title>video_reader::probeVideo (VideoReader.cpp:559) (8 samples, 3.07%)</title><rect x="30.2682%" y="372" width="3.0651%" height="15" fill="rgb(242,14,37)"/><text x="30.5182%" y="382.50">vid..</text></g><g><title>video_reader::readVideo (VideoReader.cpp:262) (4 samples, 1.53%)</title><rect x="43.2950%" y="404" width="1.5326%" height="15" fill="rgb(246,228,12)"/><text x="43.5450%" y="414.50"></text></g><g><title>0x7f6329b4600a (libavcodec.so.58.54.100) (10 samples, 3.83%)</title><rect x="45.9770%" y="548" width="3.8314%" height="15" fill="rgb(213,55,15)"/><text x="46.2270%" y="558.50">0x7f..</text></g><g><title>0x7f6329d8b2cf (libavcodec.so.58.54.100) (3 samples, 1.15%)</title><rect x="50.1916%" y="564" width="1.1494%" height="15" fill="rgb(209,9,3)"/><text x="50.4416%" y="574.50"></text></g><g><title>0x7f6329b46e5a (libavcodec.so.58.54.100) (16 samples, 6.13%)</title><rect x="45.9770%" y="532" width="6.1303%" height="15" fill="rgb(230,59,30)"/><text x="46.2270%" y="542.50">0x7f6329..</text></g><g><title>0x7f6329b46039 (libavcodec.so.58.54.100) (6 samples, 2.30%)</title><rect x="49.8084%" y="548" width="2.2989%" height="15" fill="rgb(209,121,21)"/><text x="50.0584%" y="558.50">0..</text></g><g><title>0x7f6329b4b1b1 (libavcodec.so.58.54.100) (4 samples, 1.53%)</title><rect x="59.3870%" y="596" width="1.5326%" height="15" fill="rgb(220,109,13)"/><text x="59.6370%" y="606.50"></text></g><g><title>0x7f6329b4e91d (libavcodec.so.58.54.100) (11 samples, 4.21%)</title><rect x="58.6207%" y="580" width="4.2146%" height="15" fill="rgb(232,18,1)"/><text x="58.8707%" y="590.50">0x7f6..</text></g><g><title>0x7f6329b99490 (libavcodec.so.58.54.100) (41 samples, 15.71%)</title><rect x="53.2567%" y="564" width="15.7088%" height="15" fill="rgb(215,41,42)"/><text x="53.5067%" y="574.50">0x7f6329b99490 (libavcod..</text></g><g><title>0x7f6329b997ac (libavcodec.so.58.54.100) (8 samples, 3.07%)</title><rect x="68.9655%" y="564" width="3.0651%" height="15" fill="rgb(224,123,36)"/><text x="69.2155%" y="574.50">0x7..</text></g><g><title>0x7f6329b9985d (libavcodec.so.58.54.100) (5 samples, 1.92%)</title><rect x="72.0307%" y="564" width="1.9157%" height="15" fill="rgb(240,125,3)"/><text x="72.2807%" y="574.50">0..</text></g><g><title>ffmpeg::Stream::decodePacket (stream.cpp:144) (75 samples, 28.74%)</title><rect x="45.5939%" y="468" width="28.7356%" height="15" fill="rgb(205,98,50)"/><text x="45.8439%" y="478.50">ffmpeg::Stream::decodePacket (stream.cpp:144)</text></g><g><title>ffmpeg::Stream::analyzePacket (stream.cpp:98) (75 samples, 28.74%)</title><rect x="45.5939%" y="484" width="28.7356%" height="15" fill="rgb(205,185,37)"/><text x="45.8439%" y="494.50">ffmpeg::Stream::analyzePacket (stream.cpp:98)</text></g><g><title>avcodec_send_packet (libavcodec.so.58.54.100) (75 samples, 28.74%)</title><rect x="45.5939%" y="500" width="28.7356%" height="15" fill="rgb(238,207,15)"/><text x="45.8439%" y="510.50">avcodec_send_packet (libavcodec.so.58.54.100)</text></g><g><title>0x7f6329a766f7 (libavcodec.so.58.54.100) (75 samples, 28.74%)</title><rect x="45.5939%" y="516" width="28.7356%" height="15" fill="rgb(213,199,42)"/><text x="45.8439%" y="526.50">0x7f6329a766f7 (libavcodec.so.58.54.100)</text></g><g><title>0x7f6329ba1317 (libavcodec.so.58.54.100) (56 samples, 21.46%)</title><rect x="52.8736%" y="532" width="21.4559%" height="15" fill="rgb(235,201,11)"/><text x="53.1236%" y="542.50">0x7f6329ba1317 (libavcodec.so.58.5..</text></g><g><title>0x7f6329b9b0c1 (libavcodec.so.58.54.100) (56 samples, 21.46%)</title><rect x="52.8736%" y="548" width="21.4559%" height="15" fill="rgb(207,46,11)"/><text x="53.1236%" y="558.50">0x7f6329b9b0c1 (libavcodec.so.58.5..</text></g><g><title>0x7f632949b115 (libswscale.so.5.5.100) (6 samples, 2.30%)</title><rect x="83.5249%" y="548" width="2.2989%" height="15" fill="rgb(241,35,35)"/><text x="83.7749%" y="558.50">0..</text></g><g><title>0x7f632949b11a (libswscale.so.5.5.100) (5 samples, 1.92%)</title><rect x="85.8238%" y="548" width="1.9157%" height="15" fill="rgb(243,32,47)"/><text x="86.0738%" y="558.50">0..</text></g><g><title>ffmpeg::VideoStream::copyFrameBytes (video_stream.cpp:115) (34 samples, 13.03%)</title><rect x="75.0958%" y="484" width="13.0268%" height="15" fill="rgb(247,202,23)"/><text x="75.3458%" y="494.50">ffmpeg::VideoStream:..</text></g><g><title>ffmpeg::VideoSampler::sample (video_sampler.cpp:182) (34 samples, 13.03%)</title><rect x="75.0958%" y="500" width="13.0268%" height="15" fill="rgb(219,102,11)"/><text x="75.3458%" y="510.50">ffmpeg::VideoSampler..</text></g><g><title>transformImage (video_sampler.cpp:45) (34 samples, 13.03%)</title><rect x="75.0958%" y="516" width="13.0268%" height="15" fill="rgb(243,110,44)"/><text x="75.3458%" y="526.50">transformImage (vide..</text></g><g><title>sws_scale (libswscale.so.5.5.100) (34 samples, 13.03%)</title><rect x="75.0958%" y="532" width="13.0268%" height="15" fill="rgb(222,74,54)"/><text x="75.3458%" y="542.50">sws_scale (libswscal..</text></g><g><title>ffmpeg::Decoder::getFrame (decoder.cpp:517) (112 samples, 42.91%)</title><rect x="45.5939%" y="436" width="42.9119%" height="15" fill="rgb(216,99,12)"/><text x="45.8439%" y="446.50">ffmpeg::Decoder::getFrame (decoder.cpp:517)</text></g><g><title>ffmpeg::Decoder::processPacket (decoder.cpp:600) (112 samples, 42.91%)</title><rect x="45.5939%" y="452" width="42.9119%" height="15" fill="rgb(226,22,26)"/><text x="45.8439%" y="462.50">ffmpeg::Decoder::processPacket (decoder.cpp:600)</text></g><g><title>ffmpeg::Stream::decodePacket (stream.cpp:147) (37 samples, 14.18%)</title><rect x="74.3295%" y="468" width="14.1762%" height="15" fill="rgb(217,163,10)"/><text x="74.5795%" y="478.50">ffmpeg::Stream::decode..</text></g><g><title>video_reader::readVideo (VideoReader.cpp:272) (115 samples, 44.06%)</title><rect x="44.8276%" y="404" width="44.0613%" height="15" fill="rgb(213,25,53)"/><text x="45.0776%" y="414.50">video_reader::readVideo (VideoReader.cpp:272)</text></g><g><title>ffmpeg::SyncDecoder::decode (sync_decoder.cpp:72) (115 samples, 44.06%)</title><rect x="44.8276%" y="420" width="44.0613%" height="15" fill="rgb(252,105,26)"/><text x="45.0776%" y="430.50">ffmpeg::SyncDecoder::decode (sync_decoder.cpp:72)</text></g><g><title>video_reader::readVideo (VideoReader.cpp:311) (3 samples, 1.15%)</title><rect x="89.2720%" y="404" width="1.1494%" height="15" fill="rgb(220,39,43)"/><text x="89.5220%" y="414.50"></text></g><g><title>at::Tensor::operator= &amp; (TensorBody.h:172) (3 samples, 1.15%)</title><rect x="89.2720%" y="420" width="1.1494%" height="15" fill="rgb(229,68,48)"/><text x="89.5220%" y="430.50"></text></g><g><title>c10::intrusive_ptr&lt;c10::TensorImpl, c10::UndefinedTensorImpl&gt;::operator= &amp; (intrusive_ptr.h:253) (3 samples, 1.15%)</title><rect x="89.2720%" y="436" width="1.1494%" height="15" fill="rgb(252,8,32)"/><text x="89.5220%" y="446.50"></text></g><g><title>c10::intrusive_ptr&lt;c10::TensorImpl, c10::UndefinedTensorImpl&gt;::operator=&lt;c10::TensorImpl, c10::UndefinedTensorImpl&gt; &amp; (intrusive_ptr.h:262) (3 samples, 1.15%)</title><rect x="89.2720%" y="452" width="1.1494%" height="15" fill="rgb(223,20,43)"/><text x="89.5220%" y="462.50"></text></g><g><title>c10::intrusive_ptr&lt;c10::TensorImpl, c10::UndefinedTensorImpl&gt;::intrusive_ptr (intrusive_ptr.h:222) (3 samples, 1.15%)</title><rect x="89.2720%" y="468" width="1.1494%" height="15" fill="rgb(229,81,49)"/><text x="89.5220%" y="478.50"></text></g><g><title>torch::zeros (variable_factories.h:618) (3 samples, 1.15%)</title><rect x="89.2720%" y="484" width="1.1494%" height="15" fill="rgb(236,28,36)"/><text x="89.5220%" y="494.50"></text></g><g><title>torch::zeros(c10::ArrayRef&lt;long&gt;, c10::TensorOptions const&amp;)::{lambda()#1}::operator() const (variable_factories.h:616) (3 samples, 1.15%)</title><rect x="89.2720%" y="500" width="1.1494%" height="15" fill="rgb(249,185,26)"/><text x="89.5220%" y="510.50"></text></g><g><title>at::AutoNonVariableTypeMode::~AutoNonVariableTypeMode (LegacyTypeDispatch.h:46) (3 samples, 1.15%)</title><rect x="89.2720%" y="516" width="1.1494%" height="15" fill="rgb(249,174,33)"/><text x="89.5220%" y="526.50"></text></g><g><title>at::zeros (libtorch_cpu.so) (3 samples, 1.15%)</title><rect x="89.2720%" y="532" width="1.1494%" height="15" fill="rgb(233,201,37)"/><text x="89.5220%" y="542.50"></text></g><g><title>c10::TypedOperatorHandle&lt;at::Tensor(c10::ArrayRef&lt;long&gt;, c10::optional&lt;c10::ScalarType&gt;, c10::optional&lt;c10::Layout&gt;, c10::optional&lt;c10::Device&gt;, c10::optional&lt;bool&gt;)&gt;::call (libtorch_cpu.so) (3 samples, 1.15%)</title><rect x="89.2720%" y="548" width="1.1494%" height="15" fill="rgb(221,78,26)"/><text x="89.5220%" y="558.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;at::Tensor (*)(c10::ArrayRef&lt;long&gt;, c10::optional&lt;c10::ScalarType&gt;, c10::optional&lt;c10::Layout&gt;, c10::optional&lt;c10::Device&gt;, c10::optional&lt;bool&gt;), at::Tensor, c10::guts::typelist::typelist&lt;c10::ArrayRef&lt;long&gt;, c10::optional&lt;c10::ScalarType&gt;, c10::optional&lt;c10::Layout&gt;, c10::optional&lt;c10::Device&gt;, c10::optional&lt;bool&gt; &gt; &gt;, at::Tensor(c10::ArrayRef&lt;long&gt;, c10::optional&lt;c10::ScalarType&gt;, c10::optional&lt;c10::Layout&gt;, c10::optional&lt;c10::Device&gt;, c10::optional&lt;bool&gt;)&gt;::call (libtorch_cpu.so) (3 samples, 1.15%)</title><rect x="89.2720%" y="564" width="1.1494%" height="15" fill="rgb(250,127,30)"/><text x="89.5220%" y="574.50"></text></g><g><title>c10::impl::detail::with_scattered_tensor_options_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::ArrayRef&lt;long&gt;, c10::TensorOptions const&amp;), &amp;at::(anonymous namespace)::zeros(c10::ArrayRef&lt;long&gt;, c10::TensorOptions const&amp;)&gt;, c10::guts::typelist::typelist&lt;c10::ArrayRef&lt;long&gt; &gt;, c10::guts::typelist::typelist&lt;&gt; &gt;::wrapper (libtorch_cpu.so) (3 samples, 1.15%)</title><rect x="89.2720%" y="580" width="1.1494%" height="15" fill="rgb(230,49,44)"/><text x="89.5220%" y="590.50"></text></g><g><title>c10::TypedOperatorHandle&lt;at::Tensor(c10::ArrayRef&lt;long&gt;, c10::optional&lt;c10::ScalarType&gt;, c10::optional&lt;c10::Layout&gt;, c10::optional&lt;c10::Device&gt;, c10::optional&lt;bool&gt;)&gt;::callWithDispatchKey (libtorch_cpu.so) (3 samples, 1.15%)</title><rect x="89.2720%" y="596" width="1.1494%" height="15" fill="rgb(229,67,23)"/><text x="89.5220%" y="606.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;at::Tensor (*)(c10::ArrayRef&lt;long&gt;, c10::optional&lt;c10::ScalarType&gt;, c10::optional&lt;c10::Layout&gt;, c10::optional&lt;c10::Device&gt;, c10::optional&lt;bool&gt;), at::Tensor, c10::guts::typelist::typelist&lt;c10::ArrayRef&lt;long&gt;, c10::optional&lt;c10::ScalarType&gt;, c10::optional&lt;c10::Layout&gt;, c10::optional&lt;c10::Device&gt;, c10::optional&lt;bool&gt; &gt; &gt;, at::Tensor(c10::ArrayRef&lt;long&gt;, c10::optional&lt;c10::ScalarType&gt;, c10::optional&lt;c10::Layout&gt;, c10::optional&lt;c10::Device&gt;, c10::optional&lt;bool&gt;)&gt;::call (libtorch_cpu.so) (3 samples, 1.15%)</title><rect x="89.2720%" y="612" width="1.1494%" height="15" fill="rgb(249,83,47)"/><text x="89.5220%" y="622.50"></text></g><g><title>c10::impl::detail::with_scattered_tensor_options_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::ArrayRef&lt;long&gt;, c10::TensorOptions const&amp;), &amp;at::TypeDefault::zeros(c10::ArrayRef&lt;long&gt;, c10::TensorOptions const&amp;)&gt;, c10::guts::typelist::typelist&lt;c10::ArrayRef&lt;long&gt; &gt;, c10::guts::typelist::typelist&lt;&gt; &gt;::wrapper (libtorch_cpu.so) (3 samples, 1.15%)</title><rect x="89.2720%" y="628" width="1.1494%" height="15" fill="rgb(215,43,3)"/><text x="89.5220%" y="638.50"></text></g><g><title>at::TypeDefault::zeros (libtorch_cpu.so) (3 samples, 1.15%)</title><rect x="89.2720%" y="644" width="1.1494%" height="15" fill="rgb(238,154,13)"/><text x="89.5220%" y="654.50"></text></g><g><title>at::native::zeros (libtorch_cpu.so) (3 samples, 1.15%)</title><rect x="89.2720%" y="660" width="1.1494%" height="15" fill="rgb(219,56,2)"/><text x="89.5220%" y="670.50"></text></g><g><title>at::native::zero_ (libtorch_cpu.so) (3 samples, 1.15%)</title><rect x="89.2720%" y="676" width="1.1494%" height="15" fill="rgb(233,0,4)"/><text x="89.5220%" y="686.50"></text></g><g><title>at::TypeDefault::fill__Scalar (libtorch_cpu.so) (3 samples, 1.15%)</title><rect x="89.2720%" y="692" width="1.1494%" height="15" fill="rgb(235,30,7)"/><text x="89.5220%" y="702.50"></text></g><g><title>at::native::fill_out (libtorch_cpu.so) (3 samples, 1.15%)</title><rect x="89.2720%" y="708" width="1.1494%" height="15" fill="rgb(250,79,13)"/><text x="89.5220%" y="718.50"></text></g><g><title>at::native::(anonymous namespace)::fill_kernel (libtorch_cpu.so) (3 samples, 1.15%)</title><rect x="89.2720%" y="724" width="1.1494%" height="15" fill="rgb(211,146,34)"/><text x="89.5220%" y="734.50"></text></g><g><title>at::native::(anonymous namespace)::fill_kernel(at::TensorIterator&amp;, c10::Scalar)::{lambda()#1}::operator() const (libtorch_cpu.so) (3 samples, 1.15%)</title><rect x="89.2720%" y="740" width="1.1494%" height="15" fill="rgb(228,22,38)"/><text x="89.5220%" y="750.50"></text></g><g><title>at::TensorIterator::for_each (libtorch_cpu.so) (3 samples, 1.15%)</title><rect x="89.2720%" y="756" width="1.1494%" height="15" fill="rgb(235,168,5)"/><text x="89.5220%" y="766.50"></text></g><g><title>at::TensorIterator::for_each (libtorch_cpu.so) (3 samples, 1.15%)</title><rect x="89.2720%" y="772" width="1.1494%" height="15" fill="rgb(221,155,16)"/><text x="89.5220%" y="782.50"></text></g><g><title>0x7f639221bbdb (libc-2.27.so) (3 samples, 1.15%)</title><rect x="93.1034%" y="436" width="1.1494%" height="15" fill="rgb(215,215,53)"/><text x="93.3534%" y="446.50"></text></g><g><title>video_reader::readVideo (VideoReader.cpp:326) (14 samples, 5.36%)</title><rect x="90.4215%" y="404" width="5.3640%" height="15" fill="rgb(223,4,10)"/><text x="90.6715%" y="414.50">video_r..</text></g><g><title>video_reader::fillTensor&lt;unsigned char&gt; (VideoReader.cpp:112) (14 samples, 5.36%)</title><rect x="90.4215%" y="420" width="5.3640%" height="15" fill="rgb(234,103,6)"/><text x="90.6715%" y="430.50">video_r..</text></g><g><title>&lt;module&gt; (profile_tvvr.py:13) (176 samples, 67.43%)</title><rect x="29.1188%" y="52" width="67.4330%" height="15" fill="rgb(227,97,0)"/><text x="29.3688%" y="62.50">&lt;module&gt; (profile_tvvr.py:13)</text></g><g><title>read_video (torchvision/io/video.py:215) (173 samples, 66.28%)</title><rect x="30.2682%" y="68" width="66.2835%" height="15" fill="rgb(234,150,53)"/><text x="30.5182%" y="78.50">read_video (torchvision/io/video.py:215)</text></g><g><title>_read_video (torchvision/io/_video_opt.py:522) (165 samples, 63.22%)</title><rect x="33.3333%" y="84" width="63.2184%" height="15" fill="rgb(228,201,54)"/><text x="33.5833%" y="94.50">_read_video (torchvision/io/_video_opt.py:522)</text></g><g><title>_read_video_from_file (torchvision/io/_video_opt.py:242) (165 samples, 63.22%)</title><rect x="33.3333%" y="100" width="63.2184%" height="15" fill="rgb(222,22,37)"/><text x="33.5833%" y="110.50">_read_video_from_file (torchvision/io/_video_opt.py:242)</text></g><g><title>pybind11::cpp_function::dispatcher (libtorch_python.so) (139 samples, 53.26%)</title><rect x="43.2950%" y="116" width="53.2567%" height="15" fill="rgb(237,53,32)"/><text x="43.5450%" y="126.50">pybind11::cpp_function::dispatcher (libtorch_python.so)</text></g><g><title>void pybind11::cpp_function::initialize&lt;torch::jit::initJITBindings(_object*)::{lambda(std::string const&amp;)#93}::operator()(std::string const&amp;) const::{lambda(pybind11::args, pybind11::kwargs)#1}, pybind11::object, pybind11::args, pybind11::kwargs, pybind11::name, pybind11::doc&gt;(torch::jit::initJITBindings(_object*)::{lambda(std::string const&amp;)#93}::operator()(std::string const&amp;) const::{lambda(pybind11::args&amp;&amp;, pybind11::kwargs)#1}, pybind11::object (*)(pybind11::args, pybind11::kwargs), pybind11::name const, pybind11::doc&amp;)::{lambda(pybind11::detail::function_call&amp;)#3}::_FUN (libtorch_python.so) (139 samples, 53.26%)</title><rect x="43.2950%" y="132" width="53.2567%" height="15" fill="rgb(233,25,53)"/><text x="43.5450%" y="142.50">void pybind11::cpp_function::initialize&lt;torch::jit::initJITBindings(_object*)::{lambda(s..</text></g><g><title>torch::jit::invokeOperatorFromPython (libtorch_python.so) (139 samples, 53.26%)</title><rect x="43.2950%" y="148" width="53.2567%" height="15" fill="rgb(210,40,34)"/><text x="43.5450%" y="158.50">torch::jit::invokeOperatorFromPython (libtorch_python.so)</text></g><g><title>torch::jit::(anonymous namespace)::createOperatorFromC10_withTracingHandledHere(c10::OperatorHandle const&amp;)::{lambda(std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)#1}::operator() const (libtorch_cpu.so) (139 samples, 53.26%)</title><rect x="43.2950%" y="164" width="53.2567%" height="15" fill="rgb(241,220,44)"/><text x="43.5450%" y="174.50">torch::jit::(anonymous namespace)::createOperatorFromC10_withTracingHandledHere(c10::Ope..</text></g><g><title>c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long&gt; &gt;, true&gt;::call (make_boxed_from_unboxed_functor.h:292) (139 samples, 53.26%)</title><rect x="43.2950%" y="180" width="53.2567%" height="15" fill="rgb(235,28,35)"/><text x="43.5450%" y="190.50">c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFun..</text></g><g><title>c10::guts::if_constexpr&lt;true, c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long&gt; &gt;, true&gt;::call(c10::OperatorKernel*, c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)::{lambda(auto:1)#1}, c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long&gt; &gt;, true&gt;::call(c10::OperatorKernel*, c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)::{lambda()#2}&gt; (C++17.h:282) (139 samples, 53.26%)</title><rect x="43.2950%" y="196" width="53.2567%" height="15" fill="rgb(210,56,17)"/><text x="43.5450%" y="206.50">c10::guts::if_constexpr&lt;true, c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::deta..</text></g><g><title>c10::guts::detail::_if_constexpr&lt;true&gt;::call&lt;c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long&gt; &gt;, true&gt;::call(c10::OperatorKernel*, c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)::{lambda(auto:1)#1}, c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long&gt; &gt;, true&gt;::call(c10::OperatorKernel*, c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)::{lambda()#2}, (void*)0&gt; (C++17.h:193) (139 samples, 53.26%)</title><rect x="43.2950%" y="212" width="53.2567%" height="15" fill="rgb(224,130,29)"/><text x="43.5450%" y="222.50">c10::guts::detail::_if_constexpr&lt;true&gt;::call&lt;c10::impl::make_boxed_from_unboxed_functor&lt;..</text></g><g><title>c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long&gt; &gt;, true&gt;::call(c10::OperatorKernel*, c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)::{lambda(auto:1)#1}::operator()&lt;c10::guts::detail::_identity&gt; const (make_boxed_from_unboxed_functor.h:294) (139 samples, 53.26%)</title><rect x="43.2950%" y="228" width="53.2567%" height="15" fill="rgb(235,212,8)"/><text x="43.5450%" y="238.50">c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoRuntimeFun..</text></g><g><title>drop (stack.h:57) (139 samples, 53.26%)</title><rect x="43.2950%" y="244" width="53.2567%" height="15" fill="rgb(223,33,50)"/><text x="43.5450%" y="254.50">drop (stack.h:57)</text></g><g><title>std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;::end (stl_vector.h:582) (139 samples, 53.26%)</title><rect x="43.2950%" y="260" width="53.2567%" height="15" fill="rgb(219,149,13)"/><text x="43.5450%" y="270.50">std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;::end (stl_vector.h:582)</text></g><g><title>__gnu_cxx::__normal_iterator&lt;c10::IValue*, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt; &gt;::__normal_iterator (stl_iterator.h:783) (139 samples, 53.26%)</title><rect x="43.2950%" y="276" width="53.2567%" height="15" fill="rgb(250,156,29)"/><text x="43.5450%" y="286.50">__gnu_cxx::__normal_iterator&lt;c10::IValue*, std::vector&lt;c10::IValue, std::allocator&lt;c10::..</text></g><g><title>c10::impl::call_functor_with_args_from_stack_&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long&gt; &gt;, true, (unsigned long)0, (unsigned long)1, (unsigned long)2, (unsigned long)3, (unsigned long)4, (unsigned long)5, (unsigned long)6, (unsigned long)7, (unsigned long)8, (unsigned long)9, (unsigned long)10, (unsigned long)11, (unsigned long)12, (unsigned long)13, (unsigned long)14, (unsigned long)15, (unsigned long)16, (unsigned long)17, (unsigned long)18&gt; (make_boxed_from_unboxed_functor.h:249) (139 samples, 53.26%)</title><rect x="43.2950%" y="292" width="53.2567%" height="15" fill="rgb(216,193,19)"/><text x="43.5450%" y="302.50">c10::impl::call_functor_with_args_from_stack_&lt;c10::impl::detail::WrapFunctionIntoRuntime..</text></g><g><title>c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long), c10::List&lt;at::Tensor&gt;, c10::guts::typelist::typelist&lt;std::string, double, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long&gt; &gt;::operator() (WrapFunctionIntoRuntimeFunctor.h:18) (139 samples, 53.26%)</title><rect x="43.2950%" y="308" width="53.2567%" height="15" fill="rgb(216,135,14)"/><text x="43.5450%" y="318.50">c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;c10::List&lt;at::Tensor&gt; (*)(std::string..</text></g><g><title>std::string::~string (basic_string.h:3630) (139 samples, 53.26%)</title><rect x="43.2950%" y="324" width="53.2567%" height="15" fill="rgb(241,47,5)"/><text x="43.5450%" y="334.50">std::string::~string (basic_string.h:3630)</text></g><g><title>std::string::_M_rep (basic_string.h:3312) (139 samples, 53.26%)</title><rect x="43.2950%" y="340" width="53.2567%" height="15" fill="rgb(233,42,35)"/><text x="43.5450%" y="350.50">std::string::_M_rep (basic_string.h:3312)</text></g><g><title>video_reader::readVideoFromFile (VideoReader.cpp:514) (139 samples, 53.26%)</title><rect x="43.2950%" y="356" width="53.2567%" height="15" fill="rgb(231,13,6)"/><text x="43.5450%" y="366.50">video_reader::readVideoFromFile (VideoReader.cpp:514)</text></g><g><title>std::string::~string (basic_string.h:3630) (139 samples, 53.26%)</title><rect x="43.2950%" y="372" width="53.2567%" height="15" fill="rgb(207,181,40)"/><text x="43.5450%" y="382.50">std::string::~string (basic_string.h:3630)</text></g><g><title>std::string::_M_rep (basic_string.h:3312) (139 samples, 53.26%)</title><rect x="43.2950%" y="388" width="53.2567%" height="15" fill="rgb(254,173,49)"/><text x="43.5450%" y="398.50">std::string::_M_rep (basic_string.h:3312)</text></g><g><title>&lt;module&gt; (torchvision/models/__init__.py:12) (3 samples, 1.15%)</title><rect x="96.5517%" y="276" width="1.1494%" height="15" fill="rgb(221,1,38)"/><text x="96.8017%" y="286.50"></text></g><g><title>_handle_fromlist (&lt;frozen importlib._bootstrap&gt;:1035) (3 samples, 1.15%)</title><rect x="96.5517%" y="292" width="1.1494%" height="15" fill="rgb(206,124,46)"/><text x="96.8017%" y="302.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (3 samples, 1.15%)</title><rect x="96.5517%" y="308" width="1.1494%" height="15" fill="rgb(249,21,11)"/><text x="96.8017%" y="318.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:983) (3 samples, 1.15%)</title><rect x="96.5517%" y="324" width="1.1494%" height="15" fill="rgb(222,201,40)"/><text x="96.8017%" y="334.50"></text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:967) (3 samples, 1.15%)</title><rect x="96.5517%" y="340" width="1.1494%" height="15" fill="rgb(235,61,29)"/><text x="96.8017%" y="350.50"></text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:677) (3 samples, 1.15%)</title><rect x="96.5517%" y="356" width="1.1494%" height="15" fill="rgb(219,207,3)"/><text x="96.8017%" y="366.50"></text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:728) (3 samples, 1.15%)</title><rect x="96.5517%" y="372" width="1.1494%" height="15" fill="rgb(222,56,46)"/><text x="96.8017%" y="382.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (3 samples, 1.15%)</title><rect x="96.5517%" y="388" width="1.1494%" height="15" fill="rgb(239,76,54)"/><text x="96.8017%" y="398.50"></text></g><g><title>&lt;module&gt; (torchvision/models/detection/__init__.py:1) (3 samples, 1.15%)</title><rect x="96.5517%" y="404" width="1.1494%" height="15" fill="rgb(231,124,27)"/><text x="96.8017%" y="414.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:983) (3 samples, 1.15%)</title><rect x="96.5517%" y="420" width="1.1494%" height="15" fill="rgb(249,195,6)"/><text x="96.8017%" y="430.50"></text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:967) (3 samples, 1.15%)</title><rect x="96.5517%" y="436" width="1.1494%" height="15" fill="rgb(237,174,47)"/><text x="96.8017%" y="446.50"></text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:677) (3 samples, 1.15%)</title><rect x="96.5517%" y="452" width="1.1494%" height="15" fill="rgb(206,201,31)"/><text x="96.8017%" y="462.50"></text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:728) (3 samples, 1.15%)</title><rect x="96.5517%" y="468" width="1.1494%" height="15" fill="rgb(231,57,52)"/><text x="96.8017%" y="478.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (3 samples, 1.15%)</title><rect x="96.5517%" y="484" width="1.1494%" height="15" fill="rgb(248,177,22)"/><text x="96.8017%" y="494.50"></text></g><g><title>&lt;module&gt; (torchvision/models/detection/faster_rcnn.py:7) (3 samples, 1.15%)</title><rect x="96.5517%" y="500" width="1.1494%" height="15" fill="rgb(215,211,37)"/><text x="96.8017%" y="510.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:983) (3 samples, 1.15%)</title><rect x="96.5517%" y="516" width="1.1494%" height="15" fill="rgb(241,128,51)"/><text x="96.8017%" y="526.50"></text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:967) (3 samples, 1.15%)</title><rect x="96.5517%" y="532" width="1.1494%" height="15" fill="rgb(227,165,31)"/><text x="96.8017%" y="542.50"></text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:677) (3 samples, 1.15%)</title><rect x="96.5517%" y="548" width="1.1494%" height="15" fill="rgb(228,167,24)"/><text x="96.8017%" y="558.50"></text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:728) (3 samples, 1.15%)</title><rect x="96.5517%" y="564" width="1.1494%" height="15" fill="rgb(228,143,12)"/><text x="96.8017%" y="574.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (3 samples, 1.15%)</title><rect x="96.5517%" y="580" width="1.1494%" height="15" fill="rgb(249,149,8)"/><text x="96.8017%" y="590.50"></text></g><g><title>&lt;module&gt; (torchvision/__init__.py:5) (4 samples, 1.53%)</title><rect x="96.5517%" y="148" width="1.5326%" height="15" fill="rgb(243,35,44)"/><text x="96.8017%" y="158.50"></text></g><g><title>_handle_fromlist (&lt;frozen importlib._bootstrap&gt;:1035) (4 samples, 1.53%)</title><rect x="96.5517%" y="164" width="1.5326%" height="15" fill="rgb(246,89,9)"/><text x="96.8017%" y="174.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (4 samples, 1.53%)</title><rect x="96.5517%" y="180" width="1.5326%" height="15" fill="rgb(233,213,13)"/><text x="96.8017%" y="190.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:983) (4 samples, 1.53%)</title><rect x="96.5517%" y="196" width="1.5326%" height="15" fill="rgb(233,141,41)"/><text x="96.8017%" y="206.50"></text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:967) (4 samples, 1.53%)</title><rect x="96.5517%" y="212" width="1.5326%" height="15" fill="rgb(239,167,4)"/><text x="96.8017%" y="222.50"></text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:677) (4 samples, 1.53%)</title><rect x="96.5517%" y="228" width="1.5326%" height="15" fill="rgb(209,217,16)"/><text x="96.8017%" y="238.50"></text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:728) (4 samples, 1.53%)</title><rect x="96.5517%" y="244" width="1.5326%" height="15" fill="rgb(219,88,35)"/><text x="96.8017%" y="254.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (4 samples, 1.53%)</title><rect x="96.5517%" y="260" width="1.5326%" height="15" fill="rgb(220,193,23)"/><text x="96.8017%" y="270.50"></text></g><g><title>&lt;module&gt; (profile_tvvr.py:5) (8 samples, 3.07%)</title><rect x="96.5517%" y="52" width="3.0651%" height="15" fill="rgb(230,90,52)"/><text x="96.8017%" y="62.50">&lt;mo..</text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:983) (8 samples, 3.07%)</title><rect x="96.5517%" y="68" width="3.0651%" height="15" fill="rgb(252,106,19)"/><text x="96.8017%" y="78.50">_fi..</text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:967) (8 samples, 3.07%)</title><rect x="96.5517%" y="84" width="3.0651%" height="15" fill="rgb(206,74,20)"/><text x="96.8017%" y="94.50">_fi..</text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:677) (8 samples, 3.07%)</title><rect x="96.5517%" y="100" width="3.0651%" height="15" fill="rgb(230,138,44)"/><text x="96.8017%" y="110.50">_lo..</text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:728) (8 samples, 3.07%)</title><rect x="96.5517%" y="116" width="3.0651%" height="15" fill="rgb(235,182,43)"/><text x="96.8017%" y="126.50">exe..</text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (8 samples, 3.07%)</title><rect x="96.5517%" y="132" width="3.0651%" height="15" fill="rgb(242,16,51)"/><text x="96.8017%" y="142.50">_ca..</text></g><g><title>&lt;module&gt; (torchvision/__init__.py:6) (4 samples, 1.53%)</title><rect x="98.0843%" y="148" width="1.5326%" height="15" fill="rgb(248,9,4)"/><text x="98.3343%" y="158.50"></text></g><g><title>_handle_fromlist (&lt;frozen importlib._bootstrap&gt;:1035) (4 samples, 1.53%)</title><rect x="98.0843%" y="164" width="1.5326%" height="15" fill="rgb(210,31,22)"/><text x="98.3343%" y="174.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (4 samples, 1.53%)</title><rect x="98.0843%" y="180" width="1.5326%" height="15" fill="rgb(239,54,39)"/><text x="98.3343%" y="190.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:983) (4 samples, 1.53%)</title><rect x="98.0843%" y="196" width="1.5326%" height="15" fill="rgb(230,99,41)"/><text x="98.3343%" y="206.50"></text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:967) (4 samples, 1.53%)</title><rect x="98.0843%" y="212" width="1.5326%" height="15" fill="rgb(253,106,12)"/><text x="98.3343%" y="222.50"></text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:677) (4 samples, 1.53%)</title><rect x="98.0843%" y="228" width="1.5326%" height="15" fill="rgb(213,46,41)"/><text x="98.3343%" y="238.50"></text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:728) (4 samples, 1.53%)</title><rect x="98.0843%" y="244" width="1.5326%" height="15" fill="rgb(215,133,35)"/><text x="98.3343%" y="254.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (4 samples, 1.53%)</title><rect x="98.0843%" y="260" width="1.5326%" height="15" fill="rgb(213,28,5)"/><text x="98.3343%" y="270.50"></text></g><g><title>all (261 samples, 100%)</title><rect x="0.0000%" y="36" width="100.0000%" height="15" fill="rgb(215,77,49)"/><text x="0.2500%" y="46.50"></text></g></svg></svg>